w4_12_plots.py
import numpy as np
import matplotlib.pyplot as plt
from collections import OrderedDict as OD
import os
import w3_2
import w3_utils
from matplotlib.lines import Line2D

var = lambda a, b, frac: ((b-a) * frac) ** 2
mean = lambda a, b: (b+a)/2

plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})
N_TRIALS_LIST = [5, 10, 15, 20, 30, 50]
N_DATASETS=96
STD_FRACTION = 0.25
K = 25
T_MS = 100
RH = 20
M_GRID = 15
X0 = 0.2

BETA_RANGE = (0, 4)
SIGMA_RANGE = (0.04, 4)

M_RANGE = (T_MS * 0.25, T_MS * 0.75)
R_RANGE = (1, 6)

ramp_param_specs = OD([
    ('beta', np.linspace(*BETA_RANGE, M_GRID)),
    ('sigma', np.exp(np.linspace(np.log(SIGMA_RANGE[0]),
                                    np.log(SIGMA_RANGE[1]),
                                    M_GRID))),
    ('x0', X0),
    ('K', K),
    ('T', T_MS),
    ('Rh', RH)
])

step_param_specs = OD([('m', np.linspace(*M_RANGE, M_GRID)),
                        ('r', np.linspace(*R_RANGE, 6).astype(int)),
                        ('x0', X0),
                        ('K', K),
                        ('T', T_MS),
                        ('Rh', RH)])

ramp_params_grid = w3_utils.make_params_grid(ramp_param_specs)
step_params_grid = w3_utils.make_params_grid(step_param_specs)

uniform_ramp_posterior = w3_utils.uniform_prior(ramp_params_grid)
uniform_step_posterior = w3_utils.uniform_prior(step_params_grid)


gauss_ramp_accs = []
gauss_step_accs = []
s1_ramp_accs = []
s1_step_accs = []
s3_ramp_accs = []
s3_step_accs = []
s5_ramp_accs = []
s5_step_accs = []

for N_TRIALS in N_TRIALS_LIST:
    fn = "./results/UU_D" + str(N_DATASETS) + "_shape1_T" + str(N_TRIALS)
    s1_step_acc, s1_ramp_acc = w3_2.plot_confusion_matrix(fn + '.csv',
                           r'Confusion matrix, shape = 1, ' + str(N_TRIALS) + ' trials/dataset',
                           save_name=fn + '.png',
                           fig_size_factor=0.8,
                           show=False)

    fn = "./results/UU_D" + str(N_DATASETS) + "_shape3_T" + str(N_TRIALS)
    s3_step_acc,s3_ramp_acc = w3_2.plot_confusion_matrix(fn + '.csv',
                               r'Confusion matrix, shape = 3, ' + str(N_TRIALS) + ' trials/dataset',
                               save_name=fn + '.png',
                               fig_size_factor=0.8,
                               show=False)

    fn = "./results/UU_D" + str(N_DATASETS) + "_shape5_T" + str(N_TRIALS)
    s5_step_acc,s5_ramp_acc = w3_2.plot_confusion_matrix(fn + '.csv',
                               r'Confusion matrix, shape = 5, ' + str(N_TRIALS) + ' trials/dataset',
                               save_name=fn + '.png',
                               fig_size_factor=0.8,
                               show=False)

    fn = "./results/GU_D" + str(50) + "_T" + str(N_TRIALS) + "_SF" + str(STD_FRACTION)

    gauss_step_acc,gauss_ramp_acc = w3_2.plot_confusion_matrix(fn + '.csv',
                               r'Confusion matrix, gaussian (sf=' + str(STD_FRACTION) + '), ' + str(N_TRIALS) + ' trials/dataset',
                               save_name=fn + '.png',
                               fig_size_factor=0.8,
                               show=False)
    gauss_ramp_accs.append(gauss_ramp_acc)
    gauss_step_accs.append(gauss_step_acc)

    s1_step_accs.append(s1_step_acc)
    s1_ramp_accs.append(s1_ramp_acc)
    s3_step_accs.append(s3_step_acc)
    s3_ramp_accs.append(s3_ramp_acc)
    s5_step_accs.append(s5_step_acc)
    s5_ramp_accs.append(s5_ramp_acc)
    print(N_TRIALS)

# plot results
plt.figure(figsize=(12, 8))

colors = {
    'poisson': 'k',
    'gaussian': 'blue',
    'shape3': 'green',
    'shape5': 'red'
}
labels = {
    'poisson': 'Baseline (Poisson, Uniform Prior)',
    'gaussian': 'Prior Mismatch (Gaussian Prior)',
    'shape3': 'Likelihood Mismatch (Shape=3)',
    'shape5': 'Likelihood Mismatch (Shape=5)'
}


plt.plot(N_TRIALS_LIST, s1_ramp_accs, color=colors['poisson'], linestyle='--', marker='o')
plt.plot(N_TRIALS_LIST, s1_step_accs, color=colors['poisson'], linestyle='-', marker='x')

plt.plot(N_TRIALS_LIST, gauss_ramp_accs, color=colors['gaussian'], linestyle='--', marker='o')
plt.plot(N_TRIALS_LIST, gauss_step_accs, color=colors['gaussian'], linestyle='-', marker='x')

plt.plot(N_TRIALS_LIST, s3_ramp_accs, color=colors['shape3'], linestyle='--', marker='o')
plt.plot(N_TRIALS_LIST, s3_step_accs, color=colors['shape3'], linestyle='-', marker='x')

plt.plot(N_TRIALS_LIST, s5_ramp_accs, color=colors['shape5'], linestyle='--', marker='o')
plt.plot(N_TRIALS_LIST, s5_step_accs, color=colors['shape5'], linestyle='-', marker='x')

plt.title('Model Selection Accuracy vs. Number of Trials')
plt.xlabel('Number of Trials')
plt.ylabel('Accuracy')
plt.grid(True, which='both', linestyle='--', linewidth=0.5)
plt.ylim(0.4, 1.05)


legend_elements_conditions = [
    Line2D([0], [0], color=colors['poisson'], lw=2, label=labels['poisson']),
    Line2D([0], [0], color=colors['gaussian'], lw=2, label=labels['gaussian']),
    Line2D([0], [0], color=colors['shape3'], lw=2, label=labels['shape3']),
    Line2D([0], [0], color=colors['shape5'], lw=2, label=labels['shape5'])
]

legend_elements_models = [
    Line2D([0], [0], color='gray', linestyle='--', marker='o', label='Ramp Model'),
    Line2D([0], [0], color='gray', linestyle='-', marker='x', label='Step Model')
]

ax = plt.gca()
leg1 = ax.legend(handles=legend_elements_conditions, title='Conditions', loc='lower right')
ax.add_artist(leg1)
leg2 = ax.legend(handles=legend_elements_models, title='Model Type', loc='center right')


plt.tight_layout()
plt.show()
plt.close()

w3_2.py
import numpy as np
import matplotlib.pyplot as plt

plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})

from collections import OrderedDict as OD
import scipy.special
import pandas as pd
import os
import multiprocessing
from models_hmm import RampModelHMM, StepModelHMM
from scipy.interpolate import griddata
import seaborn as sns
import w3_utils
from models_hmm import RampModelHMM
from tqdm import tqdm


def _model_selection_worker(args):
    """Helper function for parallel execution in model_selection."""
    (ramp_params_grid, step_params_grid, gen_ramp, gen_step, ramp_post, step_post,
     N_TRIALS_RAMP, ramp_gamma_shape, step_gamma_shape, N_TRIALS_STEP) = args

    ramp_params = w3_utils.sample_from_grid(gen_ramp, ramp_params_grid)
    ramp_data, _, _ = RampModelHMM(beta=ramp_params['beta'],
                                   sigma=ramp_params['sigma'],
                                   Rh=ramp_params['Rh'],
                                   x0=ramp_params['x0'] if 'x0' in ramp_params else 0.2,
                                   isi_gamma_shape=ramp_gamma_shape
                                   ).simulate(Ntrials=N_TRIALS_RAMP, T=ramp_params['T'])

    ramp_LLH_ramp = w3_utils.ramp_LLH(ramp_data, ramp_params_grid)
    step_LLH_ramp = w3_utils.step_LLH(ramp_data, step_params_grid)

    ramp_bf_ramp = w3_utils.marginal_likelihood(ramp_LLH_ramp, ramp_post)
    step_bf_ramp = w3_utils.marginal_likelihood(step_LLH_ramp, step_post)

    step_params = w3_utils.sample_from_grid(gen_step, step_params_grid)
    step_data, _, _ = StepModelHMM(m=step_params['m'],
                                   r=step_params['r'],
                                   Rh=step_params['Rh'],
                                   x0=step_params['x0'] if 'x0' in step_params else 0.2,
                                   isi_gamma_shape=step_gamma_shape
                                   ).simulate_exact(Ntrials=N_TRIALS_STEP, T=step_params['T'])

    ramp_LLH_step = w3_utils.ramp_LLH(step_data, ramp_params_grid)
    step_LLH_step = w3_utils.step_LLH(step_data, step_params_grid)

    ramp_bf_step = w3_utils.marginal_likelihood(ramp_LLH_step, ramp_post)
    step_bf_step = w3_utils.marginal_likelihood(step_LLH_step, step_post)

    return {
        'beta': ramp_params['beta'],
        'sigma': ramp_params['sigma'],
        'ramp_data_ramp_bf': ramp_bf_ramp,
        'ramp_data_step_bf': step_bf_ramp,
        'm': step_params['m'],
        'r': step_params['r'],
        'step_data_ramp_bf': ramp_bf_step,
        'step_data_step_bf': step_bf_step
    }


def model_selection(ramp_params_grid, step_params_grid, gen_ramp, gen_step, ramp_post, step_post,
                   N_DATASETS=100, N_TRIALS=100, ramp_gamma_shape=None, step_gamma_shape=None, save_to=None):
    """
    Run simulation and save model comparison results
    
    Parameters:
    -----------
    ramp_params_grid: dict
        Grid of parameters for ramp model
    step_params_grid: dict
        Grid of parameters for step model  
    gen_ramp: function
        PDF grid for ramp data
    gen_step: function
        PDF grid for step data
    ramp_post: array-like
        Ramp model posterior
    step_post: array-like
        Step model posterior
    N_DATASETS: int
        Number of datasets to generate
    N_TRIALS: int
        Number of trials per dataset
    ramp_gamma_shape: float, optional
        Shape parameter for ramp model ISI gamma distribution
    step_gamma_shape: float, optional 
        Shape parameter for step model ISI gamma distribution
    save_to: str, optional
        Path to save results CSV file
    """
    
    results = {
        'beta': [], 'sigma': [],
        'ramp_data_ramp_bf': [], 'ramp_data_step_bf': [],
        'm': [], 'r': [],
        'step_data_ramp_bf': [], 'step_data_step_bf': []
    }

    N_TRIALS_STEP = 50

    worker_args = [(ramp_params_grid, step_params_grid, gen_ramp, gen_step, ramp_post, step_post,
                    N_TRIALS, ramp_gamma_shape, step_gamma_shape, N_TRIALS) for _ in range(N_DATASETS)]

    with multiprocessing.Pool() as pool:
        pool_results = list(tqdm(pool.imap_unordered(_model_selection_worker, worker_args), total=N_DATASETS))
    
    for res in pool_results:
        for key in results:
            results[key].append(res[key])

    if save_to:
        results_df = pd.DataFrame(results)
        os.makedirs(os.path.dirname(save_to), exist_ok=True)
        results_df.to_csv(save_to, index=False)

    return results


def plot_heatmap(results_df, title='Untitled Heatmap', interp_method='linear', save_name=None, show=True):
    """
    Plot heatmaps comparing model performance on ramp and step data
    
    Parameters:
    -----------
    results_df: pandas.DataFrame or str
        DataFrame containing results or path to CSV file with results
    """

    if isinstance(results_df, str):
        results_df = pd.read_csv(results_df)
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15 * 0.7, 6 * 0.7))

    # Ramp data heatmap
    grid_x1, grid_y1 = np.mgrid[0:4:100j, 0.04:4:100j]
    grid_z1 = griddata((results_df['beta'], results_df['sigma']),
                       np.array(results_df['ramp_data_ramp_bf']) - np.array(results_df['ramp_data_step_bf']),
                       (grid_x1, grid_y1),
                       method=interp_method)

    max_val = np.nanmax(np.abs(grid_z1))
    norm = plt.Normalize(vmin=-max_val, vmax=max_val)

    im1 = ax1.pcolormesh(grid_x1, grid_y1, grid_z1, cmap='coolwarm', shading='auto', norm=norm)

    ax1.scatter(results_df['beta'], results_df['sigma'], c='black', s=5, alpha=0.1)
    ax1.set_xlabel('beta')
    ax1.set_ylabel('sigma') 
    ax1.set_title('Ramp Data')

    ax1.set_yscale('log')
    plt.colorbar(im1, ax=ax1)

    # Step data heatmap
    grid_x2, grid_y2 = np.mgrid[25:75:100j, 1:6:100j]
    grid_z2 = griddata((results_df['m'], results_df['r']),
                       np.array(results_df['step_data_step_bf']) - np.array(results_df['step_data_ramp_bf']),
                       (grid_x2, grid_y2),
                       method='cubic')

    im2 = ax2.pcolormesh(grid_x2, grid_y2, grid_z2, cmap='coolwarm', shading='auto')
    ax2.scatter(results_df['m'], results_df['r'], c='black', s=5, alpha=0.1)
    ax2.set_xlabel('m')
    ax2.set_ylabel('r')
    ax2.set_title('Step Data')

    fig.suptitle(title, fontsize=20)

    plt.tight_layout()
    plt.colorbar(im2, ax=ax2)

    if save_name:
        plt.savefig(save_name)
    if show:
        plt.show()
    plt.close()


def plot_confusion_matrix(csv_path, plot_title, save_name='confmat', normalize=True, fig_size_factor=0.7, show=True):
    """
    Plot confusion matrix from results CSV and return accuracy.

    Args:
        csv_path (str): Path to the CSV file containing results
        plot_title (str): Title for the confusion matrix plot

    Returns:
        float: Classification accuracy
    """
    results_df = pd.read_csv(csv_path)

    # Calculate predictions (1 if ramp, 0 if step)
    ramp_predictions = (results_df['ramp_data_ramp_bf'] - results_df['ramp_data_step_bf'] > 0).astype(int)
    step_predictions = (results_df['step_data_ramp_bf'] - results_df['step_data_step_bf'] > 0).astype(int)

    ramp_true = np.ones(len(ramp_predictions))
    step_true = np.zeros(len(step_predictions))

    y_true = np.concatenate([ramp_true, step_true])
    y_pred = np.concatenate([ramp_predictions, step_predictions])

    conf_matrix = np.zeros((2, 2))
    conf_matrix[0, 0] = np.sum((y_true == 0) & (y_pred == 0))  # True Negatives
    conf_matrix[0, 1] = np.sum((y_true == 0) & (y_pred == 1))  # False Positives
    conf_matrix[1, 0] = np.sum((y_true == 1) & (y_pred == 0))  # False Negatives
    conf_matrix[1, 1] = np.sum((y_true == 1) & (y_pred == 1))  # True Positives

    if normalize:
        conf_matrix /= len(ramp_predictions)

        # print(conf_matrix)

    plt.figure(figsize=(8 * fig_size_factor, 6 * fig_size_factor))
    sns.heatmap(conf_matrix, annot=True, fmt='.3f', cmap='Blues',
                xticklabels=['Step', 'Ramp'],
                yticklabels=['Step', 'Ramp'])
    plt.title(plot_title)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.tight_layout()
    plt.savefig(save_name)
    if show:
        plt.show()
    plt.close()
    accuracy = (conf_matrix[0, 0] + conf_matrix[1, 1]) / np.sum(conf_matrix)
    print(f'Overall HMM Accuracy: {accuracy:.2%}')
    print(conf_matrix)

    if 'ML_LLR_step' in results_df and 'ML_LLR_ramp' in results_df:
        # additionally plot conf matrix for ML (1.4)

        ramp_true = np.ones(len(results_df['ML_LLR_ramp']))
        step_true = np.zeros(len(results_df['ML_LLR_step']))

        ramp_predictions = (results_df['ML_LLR_ramp'] > 0).astype(int)
        step_predictions = (results_df['ML_LLR_step'] > 0).astype(int)

        y_true = np.concatenate([ramp_true, step_true])
        y_pred = np.concatenate([ramp_predictions, step_predictions])

        conf_matrix = np.zeros((2, 2))
        conf_matrix[0, 0] = np.sum((y_true == 0) & (y_pred == 0))  # True Negatives
        conf_matrix[0, 1] = np.sum((y_true == 0) & (y_pred == 1))  # False Positives
        conf_matrix[1, 0] = np.sum((y_true == 1) & (y_pred == 0))  # False Negatives
        conf_matrix[1, 1] = np.sum((y_true == 1) & (y_pred == 1))  # True Positives

        if normalize:
            conf_matrix /= len(ramp_predictions)

        plt.figure(figsize=(8 * fig_size_factor, 6 * fig_size_factor))
        sns.heatmap(conf_matrix, annot=True, fmt='.3f', cmap='Blues',
                    xticklabels=['Step', 'Ramp'],
                    yticklabels=['Step', 'Ramp'])
        plt.title(plot_title + ' - ad-hoc')
        plt.xlabel('Predicted Label')
        plt.ylabel('True Label')
        plt.tight_layout()
        plt.savefig(save_name + ' - ad-hoc (ML).png')
        if show:
            plt.show()
        plt.close()

    return conf_matrix[0, 0], conf_matrix[1, 1]





    return


def _test_worker(args):
    (uniform_ramp_posterior, ramp_params_grid, uniform_step_posterior, 
     step_params_grid, RH, N_TRIALS, T_MS) = args

    dataset_params = w3_utils.sample_from_grid(uniform_ramp_posterior, ramp_params_grid)
    data_ramp, _, _ = RampModelHMM(beta=dataset_params['beta'],
                            sigma=dataset_params['sigma'], Rh=RH).simulate(Ntrials=N_TRIALS,
                                                                        T=T_MS)

    dataset_params = w3_utils.sample_from_grid(uniform_step_posterior, step_params_grid)

    data_step, _, _ = StepModelHMM(m=dataset_params['m'],
                              r=dataset_params['r'], Rh=RH).simulate_exact(Ntrials=N_TRIALS,
                                                                             T=T_MS)

    ramp_LLH_pgrid = w3_utils.ramp_LLH(data_ramp, ramp_params_grid)
    ramp_bayes = w3_utils.marginal_likelihood(ramp_LLH_pgrid, uniform_ramp_posterior)

    step_LLH_pgrid = w3_utils.step_LLH(data_step, step_params_grid)
    step_bayes = w3_utils.marginal_likelihood(step_LLH_pgrid, uniform_step_posterior)

    return ramp_bayes, step_bayes, dataset_params['m'], dataset_params['r']


if __name__ == "__main__":
    os.makedirs('plots', exist_ok=True)
    K = 25
    T_MS = 100
    RH = 50
    M_GRID = 10
    X0 = 0.2
    N_DATASETS = 20
    N_TRIALS = 50


    ramp_param_specs = OD([
        ('beta', np.linspace(0, 4, M_GRID)),
        ('sigma', np.exp(np.linspace(np.log(0.04), np.log(4), M_GRID))),
        ('x0', X0),
        ('K', K),
        ('T', T_MS),
        ('Rh', RH)
    ])

    step_param_specs = OD([('m', [T_MS * 0.25, T_MS * 0.75, M_GRID]),
                ('r', [1, 6, 6]),
                ('x0', X0),
                ('K', K),
                ('T', T_MS),
                ('Rh', RH)])

    ramp_params_grid = w3_utils.make_params_grid(ramp_param_specs)
    step_params_grid = w3_utils.make_params_grid(step_param_specs)

    uniform_ramp_posterior = w3_utils.uniform_prior(ramp_params_grid)
    uniform_step_posterior = w3_utils.uniform_prior(step_params_grid)



    iv1 = []
    iv2 = []
    ramp_bayes_factors = []
    step_bayes_factors = []


    worker_args = [(uniform_ramp_posterior, ramp_params_grid, uniform_step_posterior,
                    step_params_grid, RH, N_TRIALS, T_MS) for _ in range(N_DATASETS)]

    with multiprocessing.Pool() as pool:
        results = list(tqdm(pool.imap_unordered(_test_worker, worker_args), total=N_DATASETS))

    for ramp_bayes, step_bayes, m_val, r_val in results:
        ramp_bayes_factors.append(ramp_bayes)
        step_bayes_factors.append(step_bayes)
        iv1.append(m_val)
        iv2.append(r_val)


    diff_bayes = np.array(step_bayes_factors) - np.array(ramp_bayes_factors)

    print(diff_bayes)
    # Create a regular grid to interpolate the data
    grid_x, grid_y = np.mgrid[T_MS*0.25:T_MS*0.75:100j, 1:6:100j]
    # grid_x, grid_y = np.mgrid[0:4:100j, 0:4:100j]

    # Interpolate the data onto the regular grid
    grid_z = griddata((iv1, iv2), diff_bayes, (grid_x, grid_y), method='cubic')

    # Create the heatmap
    plt.figure(figsize=(10, 8))
    plt.pcolormesh(grid_x, grid_y, grid_z, cmap='coolwarm', shading='auto')
    plt.colorbar(label='Log Likelihood Difference (ramp - step)')

    # Add the original points
    plt.scatter(iv1, iv2, c='black', s=20, alpha=0.5)

    plt.xlabel('m')
    plt.ylabel('r')
    plt.title('Heatmap of Log Likelihood Differences')

    # Use log scale for sigma axis since it was generated using exp(linspace)
    plt.yscale('log')

    plt.savefig('plots/task_3_2_heatmap.png')
    plt.show()


'''gauss_post = w3_utils.gaussian_posterior(params_grid, mu={
        'beta': 1.0, 'sigma': 1.0
    }, cov={
        ('beta', 'beta'): 2,
        ('sigma', 'sigma'): 3
    }, log=True)'''

models_hmm.py
import numpy as np
import numpy.random as npr

from scipy.stats import norm
from scipy.stats import nbinom

def lo_histogram(x, bins):
    """
    Left-open version of np.histogram with left-open bins covering the interval (left_edge, right_edge]
    (np.histogram does the opposite and treats bins as right-open.)
    Input & output behaviour is exactly the same as np.histogram
    """
    out = np.histogram(-x, -bins[::-1])
    return out[0][::-1], out[1:]


def gamma_isi_point_process(rate, shape):
    """
    Simulates (1 trial of) a sub-poisson point process (with underdispersed inter-spike intervals relative to Poisson)
    :param rate: time-series giving the mean spike count (firing rate * dt) in different time bins (= time steps)
    :param shape: shape parameter of the gamma distribution of ISI's
    :return: vector of spike counts with same shape as "rate".
    """
    sum_r_t = np.hstack((0, np.cumsum(rate)))
    gs = np.zeros(2)
    while gs[-1] < sum_r_t[-1]:
        gs = np.cumsum( npr.gamma(shape, 1 / shape, size=(2 + int(2 * sum_r_t[-1]),)) )
    y, _ = lo_histogram(gs, sum_r_t)

    return y


class StepModelHMM():
    """
    Simulator of the Stepping Model of Latimer et al. Science 2015.
    """
    def __init__(self, m=50, r=10, x0=0.2, Rh=50, isi_gamma_shape=None, Rl=None, dt=None):
        """
        Simulator of the Stepping Model of Latimer et al. Science 2015.
        :param m: mean jump time (in # of time-steps). This is the mean parameter of the Negative Binomial distribution
                  of jump (stepping) time
        :param r: parameter r ("# of successes") of the Negative Binomial (NB) distribution of jump (stepping) time
                  (Note that it is more customary to parametrise the NB distribution by its parameter p and r,
                  instead of m and r, where p is so-called "probability of success" (see Wikipedia). The two
                  parametrisations are equivalent and one can go back-and-forth via: m = r (1-p)/p and p = r / (m + r).)
        :param x0: determines the pre-jump firing rate, via  R_pre = x0 * Rh (see below for Rh)
        :param Rh: firing rate of the "up" state (the same as the post-jump state in most of the project tasks)
        :param isi_gamma_shape: shape parameter of the Gamma distribution of inter-spike intervals.
                            see https://en.wikipedia.org/wiki/Gamma_distribution
        :param Rl: firing rate of the post-jump "down" state (rarely used)
        :param dt: real time duration of time steps in seconds (only used for converting rates to units of inverse time-step)
        """
        self.m = m
        self.r = r
        self.x0 = x0

        self.p = r / (m + r)

        self.Rh = Rh
        if Rl is not None:
            self.Rl = Rl

        self.isi_gamma_shape = isi_gamma_shape
        self.dt = dt


    @property
    def params(self):
        return self.m, self.r, self.x0

    @property
    def fixed_params(self):
        return self.Rh, self.Rl


    def emit(self, rate):
        """
        emit spikes based on rates
        :param rate: firing rate sequence, r_t, possibly in many trials. Shape: (Ntrials, T)
        :return: spike train, n_t, as an array of shape (Ntrials, T) containing integer spike counts in different
                 trials and time bins.
        """
        if self.isi_gamma_shape is None:
            # poisson spike emissions
            y = npr.poisson(rate * self.dt)
        else:
            # sub-poisson/underdispersed spike emissions
            y = gamma_isi_point_process(rate * self.dt, self.isi_gamma_shape)

        return y

    # TODO: maybe separate the transition matrix code, if 2.3/further sections need it
    def simulate_2state(self, Ntrials=1, T=100, get_rate=True):
        """
        :param Ntrials: (int) number of trials
        :param T: (int) duration of each trial in number of time-steps.
        :param get_rate: whether or not to return the rate time-series
        :return:
        spikes: shape = (Ntrial, T); spikes[j] gives the spike train, n_t, in trial j, as
                an array of spike counts in each time-bin (= time step)
        jumps:  shape = (Ntrials,) ; jumps[j] is the jump time (aka step time), tau, in trial j.
        rates:  shape = (Ntrial, T); rates[j] is the rate time-series, r_t, in trial j (returned only if get_rate=True)
        """
        # set dt (time-step duration in seconds) such that trial duration is always 1 second, regardless of T.
        dt = 1 / T
        self.dt = dt

        # in this model, the jump times, tau, follow Geom(p) rather than NB(r,p) so it is not exact
        transition = np.array([[1-self.p, self.p], [0, 1]])

        spikes, jumps, rates = [], [], []
        for tr in range(Ntrials):
            state = 0 # start with initial state = x0
            rate = np.ones(T)*self.Rh
            rate[0] = rate[0]*self.x0
            for t in range(T-1):
                sample = npr.binomial(1,transition[state][state+1])
                state+=sample
                if state==1:
                    break
                else:
                    rate[t+1]*=self.x0

            jumps.append(np.argmax(rate))
            rates.append(rate)
            spikes.append(self.emit(rate))

        if get_rate:
            return np.array(spikes), np.array(jumps), np.array(rates)
        else:
            return np.array(spikes), np.array(jumps)

    def _calculate_transition_matrix_exact(self, Ntrials=1, T=100):
        transition = np.identity(int(self.r) + 1)
        for i in range(int(self.r)):
            transition[i][i] = 1 - self.p
            transition[i][i + 1] = self.p
        return transition

    def _calculate_initial_distribution_exact(self):
        # always start from the first state
        pi = np.zeros(int(self.r) + 1)
        pi[0] = 1
        return pi

    def simulate_exact(self, Ntrials=1, T=100, get_rate=True, return_state_indices=False, delay_compensation=False):

        """
        :param Ntrials: (int) number of trials
        :param T: (int) duration of each trial in number of time-steps.
        :param get_rate: whether or not to return the rate time-series
        :return:
        spikes: shape = (Ntrial, T); spikes[j] gives the spike train, n_t, in trial j, as
                an array of spike counts in each time-bin (= time step)
        jumps:  shape = (Ntrials,) ; jumps[j] is the jump time (aka step time), tau, in trial j.
        rates:  shape = (Ntrial, T); rates[j] is the rate time-series, r_t, in trial j (returned only if get_rate=True)
        """
        # set dt (time-step duration in seconds) such that trial duration is always 1 second, regardless of T.
        dt = 1 / T
        self.dt = dt

        # in this model, the states are 0 <= number of successes <= r
        # in this model, jump occurs after rth success so it is delayed from Week 1 model by r time-steps
        transition = self._calculate_transition_matrix_exact(Ntrials, T)

        spikes, jumps, rates, states = [], [], [], []
        for tr in range(Ntrials):



            sim_steps = T+self.r-1 if delay_compensation else T-1

            state = np.ones(sim_steps+1) * self.r # states vector for current trial. Assume all are at the max state
            rate = np.ones(sim_steps+1)*self.Rh

            rate[0] = rate[0]*self.x0
            cur_state = 0  # start with initial state = x0
            state[0] = cur_state


            for t in range(sim_steps):

                sample = npr.binomial(1,transition[cur_state][cur_state+1])
                cur_state+=sample
                if cur_state==self.r:
                    break
                else:
                    rate[t+1]*=self.x0

                state[t+1] = cur_state

            if delay_compensation:
                rate = rate[self.r:]
                state = state[self.r:]

            jumps.append(np.argmax(rate))
            rates.append(rate)
            spikes.append(self.emit(rate))
            states.append(state)

        if return_state_indices:
            rates = states

        if get_rate:
            return np.array(spikes), np.array(jumps), np.array(rates)
        else:
            return np.array(spikes), np.array(jumps)

    def simulate_exact_2state(self, Ntrials=1, T=100, get_rate=True):
        """
        :param Ntrials: (int) number of trials
        :param T: (int) duration of each trial in number of time-steps.
        :param get_rate: whether or not to return the rate time-series
        :return:
        spikes: shape = (Ntrial, T); spikes[j] gives the spike train, n_t, in trial j, as
                an array of spike counts in each time-bin (= time step)
        jumps:  shape = (Ntrials,) ; jumps[j] is the jump time (aka step time), tau, in trial j.
        rates:  shape = (Ntrial, T); rates[j] is the rate time-series, r_t, in trial j (returned only if get_rate=True)
        """
        # set dt (time-step duration in seconds) such that trial duration is always 1 second, regardless of T.
        dt = 1 / T
        self.dt = dt

        spikes, jumps, rates = [], [], []
        for tr in range(Ntrials):
            state = 0 # start with initial state = x0
            rate = np.ones(T)*self.Rh
            rate[0] = rate[0]*self.x0
            for t in range(T-1):
                # in this model, p_t = P(rth success occurs after exactly t failures|rth success occurs after > t-1 failures)
                p_t = nbinom.pmf(t, self.r, self.p)/(1-nbinom.cdf(t, self.r, self.p))
                transition = np.array([[1-p_t, p_t], [0, 1]])
                sample = npr.binomial(1,np.clip(transition[state][state+1], 0, 1))
                state+=sample
                if state==1:
                    break
                else:
                    rate[t+1]*=self.x0

            jumps.append(np.argmax(rate))
            rates.append(rate)
            spikes.append(self.emit(rate))

        if get_rate:
            return np.array(spikes), np.array(jumps), np.array(rates)
        else:
            return np.array(spikes), np.array(jumps)

class RampModelHMM:
    """
    Simulator of the HMM approximation of the Ramping Model of Latimer et al., Science (2015).
    """
    def __init__(self, beta=0.5, sigma=0.2, x0=0.2, K=50, Rh=50, isi_gamma_shape=None, Rl=None, dt=None):
        """
        Simulator of the HMM approximation of the Ramping Model of Latimer et al., Science (2015).
        :param beta: drift rate of the drift-diffusion process
        :param sigma: diffusion strength of the drift-diffusion process.
        :param x0: average initial value of latent variable x[0]
        :param K: number of discrete states for x_t
        :param Rh: the maximal firing rate obtained when x_t reaches 1 (corresponding to the same as the post-step
                   state in most of the project tasks)
        :param isi_gamma_shape: shape parameter of the Gamma distribution of inter-spike intervals.
                            see https://en.wikipedia.org/wiki/Gamma_distribution
        :param Rl: Not implemented. Ignore.
        :param dt: real time duration of time steps in seconds (only used for converting rates to units of inverse time-step)
        """
        self.beta = beta
        self.sigma = sigma
        self.x0 = x0

        self.Rh = Rh
        if Rl is not None:
            self.Rl = Rl

        self.isi_gamma_shape = isi_gamma_shape
        self.dt = dt

        self.K = K

        if self.K > 0:
            self.x_values = np.linspace(0, 1, self.K)
        else:
            self.x_values = np.array([])

    @property
    def params(self):
        return self.beta, self.sigma, self.x0, self.K, self.Rh, self.Rl, self.dt

    @property
    def fixed_params(self):
        return self.Rh, self.Rl


    def f_io(self, xs, b=None):
        if b is None:
            return self.Rh * np.maximum(0, xs)
        else:
            return self.Rh * b * np.log(1 + np.exp(xs / b))
        
    def emit(self, rate):
        """
        emit spikes based on rates
        :param rate: firing rate sequence, r_t, possibly in many trials. Shape: (Ntrials, T)
        :return: spike train, n_t, as an array of shape (Ntrials, T) containing integer spike counts in different
                 trials and time bins.
        """
        if self.isi_gamma_shape is None:
            # poisson spike emissions
            y = npr.poisson(rate * self.dt)
        else:
            # sub-poisson/underdispersed spike emissions
            y = gamma_isi_point_process(rate * self.dt, self.isi_gamma_shape)

        return y

    def _get_bin_edges(self):
        bin_width_internal = 1.0 / (self.K - 1)
        edges = np.zeros(self.K + 1)
        edges[0] = -np.inf
        edges[self.K] = np.inf
        edges[1:-1] = self.x_values[:-1] + bin_width_internal / 2.0
        return edges

    def _calculate_initial_distribution(self, T=None):

        if T is not None:
            self.dt = 1.0/T

        pi_values = np.zeros(self.K)
        mu_init = self.x0
        std_init = self.sigma * np.sqrt(self.dt)
        edges = self._get_bin_edges()

        for s_idx in range(self.K):
            lower_bound = edges[s_idx]
            upper_bound = edges[s_idx+1]
            prob = 0.0
            # if sigma is too low this breaks
            if std_init > 1e-9: 
                prob = norm.cdf(upper_bound, loc=mu_init, scale=std_init) - \
                              norm.cdf(lower_bound, loc=mu_init, scale=std_init)
            else: 
                if lower_bound <= mu_init < upper_bound:
                    prob = 1.0
            pi_values[s_idx] = prob

        pi = pi_values / np.sum(pi_values)
        return pi

    def _calculate_transition_matrix(self, T=None):
        if T is not None:
            self.dt = 1.0/T

        T_matrix = np.zeros((self.K, self.K))
        std_transition = self.sigma * np.sqrt(self.dt)
        edges = self._get_bin_edges()

        for s_cur_idx in range(self.K):
            if s_cur_idx == self.K - 1: # final index is always 1
                T_matrix[s_cur_idx, self.K - 1] = 1.0
                continue

            x_curr = self.x_values[s_cur_idx]
            mu_transition = x_curr + self.beta * self.dt
            current_row_probs = np.zeros(self.K)
            
            for s_next_idx in range(self.K):
                lower_bound = edges[s_next_idx]
                upper_bound = edges[s_next_idx+1]
                prob = 0.0
                # if sigma is too low this breaks
                if std_transition > 1e-9:
                    prob = norm.cdf(upper_bound, loc=mu_transition, scale=std_transition) - \
                                  norm.cdf(lower_bound, loc=mu_transition, scale=std_transition)
                else:
                    if lower_bound <= mu_transition < upper_bound:
                         prob = 1.0
                current_row_probs[s_next_idx] = prob
            
            sum_row_probs = np.sum(current_row_probs)
            T_matrix[s_cur_idx, :] = current_row_probs / sum_row_probs
        
        return T_matrix

    def simulate(self, Ntrials=1, T=100, get_rate=True, return_state_indices=False):
        """
        :param Ntrials: (int) number of trials

        :param T: (int) duration of each trial in number of time-steps.
        :param get_rate: whether or not to return the rate time-series
        :return:
        spikes: shape = (Ntrial, T); spikes[j] gives the spike train, n_t, in trial j, as
                an array of spike counts in each time-bin (= time step)
        xs:     shape = (Ntrial, T); xs[j] is the latent variable time-series x_t in trial j
        rates:  shape = (Ntrial, T); rates[j] is the rate time-series, r_t, in trial j (returned only if get_rate=True)
        """

        # return state indices: will return state_indices in place of xs

        self.dt = 1.0 / T
        
        init_distribution = self._calculate_initial_distribution()
        transition_matrices = self._calculate_transition_matrix()

        state_indices = np.zeros((Ntrials, T), dtype=int)
        
        for trial_idx in range(Ntrials):
            init_distribution = init_distribution / np.sum(init_distribution)
            state_indices[trial_idx, 0] = np.random.choice(self.K, p=init_distribution)
            
            for t_idx in range(T - 1):
                current_s = state_indices[trial_idx, t_idx]
                next_s_probs = transition_matrices[current_s, :].copy()
                next_s_probs = next_s_probs / np.sum(next_s_probs)
                state_indices[trial_idx, t_idx+1] = np.random.choice(self.K, p=next_s_probs)
    
        xs = self.x_values[state_indices]
        rates = self.f_io(xs)

        spikes = np.zeros_like(rates, dtype=int)
        for i in range(Ntrials):
            spikes[i,:] = self.emit(rates[i,:])

        if return_state_indices:
            xs = state_indices

        if get_rate:
            return spikes, xs, rates
        else:
            return spikes, xs



w3_utils.py
import numpy as np
import models
import scipy
import inference
from models_hmm import RampModelHMM, StepModelHMM
import matplotlib.pyplot as plt

plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})

from collections import OrderedDict as OD

np.set_printoptions(legacy='1.21') # don't show np.float; helps with debug

def ramp_LLH(data, params):
    # construct data
    defaults = {
        'K': 50,
        'Rh': 50,
        'x0': 0.2,
        'beta': 0.5,
        'sigma': 0.2,
        'T': 100,
        'filter': False
    }

    if type(params) == dict:
        params = np.array(params, dtype=object)

    def ramp_LLH_single(data, _params):

        _params = {**defaults, **_params}

        beta = _params['beta']
        sigma = _params['sigma']
        x0 = _params['x0']
        T = _params['T']
        K = _params['K']
        Rh = _params['Rh']

        ramp = RampModelHMM(beta, sigma, x0, K, Rh)
        # Calculate transition probability matrix between states
        Tmat = ramp._calculate_transition_matrix(T)
        
        # Calculate initial state distribution
        pi = ramp._calculate_initial_distribution(T)

        # Create array of firing rates for each state
        # Maps states (0 to 1) to rates (0 to Rh/T spikes per time bin)
        state_rates = np.linspace(0, 1, K) * (Rh / T)

        # Calculate log likelihood of observing spike counts given each state's rate
        # Returns matrix of log likelihoods for each timepoint and state
        LLH = inference.poisson_logpdf(data, state_rates)
        # summing here is wrong
        # LLH = np.sum(LLH, axis=0)

        # Calculate normalizing constant (log probability of the data)
        # using HMM forward algorithm
        norm = 0
        for trial_llh in LLH:
            trial_norm = inference.hmm_normalizer(pi, Tmat, trial_llh)
            norm += trial_norm

            # trial_norm ranges from ~-300 (off) to ~-200 (correct)

            # plt.matshow(np.exp(trial_llh))
            # plt.show()

        return norm

    probs_grid = np.empty_like(params, dtype=float)
    for idx, p in np.ndenumerate(params):
        probs_grid[idx] = ramp_LLH_single(data, p)

    # vllh = np.vectorize(lambda params: step_LLH_single(data, params))
    # probs_grid = vllh(params)



    return probs_grid


def step_LLH(data, params):
    # construct data
    defaults = {
        'K': 50,
        'Rh': 50,
        'x0': 0.2,
        'm': 50,
        'r': 10,
        'T': 100,
    }

    if type(params) == dict:
        params = np.array(params, dtype=object)

    def step_LLH_single(data, _params):

        _params = {**defaults, **_params}

        m = _params['m']
        if not _params['r'].is_integer():
            print('rounding down floating point r:', params['r'])

        r = int(_params['r'])
        x0 = _params['x0']
        Rh = _params['Rh']
        T = _params['T']

        K = 50


        step = StepModelHMM(m=m, r=r, x0=x0, Rh=Rh)

        Tmat = step._calculate_transition_matrix_exact(T=T)
        pi = step._calculate_initial_distribution_exact()

        # compensate by changing pi
        pi = pi.T @ np.linalg.matrix_power(Tmat, r)
        pi = pi.T

        state_rates = np.ones(int(r) + 1) * (x0 * Rh) / T
        state_rates[-1] = Rh / T

        LLH = inference.poisson_logpdf(data, state_rates)
        # LLH = np.sum(LLH, axis=0)

        norm = 0
        for trial_llh in LLH:
            trial_norm = inference.hmm_normalizer(pi, Tmat, trial_llh)
            norm += trial_norm

        return norm

    probs_grid = np.empty_like(params, dtype=float)
    for idx, p in np.ndenumerate(params):
        probs_grid[idx] = step_LLH_single(data, p)

    # vllh = np.vectorize(lambda params: step_LLH_single(data, params))
    # probs_grid = vllh(params)

    return probs_grid

def make_params_grid(specs):
    """
    Create a grid of all possible parameter combinations, where each cell is a tuple of parameters.

    Parameters:
    -----------
    specs : Ordered dict
        A dictionary where keys are parameter names and values are either:
        - A tuple `(start, stop, num)` for `np.linspace`, or
        - A list/array of explicit values.

    Returns:
    --------
    list of list of tuples
        A grid (2D list) where each cell contains a tuple of parameter values.
    dict
        A dictionary of parameter names and their generated values.
    """
    # Generate parameter values
    param_values = {}
    for param, spec in specs.items():
        if isinstance(spec, (tuple, list)) and len(spec) == 3:
            param_values[param] = np.linspace(*spec)
        else:
            param_values[param] = np.asarray(spec)

        if isinstance(spec, (float, int)):
            param_values[param] = np.array([spec])

    mesh = np.meshgrid(*param_values.values(), indexing='ij')

    grid_shape = mesh[0].shape
    param_names = list(param_values.keys())
    param_grid = np.empty(grid_shape, dtype=object)

    for indices in np.ndindex(*grid_shape):
        current_params = {list(specs.keys())[i]: mesh[i][indices] for i in range(len(param_names))}
        param_grid[indices] = current_params

    return np.squeeze(param_grid)


def get_param_values(params_grid, param_name):
    # get some named param from params grid, for testing
    return np.vectorize(lambda x: x[param_name])(params_grid)


def uniform_prior(params_grid, log=True):
    """
    Generate a uniform posterior probability grid with the same shape as params_grid.

    Parameters:
    - params_grid: numpy array of any shape
    - log: boolean, if True returns log probabilities, otherwise regular probabilities

    Returns:
    - probs_grid: numpy array with same shape as params_grid containing uniform probabilities
                  that sum to 1 (or log probabilities that sum to 1 when exponentiated)
    """
    probs_grid = np.ones_like(params_grid, dtype=float)

    probs_grid = probs_grid / probs_grid.sum()

    if log:
        probs_grid = np.log(probs_grid)

    return probs_grid


def gaussian_prior(params_grid, mu, cov, log=True):
    """
    Generate a gaussian posterior probability grid with the same shape as params_grid.

    Parameters:
    - params_grid: numpy array of any shape containing parameter dictionaries
    - mu: dict with mean values for each parameter
    - cov: 2D array or dict of parameter variances/covariances
    - log: boolean, if True returns log probabilities, otherwise regular probabilities

    Returns:
    - probs_grid: numpy array with same shape as params_grid containing probabilities
                  that sum to 1 (or log probabilities that sum to 1 when exponentiated)
    """
    shape = params_grid.shape
    sorted_mu_keys = sorted(mu.keys())
    param_names = sorted(list(params_grid.flat[0].keys()))

    varied_params = []
    for i, param in enumerate(param_names):
        if param in mu:
            varied_params.append(get_param_values(params_grid, param))

    # Convert mu dict to vector in same order as param_names
    mu_vec = np.array([mu[param] for param in sorted_mu_keys])

    # Prepare covariance matrix if provided as dict
    # also, i realised that this wouldve been cleaner if cov matrix only was allowed
    # but since the param grid dict is not ordered we have no way of knowing
    # how the order of the cov matrix corresponds, and I don't want to refactor for now

    if isinstance(cov, dict):
        cov_matrix = np.zeros((len(varied_params), len(varied_params)))
        for i, pi in enumerate(sorted_mu_keys):
            for j, pj in enumerate(sorted_mu_keys):
                key = (pi, pj) if (pi, pj) in cov else (pj, pi)
                if key not in cov:
                    if pi == pj:
                        raise ValueError(f"Covariance matrix is missing key {key}")
                    else:
                        cov[key] = 0 # assume uncorrelated

                cov_matrix[i, j] = cov[key]

    else:
        cov_matrix = cov

    # Calculate Gaussian probability density
    varied_params = np.array(varied_params)
    reshaped_params = np.moveaxis(varied_params, 0, -1).reshape(-1, len(mu_vec))

    diff = reshaped_params - mu_vec

    # exp_term =  -0.5 * np.einsum('ij, jk, ik->i', diff, np.linalg.inv(cov_matrix), diff)
    exp_term = -0.5 * np.sum((diff @ np.linalg.inv(cov_matrix)) * diff, axis=1)

    exp_term = exp_term.reshape(shape)

    probs_grid = np.exp(exp_term)
    probs_grid /= np.sum(probs_grid)

    if log:
        probs_grid = np.log(probs_grid)

    return probs_grid


def sample_from_grid(probs_grid, params_grid=None, log=True):
    if log:
        probs_grid = np.exp(probs_grid)

    flat = probs_grid.flatten()
    flat_idx = np.random.choice(len(flat), p=flat) # sample with probs grid as our dist

    idx = np.unravel_index(flat_idx, probs_grid.shape)

    if params_grid is not None:
        return params_grid[idx]

    else:
        return idx

def marginal_likelihood(llh_grid, prior_grid, log=True):
    if log:
        return scipy.special.logsumexp(llh_grid + prior_grid)

def unnorm_posterior(llh_grid, prior_grid, log=True):
    if log:
        return llh_grid + prior_grid

def norm_posterior(llh_grid, prior_grid, log=True):
    if log:
        return llh_grid + prior_grid - marginal_likelihood(llh_grid, prior_grid, log=log)

def expectation(probs_grid, params_grid, log=True):
    if log:
        probs_grid = np.exp(probs_grid)

    param_names = list(params_grid.flat[0].keys())

    dtype = [(name, float) for name in param_names]
    param_values = np.zeros(params_grid.shape, dtype=dtype)

    for param in param_names:
        param_values[param] = get_param_values(params_grid, param)

    expectations = {param: np.sum(param_values[param] * probs_grid) for param in param_names}

    return expectations


def posterior_std_dev(probs_grid, params_grid, posterior_means, log=True):
    """
    Calculate the posterior standard deviation for each parameter.

    Parameters:
    - probs_grid: numpy array, posterior probabilities (can be log probabilities).
    - params_grid: numpy array, grid of parameter dictionaries.
    - posterior_means: dict, pre-calculated posterior means for each parameter.
    - log: boolean, if True, probs_grid is in log scale.

    Returns:
    - std_devs: dict, posterior standard deviation for each parameter.
    """
    if log:
        max_log_prob = np.max(probs_grid)
        probs_grid_linear = np.exp(probs_grid - max_log_prob)
        probs_grid_linear = probs_grid_linear / np.sum(probs_grid_linear)
    else:
        probs_grid_linear = probs_grid / np.sum(probs_grid)


    param_names = list(params_grid.flat[0].keys())
    std_devs = {}

    for param in param_names:
        if param not in posterior_means: # Skip if param not in posterior_means (e.g. T, Rh, K)
            if param in params_grid.flat[0] and isinstance(params_grid.flat[0][param], (int, float)):
                 pass
            else:
                continue


        # E[X^2]
        try:
            # Vectorized extraction of param**2
            squared_values = np.array([d[param]**2 for d in params_grid.flat]).reshape(params_grid.shape)
        except TypeError:
            continue


        expected_sq_value = np.sum(squared_values * probs_grid_linear)
        
        # Variance = E[X^2] - (E[X])^2
        variance = expected_sq_value - (posterior_means[param]**2)
        
        if variance < 0:
            variance = 0.0
            
        std_devs[param] = np.sqrt(variance)
        
    return std_devs


if __name__ == "__main__":

    T = 100
    Rh = 50
    N_TRIALS = 10

    specs = OD([('m', [25, 75, 15]),
                ('r', [1, 6, 6]),
                ('T', T),
                ('Rh', Rh)])

    params_grid = make_params_grid(specs)

    step_true_params = {'m': 50, 'r': 2, 'x0': 0.2}


    data, _, _ = StepModelHMM(m=step_true_params['m'], r=step_true_params['r'], Rh=Rh).simulate_exact(Ntrials=N_TRIALS, T=T, delay_compensation=True)

    LLH_probs_grid = step_LLH(data, params_grid)
    prior_probs_grid = uniform_prior(params_grid)

    npost = norm_posterior(LLH_probs_grid, prior_probs_grid)
    plt.matshow(np.exp(npost))
    plt.show()


    print(step_true_params)
    print(expectation(npost, params_grid))

    get_param_values(params_grid, 'm')
    get_param_values(params_grid, 'r')


    '''specs = OD([('beta', [0, 1, 10]),
                ('sigma', [0, 0.5, 10]),
                ('T', T),
                ('Rh', Rh)])'''

    '''K = 25
    T_MS = 100
    RH = 500
    M_GRID = 7

    true_params = {'beta': 1.0, 'sigma': 0.2, 'x0': 0.2}

    specs = OD([
        ('beta', np.linspace(0, 4, M_GRID)),
        ('sigma', np.exp(np.linspace(np.log(0.04), np.log(4), M_GRID))),
        ('x0', true_params['x0']),
        ('K', K),
        ('T', T_MS),
        ('Rh', RH)
    ])

    params_grid = make_params_grid(specs)



    data, _, _ = RampModelHMM(beta=true_params['beta'], sigma=true_params['sigma'], Rh=RH).simulate(Ntrials=1, T=T_MS)

    LLH_probs_grid = ramp_LLH(data, params_grid)
    prior_probs_grid = uniform_prior(params_grid)

    npost = norm_posterior(LLH_probs_grid, prior_probs_grid)

    plt.matshow(np.exp(npost))
    plt.show()

    print(expectation(npost, params_grid))'''


models.py
import numpy as np
import numpy.random as npr


def lo_histogram(x, bins):
    """
    Left-open version of np.histogram with left-open bins covering the interval (left_edge, right_edge]
    (np.histogram does the opposite and treats bins as right-open.)
    Input & output behaviour is exactly the same as np.histogram
    """
    out = np.histogram(-x, -bins[::-1])
    return out[0][::-1], out[1:]


def gamma_isi_point_process(rate, shape):
    """
    Simulates (1 trial of) a sub-poisson point process (with underdispersed inter-spike intervals relative to Poisson)
    :param rate: time-series giving the mean spike count (firing rate * dt) in different time bins (= time steps)
    :param shape: shape parameter of the gamma distribution of ISI's
    :return: vector of spike counts with same shape as "rate".
    """
    sum_r_t = np.hstack((0, np.cumsum(rate)))
    gs = np.zeros(2)
    while gs[-1] < sum_r_t[-1]:
        gs = np.cumsum( npr.gamma(shape, 1 / shape, size=(2 + int(2 * sum_r_t[-1]),)) )
    y, _ = lo_histogram(gs, sum_r_t)

    return y



class StepModel():
    """
    Simulator of the Stepping Model of Latimer et al. Science 2015.
    """
    def __init__(self, m=50, r=10, x0=0.2, Rh=50, isi_gamma_shape=None, Rl=None, dt=None):
        """
        Simulator of the Stepping Model of Latimer et al. Science 2015.
        :param m: mean jump time (in # of time-steps). This is the mean parameter of the Negative Binomial distribution
                  of jump (stepping) time
        :param r: parameter r ("# of successes") of the Negative Binomial (NB) distribution of jump (stepping) time
                  (Note that it is more customary to parametrise the NB distribution by its parameter p and r,
                  instead of m and r, where p is so-called "probability of success" (see Wikipedia). The two
                  parametrisations are equivalent and one can go back-and-forth via: m = r (1-p)/p and p = r / (m + r).)
        :param x0: determines the pre-jump firing rate, via  R_pre = x0 * Rh (see below for Rh)
        :param Rh: firing rate of the "up" state (the same as the post-jump state in most of the project tasks)
        :param isi_gamma_shape: shape parameter of the Gamma distribution of inter-spike intervals.
                            see https://en.wikipedia.org/wiki/Gamma_distribution
        :param Rl: firing rate of the post-jump "down" state (rarely used)
        :param dt: real time duration of time steps in seconds (only used for converting rates to units of inverse time-step)
        """
        self.m = m
        self.r = r
        self.x0 = x0

        self.p = r / (m + r)

        self.Rh = Rh
        if Rl is not None:
            self.Rl = Rl

        self.isi_gamma_shape = isi_gamma_shape
        self.dt = dt


    @property
    def params(self):
        return self.m, self.r, self.x0

    @property
    def fixed_params(self):
        return self.Rh, self.Rl


    def emit(self, rate):
        """
        emit spikes based on rates
        :param rate: firing rate sequence, r_t, possibly in many trials. Shape: (Ntrials, T)
        :return: spike train, n_t, as an array of shape (Ntrials, T) containing integer spike counts in different
                 trials and time bins.
        """
        if self.isi_gamma_shape is None:
            # poisson spike emissions
            y = npr.poisson(rate * self.dt)
        else:
            # sub-poisson/underdispersed spike emissions
            y = gamma_isi_point_process(rate * self.dt, self.isi_gamma_shape)

        return y


    def simulate(self, Ntrials=1, T=100, get_rate=True):
        """
        :param Ntrials: (int) number of trials
        :param T: (int) duration of each trial in number of time-steps.
        :param get_rate: whether or not to return the rate time-series
        :return:
        spikes: shape = (Ntrial, T); spikes[j] gives the spike train, n_t, in trial j, as
                an array of spike counts in each time-bin (= time step)
        jumps:  shape = (Ntrials,) ; jumps[j] is the jump time (aka step time), tau, in trial j.
        rates:  shape = (Ntrial, T); rates[j] is the rate time-series, r_t, in trial j (returned only if get_rate=True)
        """
        # set dt (time-step duration in seconds) such that trial duration is always 1 second, regardless of T.
        dt = 1 / T
        self.dt = dt

        ts = np.arange(T)

        spikes, jumps, rates = [], [], []
        for tr in range(Ntrials):
            # sample jump time
            jump = npr.negative_binomial(self.r, self.p)
            jumps.append(jump)

            # first set rate at all times to pre-step rate
            rate = np.ones(T) * self.x0 * self.Rh
            # then set rates after jump to self.Rh
            rate[ts >= jump] = self.Rh
            rates.append(rate)

            spikes.append(self.emit(rate))

        if get_rate:
            return np.array(spikes), np.array(jumps), np.array(rates)
        else:
            return np.array(spikes), np.array(jumps)


class RampModel():
    """
    Simulator of the Ramping Model (aka Drift-Diffusion Model) of Latimer et al., Science (2015).
    """
    def __init__(self, beta=0.5, sigma=0.2, x0=.2, Rh=50, isi_gamma_shape=None, Rl=None, dt=None):
        """
        Simulator of the Ramping Model of Latimer et al. Science 2015.
        :param beta: drift rate of the drift-diffusion process
        :param sigma: diffusion strength of the drift-diffusion process.
        :param x0: average initial value of latent variable x[0]
        :param Rh: the maximal firing rate obtained when x_t reaches 1 (corresponding to the same as the post-step
                   state in most of the project tasks)
        :param isi_gamma_shape: shape parameter of the Gamma distribution of inter-spike intervals.
                            see https://en.wikipedia.org/wiki/Gamma_distribution
        :param Rl: Not implemented. Ignore.
        :param dt: real time duration of time steps in seconds (only used for converting rates to units of inverse time-step)
        """
        self.beta = beta
        self.sigma = sigma
        self.x0 = x0

        self.Rh = Rh
        if Rl is not None:
            self.Rl = Rl

        self.isi_gamma_shape = isi_gamma_shape
        self.dt = dt


    @property
    def params(self):
        return self.mu, self.sigma, self.x0

    @property
    def fixed_params(self):
        return self.Rh, self.Rl


    def f_io(self, xs, b=None):
        if b is None:
            return self.Rh * np.maximum(0, xs)
        else:
            return self.Rh * b * np.log(1 + np.exp(xs / b))


    def emit(self, rate):
        """
        emit spikes based on rates
        :param rate: firing rate sequence, r_t, possibly in many trials. Shape: (Ntrials, T)
        :return: spike train, n_t, as an array of shape (Ntrials, T) containing integer spike counts in different
                 trials and time bins.
        """
        if self.isi_gamma_shape is None:
            # poisson spike emissions
            y = npr.poisson(rate * self.dt)
        else:
            # sub-poisson/underdispersed spike emissions
            y = gamma_isi_point_process(rate * self.dt, self.isi_gamma_shape)

        return y


    def simulate(self, Ntrials=1, T=100, get_rate=True):
        """
        :param Ntrials: (int) number of trials
        :param T: (int) duration of each trial in number of time-steps.
        :param get_rate: whether or not to return the rate time-series
        :return:
        spikes: shape = (Ntrial, T); spikes[j] gives the spike train, n_t, in trial j, as
                an array of spike counts in each time-bin (= time step)
        xs:     shape = (Ntrial, T); xs[j] is the latent variable time-series x_t in trial j
        rates:  shape = (Ntrial, T); rates[j] is the rate time-series, r_t, in trial j (returned only if get_rate=True)
        """
        # set dt (time-step duration in seconds) such that trial duration is always 1 second, regardless of T.
        dt = 1 / T
        self.dt = dt

       # simulate all trials in parallel (using numpy arrays and broadcasting)

        # first, directly integrate/sum the drift-diffusion updates
        # x[t+1] = x[t] +  dt +  dt * randn (with initial condition x[0] = x0 +  dt * randn)
        # to get xs in shape (Ntrials, T):
        ts = np.arange(T)
        xs = self.x0 + self.beta * dt * ts + self.sigma * np.sqrt(dt) * np.cumsum(npr.randn(Ntrials, T), axis=1)
        # in each trial set x to 1 after 1st passage through 1; padding xs w 1 assures passage does happen, possibly at T+1
        taus = np.argmax(np.hstack((xs, np.ones((xs.shape[0],1)))) >= 1., axis=-1)
        xs = np.where(ts[None,:] >= taus[:,None], 1., xs)
        # # the above 2 lines are equivalent to:
        # for x in xs:
        #     if np.sum(x >= 1) > 0:
        #         tau = np.nonzero(x >= 1)[0][0]
        #         x[tau:] = 1

        rates = self.f_io(xs) # shape = (Ntrials, T)

        spikes = np.array([self.emit(rate) for rate in rates]) # shape = (Ntrial, T)

        if get_rate:
            return spikes, xs, rates
        else:
            return spikes, xs



w4_1_2_B.py
import numpy as np
import matplotlib.pyplot as plt
from collections import OrderedDict as OD
import os
import w3_2
import w3_utils

var = lambda a, b, frac: ((b-a) * frac) ** 2
mean = lambda a, b: (b+a)/2

def run_or_load_selection(filename, ramp_grid, step_grid, gen_ramp_post, gen_step_post, inf_ramp_post, inf_step_post, n_datasets, n_trials, ramp_shape=1, step_shape=1):
    if not os.path.exists(filename):
        print(f"Running model selection, saving to {filename}...")
        w3_2.model_selection(
            ramp_grid, step_grid,
            gen_ramp_post, gen_step_post, # generating
            inf_ramp_post, inf_step_post, # inference
            N_DATASETS=n_datasets, N_TRIALS=n_trials,
            ramp_gamma_shape=ramp_shape, step_gamma_shape=step_shape,
            save_to=filename
        )
    else:
        print(f"Found existing results file: {filename}")

    confmat_savename = f'plots/task_4_1_2_{os.path.basename(filename)[:-4]}_confmat.png'
    plot_title = f'Model Selection, {os.path.basename(filename)[:-4]}'
    
    ramp_accuracy, step_accuracy = w3_2.plot_confusion_matrix(filename, plot_title, save_name=confmat_savename, show=False)
    return ramp_accuracy, step_accuracy

if __name__ == "__main__":
    os.makedirs('plots', exist_ok=True)
    os.makedirs('results', exist_ok=True)
    K = 25
    T_MS = 100
    RH = 20
    M_GRID = 15
    X0 = 0.5
    N_DATASETS = 50 
    
    N_TRIALS_LIST = [10, 25, 50, 100, 200]
    STD_FRACTION_PRIOR_MISMATCH = 0.25
    SHAPE_LIKELIHOOD_MISMATCH = 3

    BETA_RANGE = (0, 4)
    SIGMA_RANGE = (0.04, 4)
    M_RANGE = (T_MS * 0.0, T_MS * 0.75)
    R_RANGE = (1, 6)

    ramp_param_specs = OD([
        ('beta', np.linspace(*BETA_RANGE, M_GRID)),
        ('sigma', np.exp(np.linspace(np.log(SIGMA_RANGE[0]), np.log(SIGMA_RANGE[1]), M_GRID))),
        ('x0', X0), ('K', K), ('T', T_MS), ('Rh', RH)
    ])
    step_param_specs = OD([
        ('m', np.linspace(*M_RANGE, M_GRID)),
        ('r', np.arange(R_RANGE[0], R_RANGE[1] + 1)),
        ('x0', X0), ('K', K), ('T', T_MS), ('Rh', RH)
    ])

    ramp_params_grid = w3_utils.make_params_grid(ramp_param_specs)
    step_params_grid = w3_utils.make_params_grid(step_param_specs)

    uniform_ramp_posterior = w3_utils.uniform_prior(ramp_params_grid)
    uniform_step_posterior = w3_utils.uniform_prior(step_params_grid)

    gauss_ramp_posterior = w3_utils.gaussian_prior(ramp_params_grid,
        mu={"beta": mean(*BETA_RANGE), "sigma": mean(*SIGMA_RANGE)},
        cov={("beta", "beta"): var(*BETA_RANGE, STD_FRACTION_PRIOR_MISMATCH),
             ("sigma", "sigma"): var(*SIGMA_RANGE, STD_FRACTION_PRIOR_MISMATCH)})

    gauss_step_posterior = w3_utils.gaussian_prior(step_params_grid,
        mu={"m": mean(*M_RANGE), "r": 1},
        cov={("m", "m"): var(*M_RANGE, STD_FRACTION_PRIOR_MISMATCH),
             ("r", "r"): var(*R_RANGE, STD_FRACTION_PRIOR_MISMATCH)})

    results = {
        'baseline': {'ramp': [], 'step': []},
        'prior_mismatch': {'ramp': [], 'step': []},
        'likelihood_mismatch': {'ramp': [], 'step': []}
    }

    for n_trials in N_TRIALS_LIST:
        print(f"--- Processing N_TRIALS = {n_trials} ---")
        # Baseline
        print("Running Baseline (Poisson, Uniform Prior)")
        fn_base = f"./results/UU_D{N_DATASETS}_shape1_T{n_trials}.csv"
        r_acc, s_acc = run_or_load_selection(fn_base, ramp_params_grid, step_params_grid, uniform_ramp_posterior, uniform_step_posterior, uniform_ramp_posterior, uniform_step_posterior, N_DATASETS, n_trials, ramp_shape=1, step_shape=1)
        results['baseline']['ramp'].append(r_acc)
        results['baseline']['step'].append(s_acc)

        # Prior Mismatch
        print(f"Running Prior Mismatch (Poisson, Gaussian Prior SF={STD_FRACTION_PRIOR_MISMATCH})")
        fn_prior = f"./results/GU_D{N_DATASETS}_T{n_trials}_SF{STD_FRACTION_PRIOR_MISMATCH}.csv"
        r_acc, s_acc = run_or_load_selection(fn_prior, ramp_params_grid, step_params_grid, uniform_ramp_posterior, uniform_step_posterior, gauss_ramp_posterior, gauss_step_posterior, N_DATASETS, n_trials, ramp_shape=1, step_shape=1)
        results['prior_mismatch']['ramp'].append(r_acc)
        results['prior_mismatch']['step'].append(s_acc)

        # Likelihood Mismatch
        print(f"Running Likelihood Mismatch (Shape={SHAPE_LIKELIHOOD_MISMATCH}, Uniform Prior)")
        fn_like = f"./results/UU_D{N_DATASETS}_shape{SHAPE_LIKELIHOOD_MISMATCH}_T{n_trials}.csv"
        r_acc, s_acc = run_or_load_selection(fn_like, ramp_params_grid, step_params_grid, uniform_ramp_posterior, uniform_step_posterior, uniform_ramp_posterior, uniform_step_posterior, N_DATASETS, n_trials, ramp_shape=SHAPE_LIKELIHOOD_MISMATCH, step_shape=SHAPE_LIKELIHOOD_MISMATCH)
        results['likelihood_mismatch']['ramp'].append(r_acc)
        results['likelihood_mismatch']['step'].append(s_acc)

    # Plotting
    plt.figure(figsize=(12, 8))
    colors = {'baseline': 'k', 'prior_mismatch': 'b', 'likelihood_mismatch': 'r'}
    linestyles = {'ramp': '--', 'step': '-'}
    
    for mismatch_type, accs in results.items():
        label_prefix = mismatch_type.replace('_', ' ').title()
        plt.plot(N_TRIALS_LIST, accs['ramp'], color=colors[mismatch_type], linestyle=linestyles['ramp'], marker='o', label=f'{label_prefix} - Ramp Acc.')
        plt.plot(N_TRIALS_LIST, accs['step'], color=colors[mismatch_type], linestyle=linestyles['step'], marker='x', label=f'{label_prefix} - Step Acc.')

    plt.title('Model Selection Accuracy vs. Number of Trials under Mismatch')
    plt.xlabel('Number of Trials')
    plt.ylabel('Accuracy')
    plt.xscale('log')
    plt.xticks(N_TRIALS_LIST, labels=N_TRIALS_LIST)
    plt.grid(True, which="both", ls="-")
    plt.legend()
    plt.ylim(0.4, 1.05)
    plt.savefig('plots/task_4_1_2_accuracy_vs_ntrials_mismatch.png')
    plt.show() 

w3_1_contours.py
import numpy as np
import matplotlib.pyplot as plt
from collections import OrderedDict as OD
import scipy.special
import os
import pickle
import concurrent.futures
from tqdm import tqdm
import argparse

import w3_utils
from models_hmm import RampModelHMM, StepModelHMM
# make text larger
plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})


def task_3_1_1_visualize_posterior_2d(model_type, true_params, n_trials, param_specs, params_grid, K=50, T=100, Rh=50,
                                      show=False):
    """
    Visualizes the 2D posterior probability for a given model with x0 fixed.
    """
    if model_type == 'ramp':
        Model, llh_func = RampModelHMM, w3_utils.ramp_LLH
        param1_name, param2_name = 'beta', 'sigma'
        xlabel, ylabel = r'$\beta$', r'$\sigma$'
    else:  # step
        Model, llh_func = StepModelHMM, w3_utils.step_LLH
        param1_name, param2_name = 'm', 'r'
        xlabel, ylabel = 'm', 'r'

    cache_dir = os.path.join("plots", "cache")
    os.makedirs(cache_dir, exist_ok=True)
    true_param_str = "-".join(
        [f"{k}_{v:.2f}" for k, v in sorted(true_params.items()) if k in [param1_name, param2_name, 'x0']])
    grid_size = len(param_specs[param1_name])
    cache_filename = os.path.join(cache_dir,
                                  f"posterior_2d_{model_type}_{true_param_str}_N{n_trials}_M{grid_size}_K{K}.pickle")

    if os.path.exists(cache_filename):
        with open(cache_filename, 'rb') as f:
            norm_post_grid = pickle.load(f)
        print(f"Loaded from cache: {cache_filename}")
    else:
        if model_type == 'ramp':
            model = Model(beta=true_params['beta'], sigma=true_params['sigma'], x0=true_params['x0'], K=K, Rh=Rh)
            data, _, _ = model.simulate(Ntrials=n_trials, T=T)
        else:  # step
            model = Model(m=true_params['m'], r=true_params['r'], x0=true_params['x0'], Rh=Rh)
            data, _, _ = model.simulate_exact(Ntrials=n_trials, T=T, delay_compensation=True)

        llh_grid = llh_func(data, params_grid)
        prior_grid = w3_utils.uniform_prior(params_grid, log=True)
        norm_post_grid = w3_utils.norm_posterior(llh_grid, prior_grid, log=True)
        with open(cache_filename, 'wb') as f:
            pickle.dump(norm_post_grid, f)
        print(f"Saved to cache: {cache_filename}")

    param1_vals = param_specs[param1_name]
    param2_vals = param_specs[param2_name]

    delta1 = param1_vals[1] - param1_vals[0]
    delta2 = param2_vals[1] - param2_vals[0]
    extent = [
        param1_vals[0] - delta1 / 2, param1_vals[-1] + delta1 / 2,
        param2_vals[0] - delta2 / 2, param2_vals[-1] + delta2 / 2
    ]

    plt.figure(figsize=(8, 6))
    plt.imshow(np.exp(norm_post_grid).T, origin='lower', aspect='auto',
               extent=extent, cmap='viridis')
    plt.colorbar(label='Posterior Probability')
    plt.scatter(true_params[param1_name], true_params[param2_name], color='red', marker='x', s=100,
                label='True Parameters')

    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.title(f'{model_type.capitalize()} Model\n2D Posterior (x0={true_params["x0"]:.2f}, N_trials={n_trials})')
    plt.legend()

    filename = f"plots/task_3_1_1_{model_type}_posterior_N{n_trials}.png"
    plt.savefig(filename)
    if show:
        plt.show()
    plt.close()


if __name__ == "__main__":
    T = 100
    Rh = 50
    N_TRIALS = 10

    # colors = ['blue', 'green', 'purple', 'orange']

    '''specs = OD([('m', [25, 75, 15]),
                ('r', [1, 6, 6]),
                ('T', T),
                ('Rh', Rh)])

    params_grid = w3_utils.make_params_grid(specs)

    step_true_params = [{'m': 35, 'r': 2, 'x0': 0.2},
                        {'m': 65, 'r': 2, 'x0': 0.2},
                        {'m': 35, 'r': 5, 'x0': 0.2},
                        {'m': 65, 'r': 5, 'x0': 0.2}]

    step_true_params = [{'m': 50, 'r': 2, 'x0': 0.2}]'''

    specs = OD([
        ('beta', np.linspace(0, 4, 10)),
        ('sigma', np.exp(np.linspace(np.log(0.04), np.log(4), 10))),
        ('x0', 0.2)
    ])

    params_grid = w3_utils.make_params_grid(specs)
    '''ramp_true_params = [{'beta': 0.75, 'sigma': 0.75, 'x0': 0.2},
                        {'beta': 2, 'sigma': 0.75, 'x0': 0.2},
                        {'beta': 3.25, 'sigma': 0.75, 'x0': 0.2},
                        {'beta': 0.75, 'sigma': 2, 'x0': 0.2},
                        {'beta': 2, 'sigma': 2, 'x0': 0.2},
                        {'beta': 3.25, 'sigma': 2, 'x0': 0.2},
                        {'beta': 0.75, 'sigma': 3.75, 'x0': 0.2},
                        {'beta': 2, 'sigma': 3.75, 'x0': 0.2},
                        {'beta': 3.25, 'sigma': 3.75, 'x0': 0.2}
                        ]'''
    '''ramp_true_params = [{'beta': 0.75, 'sigma': 0.5, 'x0': 0.2},
                        {'beta': 3, 'sigma': 0.5, 'x0': 0.2},
                        {'beta': 0.75, 'sigma': 2, 'x0': 0.2},
                        {'beta': 3, 'sigma': 2, 'x0': 0.2}]'''

    ramp_true_params = [
        params_grid[2, 2],
        params_grid[2, 7],
        params_grid[7, 7],
        params_grid[7, 2]
    ]

    posteriors = []
    expectations = []
    for tp in ramp_true_params: #
        print(tp)
        #
        data, _, _ = RampModelHMM(beta=tp['beta'], sigma=tp['sigma'], Rh=Rh).simulate(Ntrials=N_TRIALS,
                                                                                                          T=T)
        LLH_probs_grid = w3_utils.ramp_LLH(data, params_grid) #
        prior_probs_grid = w3_utils.uniform_prior(params_grid)

        npost = w3_utils.norm_posterior(LLH_probs_grid, prior_probs_grid)

        posteriors.append(npost)
        expectations.append(w3_utils.expectation(npost, params_grid))


    # TODO change
    m_values = w3_utils.get_param_values(params_grid, 'beta')
    r_values = w3_utils.get_param_values(params_grid, 'sigma')


    plt.figure(figsize=(10 * 0.75, 8 * 0.75))

    for idx, npost in enumerate(posteriors):
        cs = plt.contour(m_values, r_values, np.exp(npost), levels=5, cmap='Reds')

        # plt.clabel(cs, inline=1, fontsize=10)
    plt.colorbar(label='Posterior Probability')

    plt.xlabel('beta')
    plt.ylabel('sigma')
    plt.title('Posterior probabilities - Ramp model, Trials = ' + str(N_TRIALS))
    for i, exp in enumerate(expectations):
        true_point = (ramp_true_params[i]['beta'], ramp_true_params[i]['sigma'])
        exp_point = (exp['beta'], exp['sigma'])

        # Plot points
        plt.scatter(true_point[0], true_point[1],
                    color='red', marker='x', s=100,
                    label='True Parameters' if i == 0 else None)

        plt.scatter(exp_point[0], exp_point[1],
                    color='blue', marker='o', s=100,
                    label='Expected Parameters' if i == 0 else None)

        # Calculate Euclidean distance
        euc_dist = np.sqrt((true_point[0] - exp_point[0]) ** 2 +
                           (true_point[1] - exp_point[1]) ** 2)

        # Draw line between points
        plt.plot([true_point[0], exp_point[0]],
                 [true_point[1], exp_point[1]],
                 'k--', alpha=0.5)

        # Add distance label at the middle of the line
        mid_x = (true_point[0] + exp_point[0]) / 2
        mid_y = (true_point[1] + exp_point[1]) / 2
        plt.annotate(f'{euc_dist:.2f}',
                     (mid_x, mid_y),
                     xytext=(5, 5),
                     textcoords='offset points')

plt.legend()

plt.show()


w3_12_confmats_plots.py
import numpy as np
import matplotlib.pyplot as plt
from collections import OrderedDict as OD
import scipy.special
import os
import scipy
from scipy.interpolate import griddata
import w3_2
import w3_utils
from models_hmm import RampModelHMM
import torch
import torch.nn as nn
import torch.optim as optim
import sklearn
import multiprocessing
from tqdm import tqdm
import pandas as pd
from ML_models import StepRampClassifier, compute_summary_statistics
from models_hmm import RampModelHMM, StepModelHMM

# Define the files and their corresponding sigma_frac values
files = [
    "C:/Users/henry/Github/gg3_shared/results/0.5GU_D240_T3.csv",
    "C:/Users/henry/Github/gg3_shared/results/0.25GU_D240_T3.csv",
    "C:/Users/henry/Github/gg3_shared/results/0.125GU_D240_T3.csv",
    "C:/Users/henry/Github/gg3_shared/results/UU_D240_T3.csv"
]
sigma_fracs = [0.5, 0.25, 0.125, 0]  # Corresponding sigma_frac values

step_accs = []
ramp_accs = []

# Process each file
for fn in files:
    step_acc, ramp_acc = w3_2.plot_confusion_matrix(fn,
                       f'Confusion matrix, sigma_frac = {sigma_fracs[files.index(fn)]}',
                       save_name=fn.replace('.csv', '.png'),
                       fig_size_factor=0.8)
    
    step_accs.append(step_acc)
    ramp_accs.append(ramp_acc)

# Plot results
plt.figure(figsize=(10 * 0.8, 5 * 0.8))

# Plot ramp (dashed) and step (solid) accuracies
plt.plot(sigma_fracs, ramp_accs, 'k--', label='ramp')  # black dashed
plt.plot(sigma_fracs, step_accs, 'k-', label='step')   # black solid

plt.title('Classification accuracy vs sigma_frac')
plt.xlabel('sigma_frac')
plt.ylabel('Classification accuracy')
plt.legend()

plt.show()

w4_1_B.py
import numpy as np
import matplotlib.pyplot as plt
from collections import OrderedDict as OD
import os
import w3_2
import w3_utils

if __name__ == "__main__":
    os.makedirs('plots', exist_ok=True)
    os.makedirs('results', exist_ok=True)
    K = 25
    T_MS = 100
    RH = 20
    M_GRID = 15
    X0 = 0.5
    N_DATASETS = 50 
    N_TRIALS = 25

    BETA_RANGE = (0, 4)
    SIGMA_RANGE = (0.04, 4)

    M_RANGE = (T_MS * 0.25, T_MS * 0.75)
    R_RANGE = (1, 6)

    ramp_param_specs = OD([
        ('beta', np.linspace(*BETA_RANGE, M_GRID)),
        ('sigma', np.exp(np.linspace(np.log(SIGMA_RANGE[0]),
                                     np.log(SIGMA_RANGE[1]),
                                     M_GRID))),
        ('x0', X0),
        ('K', K),
        ('T', T_MS),
        ('Rh', RH)
    ])

    step_param_specs = OD([
        ('m', np.linspace(*M_RANGE, M_GRID)),
        ('r', np.arange(R_RANGE[0], R_RANGE[1] + 1)),
        ('x0', X0),
        ('K', K),
        ('T', T_MS),
        ('Rh', RH)
    ])

    ramp_params_grid = w3_utils.make_params_grid(ramp_param_specs)
    step_params_grid = w3_utils.make_params_grid(step_param_specs)

    uniform_ramp_posterior = w3_utils.uniform_prior(ramp_params_grid)
    uniform_step_posterior = w3_utils.uniform_prior(step_params_grid)

    shape_values = [1, 2, 3, 4, 5]
    
    accuracies = {'ramp': [], 'step': []}

    for shape in shape_values:
        print(f"Running model selection for shape = {shape}")
        fn = f"./results/UU_D{N_DATASETS}_shape{shape}_T{N_TRIALS}.csv"
        
        if not os.path.exists(fn):
            w3_2.model_selection(
                ramp_params_grid, step_params_grid,
                uniform_ramp_posterior, uniform_step_posterior,  # generating
                uniform_ramp_posterior, uniform_step_posterior,  # inference
                N_DATASETS=N_DATASETS, N_TRIALS=N_TRIALS,
                ramp_gamma_shape=shape, step_gamma_shape=shape,
                save_to=fn
            )
        else:
            print(f"Results file already exists: {fn}")

        heatmap_savename = f'plots/task_4_1_1_shape{shape}_heatmap.png'
        confmat_savename = f'plots/task_4_1_1_shape{shape}_confmat.png'
        plot_title = f'Uniform prior, shape={shape}, {N_TRIALS} trials/dataset'
        
        w3_2.plot_heatmap(fn, plot_title, save_name=heatmap_savename, show=False)
        ramp_accuracy, step_accuracy = w3_2.plot_confusion_matrix(fn, plot_title, save_name=confmat_savename, show=False)
        accuracies['ramp'].append(ramp_accuracy)
        accuracies['step'].append(step_accuracy)

    # Plot results
    plt.figure(figsize=(10, 6))
    plt.plot(shape_values, accuracies['ramp'], 'o-', label='Ramp Model Accuracy')
    plt.plot(shape_values, accuracies['step'], 'x--', label='Step Model Accuracy')
    
    avg_accuracy = (np.array(accuracies['ramp']) + np.array(accuracies['step'])) / 2
    plt.plot(shape_values, avg_accuracy, 's-.', label='Overall Accuracy')

    plt.title(f'Model Selection Accuracy vs. Gamma Shape Parameter (N_trials={N_TRIALS})')
    plt.xlabel('Gamma Shape Parameter')
    plt.ylabel('Accuracy')
    plt.xticks(shape_values)
    plt.grid(True)
    plt.legend()
    plt.ylim(0, 1.05)
    plt.savefig('plots/task_4_1_1_accuracy_vs_shape.png')
    plt.show() 

task_2_3.py
import numpy as np
import models
import scipy
import inference
from models_hmm import RampModelHMM, StepModelHMM
import matplotlib.pyplot as plt
# make text larger
plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})

K = 50 
Rh = 100
x0 = 0.2
beta = 0.5
T = 100
filter = True


np.set_printoptions(legacy='1.25') # don't show np.float; helps with debug


def ramp_HMM_inference(model_parameters=None, test_filtering=False):
    defaults = {
        'K': 50,
        'Rh': 100,
        'x0': 0.2,
        'beta': 0.5,
        'sigma': 0.2,
        'T': 100,
        'filter': False
    }

    if model_parameters is None:
        model_parameters = {}

    params = {**defaults, **model_parameters}

    # Extract parameters (could also just use params['K'], etc. in your code)
    K = params['K']
    Rh = params['Rh']
    x0 = params['x0']
    beta = params['beta']
    T = params['T']
    sigma = params['sigma']
    filter = params['filter']

    ramp = RampModelHMM(beta, sigma, x0, K, Rh)
    ramp_spikes, states, rates = ramp.simulate(Ntrials=1, T=T, return_state_indices=True)
    Tmat = ramp._calculate_transition_matrix(T)
    pi = ramp._calculate_initial_distribution(T)

    state_rates = np.linspace(0, 1, K) * (Rh / T)

    LLH = inference.poisson_logpdf(ramp_spikes, state_rates)
    LLH = np.sum(LLH, axis=0)

    ex, norm = inference.hmm_expected_states(pi, Tmat, LLH, filter=False)
    expected_s = ex @ np.arange(K)  # this is expected s_t

    if test_filtering:
        fex, fnorm = inference.hmm_expected_states(pi, Tmat, LLH, filter=True)
        fexpected_s = fex @ np.arange(K)  # this is expected s_t
        return ex, fex, expected_s, fexpected_s, states.flatten()

    return ex, expected_s, states.flatten()


def step_HMM_inference(model_parameters=None, test_filtering=False, compress_states=False):
    defaults = {
        'K': 50,
        'Rh': 100,
        'x0': 0.2,
        'm': 50,
        'r': 10,
        'T': 100,
    }

    if model_parameters is None:
        model_parameters = {}

    params = {**defaults, **model_parameters}

    # Extract parameters (could also just use params['K'], etc. in your code)
    # K = params['K']
    m = params['m']
    r = params['r']
    x0 = params['x0']
    Rh = params['Rh']
    T = params['T']

    step = StepModelHMM(m=m, r=r, x0=x0, Rh=Rh)

    Tmat = step._calculate_transition_matrix_exact()
    pi = step._calculate_initial_distribution_exact()

    step_spikes, jumps, states = step.simulate_exact(T=T, return_state_indices=True)

    state_rates = np.ones(int(r) + 1) * (x0 * Rh) / T
    state_rates[-1] = Rh/T

    LLH = inference.poisson_logpdf(step_spikes, state_rates)
    LLH = np.sum(LLH, axis=0)

    ex, norm = inference.hmm_expected_states(pi, Tmat, LLH, filter=False)

    if compress_states: # compress all non-up states into one state, so ex will always be 2.
        ex = np.hstack((
            np.sum(ex[:, :-1], axis=1, keepdims=True),
            ex[:, -1:]
        ))

        states = np.hstack((
            np.sum(states[:, :-1], axis=1, keepdims=True),
            states[:, -1:]
        ))

    posterior_rate_binary = (ex[:, -1] >= 0.5).astype(int)

    if test_filtering:
        fex, fnorm = inference.hmm_expected_states(pi, Tmat, LLH, filter=True)
        fposterior_rate_binary = (fex[:, -1] >= 0.5).astype(int)

        if compress_states:
            fex = np.hstack((
                np.sum(fex[:, :-1], axis=1, keepdims=True),
                fex[:, -1:]
            ))

        return ex, fex, posterior_rate_binary, fposterior_rate_binary, states.flatten()
    return ex, posterior_rate_binary, states.flatten()

def compress_states(arr):
    # sum the first n-1 cols along axis 1, keep the last col the same. shape (n, m) -> (n, 2)
    # if 1d array is passed we assume n=1

    if arr.ndim == 1:
        arr = np.array([arr])

    return np.hstack((
                np.sum(arr[:, :-1], axis=1, keepdims=True),
                arr[:, -1:]
            ))

def cross_entropy(ex, true_s, base=2, time_average=False, time_sum=False):
    assert ex.shape[0] == len(true_s)

    # delta_indices = np.column_stack((np.arange(ex.shape[0]), true_s))
    true_dist = np.zeros(ex.shape)
    # ind = np.vstack((np.arange(ex.shape[0]), true_s))
    true_dist[np.arange(ex.shape[0]), true_s.astype(int)] = 1 # true_s + 1???

    CE = scipy.stats.entropy(true_dist, base=base, axis=1) + scipy.stats.entropy(true_dist, ex, base=base, axis=1)

    if time_average:
        return np.average(CE)

    if time_sum:
        return np.sum(CE)

    return CE


if __name__ == "__main__":
    trials = 500
    trials_to_plot = 5
    T = 100
    r=10

    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8),
                                   gridspec_kw={'height_ratios': [4, 1]})

    CE_sum = np.zeros(T)

    colors = plt.cm.coolwarm(np.linspace(1, 0, trials_to_plot))

    for trial in range(trials):
        ex, bpred_s, states = step_HMM_inference({
            'r': r,
            'T': T,
            'sigma': 0.35
        }, compress_states=False)

        bex = compress_states(ex)
        bstates = (states == r).astype(int)

        CE_sum += cross_entropy(bex, bstates) # use binary cross entropy as distinguishing between individual MC's "does not matter"

        # Main plot (top)
        # ax1.matshow(ex.T)

        if trial < trials_to_plot:
            alpha = 1 if trial == 0 else 0.25
            color = colors[trial]
            color = 'black' if trial == 0 else color

            #ax1.plot(np.arange(T), bpred_s, color=color, linestyle="dashed",
            #         label=f'Trial {trial + 1} (Predicted)', alpha=alpha)
            ax1.plot(np.arange(T), states, color=color, label=f'Trial {trial + 1} (True)', alpha=alpha)
            # plot prediction marker

            first_pred_index = np.argmax(bpred_s == 1) if np.any(bpred_s==1) else None

            if first_pred_index is not None:
                ax1.scatter(first_pred_index, states[first_pred_index],
                            color=color, marker='d', s=100, alpha=alpha,
                            label=f'Predicted Jump Time (Trial {trial + 1})',
                            zorder=3)

            '''if trial == 1: # plot mode
                modes = np.argmax(ex, axis=1) # + 1
                ax1.plot(np.arange(T), modes, color=color, label=f'Trial {trial + 1} (Mode)', alpha=alpha, linestyle='dotted')
'''
        print('completed', trial)

    # Cross-entropy plot (bottom)
    ax2.plot(np.arange(T), CE_sum / trials, color='black', linewidth=2)
    ax2.set_xlabel('Time')
    ax2.set_ylabel('Cross-Entropy')
    ax2.set_title('Average Cross-Entropy Over Time (' + str(trials) + ' trials)')

    # Add legend to the top plot (reduce redundancy with a single entry per trial)
    handles, labels = ax1.get_legend_handles_labels()
    unique_labels = dict(zip(labels, handles))  # Remove duplicates
    ax1.set_title("Markov state (s) over time")
    ax1.set_ylabel("Markov state (proportional to rate)")
    ax1.legend(unique_labels.values(), unique_labels.keys(),
               loc='best', ncol=2, framealpha=0.5)

    plt.tight_layout()
    plt.savefig('./plots/step_inference_traces_mode.png')


w3_23.py
import numpy as np
import matplotlib.pyplot as plt
from collections import OrderedDict as OD
import scipy.special
import os
import scipy
from scipy.interpolate import griddata
import w3_2
import w3_utils
from models_hmm import RampModelHMM
import torch
import torch.nn as nn
import torch.optim as optim
import sklearn
import multiprocessing
from tqdm import tqdm
import pandas as pd
from ML_models import StepRampClassifier, compute_summary_statistics
from models_hmm import RampModelHMM, StepModelHMM



def _model_selection_worker_with_14(args):
    """Helper function for parallel execution in model_selection."""
    (ramp_params_grid, step_params_grid, gen_ramp, gen_step, ramp_post, step_post,
     N_TRIALS_RAMP, ramp_gamma_shape, step_gamma_shape, N_TRIALS_STEP, model, scaler) = args

    ramp_params = w3_utils.sample_from_grid(gen_ramp, ramp_params_grid)
    ramp_data, _, _ = RampModelHMM(beta=ramp_params['beta'],
                                   sigma=ramp_params['sigma'],
                                   Rh=ramp_params['Rh'],
                                   x0=ramp_params['x0'] if 'x0' in ramp_params else 0.2,
                                   isi_gamma_shape=ramp_gamma_shape
                                   ).simulate(Ntrials=N_TRIALS_RAMP, T=ramp_params['T'])

    ramp_LLH_ramp = w3_utils.ramp_LLH(ramp_data, ramp_params_grid)
    step_LLH_ramp = w3_utils.step_LLH(ramp_data, step_params_grid)

    ramp_bf_ramp = w3_utils.marginal_likelihood(ramp_LLH_ramp, ramp_post)
    step_bf_ramp = w3_utils.marginal_likelihood(step_LLH_ramp, step_post)

    step_params = w3_utils.sample_from_grid(gen_step, step_params_grid)
    step_data, _, _ = StepModelHMM(m=step_params['m'],
                                   r=step_params['r'],
                                   Rh=step_params['Rh'],
                                   x0=step_params['x0'] if 'x0' in step_params else 0.2,
                                   isi_gamma_shape=step_gamma_shape
                                   ).simulate_exact(Ntrials=N_TRIALS_STEP, T=step_params['T'])

    ramp_LLH_step = w3_utils.ramp_LLH(step_data, ramp_params_grid)
    step_LLH_step = w3_utils.step_LLH(step_data, step_params_grid)

    ramp_bf_step = w3_utils.marginal_likelihood(ramp_LLH_step, ramp_post)
    step_bf_step = w3_utils.marginal_likelihood(step_LLH_step, step_post)

    # ML
    batch_size = 20
    if N_TRIALS_RAMP < batch_size:
        batch_size = N_TRIALS_RAMP
        num_batches = 1
    else:
        num_batches = N_TRIALS_RAMP // batch_size

    for i_dataset in range(num_batches):
        # print(step_spikes[i_dataset].shape)
        X_step = compute_summary_statistics(step_data[i_dataset * batch_size:(i_dataset+1) * batch_size], batch_size)
        X_ramp = compute_summary_statistics(ramp_data[i_dataset * batch_size:(i_dataset+1) * batch_size], batch_size)

        X_step = scaler.transform(X_step)
        X_ramp = scaler.transform(X_ramp)

        X_step = torch.FloatTensor(X_step)
        X_ramp = torch.FloatTensor(X_ramp)

        model.eval()  # Set model to evaluation mode

        with torch.no_grad():
            # ramp is 1, so should be positive = ramp prediction, I think
            step_outputs = model(X_step).numpy()

            epsilon = 1e-3  # Small constant (e.g., machine epsilon)
            step_outputs = np.clip(step_outputs, epsilon, 1 - epsilon)
            LLR_step = np.sum(np.log(step_outputs)) - np.sum(np.log(1 - step_outputs))

            ramp_outputs = model(X_ramp).numpy()

            epsilon = 1e-3  # Small constant (e.g., machine epsilon)
            ramp_outputs = np.clip(ramp_outputs, epsilon, 1 - epsilon)
            LLR_ramp = np.sum(np.log(ramp_outputs)) - np.sum(np.log(1 - ramp_outputs))

            # print('STEP', LLR_step, 'RAMP', LLR_ramp)

    return {
        'beta': ramp_params['beta'],
        'sigma': ramp_params['sigma'],
        'ramp_data_ramp_bf': ramp_bf_ramp,
        'ramp_data_step_bf': step_bf_ramp,
        'm': step_params['m'],
        'r': step_params['r'],
        'step_data_ramp_bf': ramp_bf_step,
        'step_data_step_bf': step_bf_step,
        'ML_LLR_step': LLR_step,
        'ML_LLR_ramp': LLR_ramp
    }


def model_selection_with_14(ramp_params_grid, step_params_grid, gen_ramp, gen_step, ramp_post, step_post,
                    N_DATASETS=100, N_TRIALS=100, ramp_gamma_shape=None, step_gamma_shape=None, save_to=None):
    """
    Run simulation and save model comparison results
    Also test against 1.4 ad-hoc ML method

    Parameters:
    -----------
    ramp_params_grid: dict
        Grid of parameters for ramp model
    step_params_grid: dict
        Grid of parameters for step model
    gen_ramp: function
        PDF grid for ramp data
    gen_step: function
        PDF grid for step data
    ramp_post: array-like
        Ramp model posterior
    step_post: array-like
        Step model posterior
    N_DATASETS: int
        Number of datasets to generate
    N_TRIALS: int
        Number of trials per dataset
    ramp_gamma_shape: float, optional
        Shape parameter for ramp model ISI gamma distribution
    step_gamma_shape: float, optional
        Shape parameter for step model ISI gamma distribution
    save_to: str, optional
        Path to save results CSV file
    """

    results = {
        'beta': [], 'sigma': [],
        'ramp_data_ramp_bf': [], 'ramp_data_step_bf': [],
        'm': [], 'r': [],
        'step_data_ramp_bf': [], 'step_data_step_bf': [],
        'ML_LLR_step': [], 'ML_LLR_ramp': []
    }




    save_path = './results/StepRampClassifier.pth'
    checkpoint = torch.load(save_path, weights_only=False)
    model = StepRampClassifier(input_dim=60)  # Use the same architecture as before
    model.load_state_dict(checkpoint['model_state_dict'])

    scaler = checkpoint['scaler_state']
    model.eval()

    worker_args = [(ramp_params_grid, step_params_grid, gen_ramp, gen_step, ramp_post, step_post,
                    N_TRIALS, ramp_gamma_shape, step_gamma_shape, N_TRIALS, model, scaler) for _ in range(N_DATASETS)]

    # pool_results = [_model_selection_worker_with_14(worker_args[0])]
    # uncomment this line to step through with debuggers

    with multiprocessing.Pool() as pool:
        pool_results = list(tqdm(pool.imap_unordered(_model_selection_worker_with_14, worker_args), total=N_DATASETS))

    for res in pool_results:
        for key in results:
            results[key].append(res[key])

    if save_to:
        results_df = pd.DataFrame(results)
        os.makedirs(os.path.dirname(save_to), exist_ok=True)
        results_df.to_csv(save_to, index=False)

    return results


var = lambda a, b, frac: ((b-a) * frac) ** 2
mean = lambda a, b: (b+a)/2

if __name__ == "__main__":
    K = 25
    T_MS = 100

    M_GRID = 15

    RH = 50
    X0 = 0.5
    N_TRIALS= 10 # new standard

    N_DATASETS = 60 # TODO make this big

    # STD_FRACTION = 0.25

    BETA_RANGE = (0, 4)
    SIGMA_RANGE = (0.04, 4)

    M_RANGE = (T_MS * 0.25, T_MS * 0.75)
    R_RANGE = (1, 6)

    ramp_param_specs = OD([
        ('beta', np.linspace(*BETA_RANGE, M_GRID)),
        ('sigma', np.exp(np.linspace(np.log(SIGMA_RANGE[0]),
                                     np.log(SIGMA_RANGE[1]),
                                     M_GRID))),
        ('x0', X0),
        ('K', K),
        ('T', T_MS),
        ('Rh', RH)
    ])

    step_param_specs = OD([('m', list(M_RANGE) + [M_GRID]),
                ('r', list(R_RANGE) + [6]),
                ('x0', X0),
                ('K', K),
                ('T', T_MS),
                ('Rh', RH)])

    ramp_params_grid = w3_utils.make_params_grid(ramp_param_specs)
    step_params_grid = w3_utils.make_params_grid(step_param_specs)

    uniform_ramp_posterior = w3_utils.uniform_prior(ramp_params_grid)
    uniform_step_posterior = w3_utils.uniform_prior(step_params_grid)

    STD_FRACTION = 0.25

    gauss_ramp_posterior = w3_utils.gaussian_prior(
        ramp_params_grid,
        mu={
            "beta": mean(*BETA_RANGE),
            "sigma": mean(*SIGMA_RANGE)
        },
        cov={
            ("beta", "beta"): var(*BETA_RANGE, STD_FRACTION),
            ("sigma", "sigma"): var(*SIGMA_RANGE, STD_FRACTION)
        })

    gauss_step_posterior = w3_utils.gaussian_prior(
        step_params_grid,
        mu={
            "m": mean(*M_RANGE),
            "r": 1
        },
        cov={
            ("m", "m"): var(*M_RANGE, STD_FRACTION),
            ("r", "r"): var(*R_RANGE, STD_FRACTION)
        })






    # TEST 1

    fn = "./results/0.25GGML_D" + str(N_DATASETS) + "_T" + str(N_TRIALS) + ".csv"

    model_selection_with_14(
        ramp_params_grid, step_params_grid,
        gauss_ramp_posterior, gauss_step_posterior, # generating
        gauss_ramp_posterior, gauss_step_posterior, # inference
        N_DATASETS=N_DATASETS, N_TRIALS=N_TRIALS,
        # format: generating: G/U; inference: G/U; n. datasets, n. trials
        # if G, append std_fraction on front
        save_to=os.path.join(os.getcwd(), fn)
    )

    w3_2.plot_heatmap(fn, r'Heatmap (Gaussian sampling + posterior, $\sigma_{frac} = 0.25$)',
                      save_name=os.path.join(os.getcwd(), f'plots/task_3_2_3_{os.path.basename(fn)[:-4]}_heatmap.png'))
    w3_2.plot_confusion_matrix(fn, r'Confusion Matrix (Gaussian sampling + posterior, $\sigma_{frac} = 0.25$)',
                               save_name=os.path.join(os.getcwd(), f'plots/task_3_2_3_{os.path.basename(fn)[:-4]}_confmat.png'))

    # exit()

2_3_ramp_contours.py
import numpy as np
import models
import scipy
import inference
from models_hmm import RampModelHMM
import os
import matplotlib.pyplot as plt

import task_2_3

np.set_printoptions(legacy='1.25') # don't show np.float; helps with debug

plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})


if __name__ == "__main__":
    num_trials = 600
    num_samples = 15 # on the grid
    K = 50
    save_filename = "./results/CE_step_15x0x15Rh.npy" # TODO
    recompute = True

    # TODO
    T = 100
    ms = np.linspace(T * 0.1, T * 0.75, num_samples)
    rs = np.rint(np.linspace(0, 20, num_samples+1))[1:]
    # betas = np.linspace(0, 4, num_samples)
    # sigmas = np.linspace(0, 4, num_samples)
    x0s = np.linspace(0.2, 1, num_samples)
    Rhs = np.linspace(0, 500, num_samples)

    # TODO changeme
    ivar1 = x0s # x-axis
    ivar2 = Rhs

    # if os.path.exists(save_filename) and not recompute:
    #     print("loading " + save_filename)
    #     CE_mat = np.load(save_filename)
    # else:
    #     print("computing")
    #     CE_mat = np.zeros((num_samples, num_samples))

    #     for i1, iv1 in enumerate(ivar1):
    #         for i2, iv2 in enumerate(ivar2):
    #             sum_CE = 0
    #             for _ in range(num_trials):
    #                 ex, expected_s, states = task_2_3.step_HMM_inference({ # TODO
    #                     #"m": iv1,
    #                     "r": 10,
    #                     'x0': iv1,
    #                     'Rh': iv2,
    #                     #"beta": b,
    #                     #"sigma": s,
    #                     "K": K,
    #                 })
    #                 bex = task_2_3.compress_states(ex)
    #                 bstates = (states == 10).astype(int) # TODO if r, set == r

    #                 # we probably want to plot the TOTAL cross-entropy in this case

    #                 sum_CE += task_2_3.cross_entropy(bex, bstates, time_average=True)
    #             CE_mat[i1, i2] = sum_CE / num_trials
    #         print(f'Progress: {i1 + 1}/{num_samples} (beta)')

    #     np.save(save_filename, CE_mat)
    #     print(f"saved to {save_filename}")

    # '''# matshow
    # plt.matshow(CE_mat)
    # plt.show()'''

    # # tricontour
    # iv1_grid, iv2_grid = np.meshgrid(ivar1, ivar2, indexing='ij')
    # iv1_flat = iv1_grid.flatten()
    # iv2_flat = iv2_grid.flatten()
    # CE_flat = CE_mat.flatten()

    # os.makedirs('plots', exist_ok=True)


    # plt.figure(figsize=(8, 6))
    # contour = plt.tricontourf(iv1_flat, iv2_flat, CE_flat, levels=20, cmap='viridis')
    # plt.colorbar(contour, label='Cross-Entropy (CE)')
    # plt.xlabel('x0') # TODO
    # plt.ylabel('Rh') # TODO
    # plt.title(r'Step model - BCE for varying $x_0, Rh$') # TODO
    # plt.savefig('plots/task_2_3_ramp_contours_contour.png')
    # plt.show()

    # plt.matshow(CE_mat)
    # plt.savefig('plots/task_2_3_ramp_contours_matshow.png')
    # plt.show()


    # Step version (Rh vs x0)

    num_trials = 100
    num_samples = 15
    T = 250
    recompute = False

    x0s = np.linspace(0.0, 1, num_samples)
    Rhs = np.linspace(10, 2000, num_samples)

    # fixed params
    r = 10
    m = 40
    Rh_lim = (min(Rhs), max(Rhs))
    x0_lim = (min(x0s), max(x0s))
    save_filename = f"./results/step_CE_heatmap_Rh{Rh_lim[0]}-{Rh_lim[1]}_x0{x0_lim[0]}-{x0_lim[1]}_r{r}_m{m}.npy"

    if os.path.exists(save_filename) and not recompute:
        CE_mat = np.load(save_filename)
    else:
        CE_mat = np.zeros((num_samples, num_samples))

        for i, rh in enumerate(Rhs):
            for j, x0 in enumerate(x0s):
                sum_mean_CE = 0
                for _ in range(num_trials):
                    ex, _, states = task_2_3.step_HMM_inference({
                        "r": r,
                        "m": m,
                        "T": T,
                        "x0": x0,
                        "Rh": rh,
                    })
                    bex = task_2_3.compress_states(ex)
                    bstates = (states == r).astype(int)
                    ce_series = task_2_3.cross_entropy(bex, bstates)
                    sum_mean_CE += np.mean(ce_series)
                
                CE_mat[i, j] = sum_mean_CE / num_trials
            print(f'Progress: {i + 1}/{num_samples} (Rh)')

        np.save(save_filename, CE_mat)
        print(f"saved to {save_filename}")

    iv1_grid, iv2_grid = np.meshgrid(x0s, Rhs, indexing='ij')
    iv1_flat = iv1_grid.flatten()
    iv2_flat = iv2_grid.flatten()
    CE_flat = CE_mat.T.flatten() 

    plt.figure(figsize=(8, 6))
    contour = plt.tricontourf(iv1_flat, iv2_flat, CE_flat, levels=20, cmap='viridis_r')
    plt.colorbar(contour, label='Mean Cross-Entropy')
    plt.xlabel('x0')
    plt.ylabel('Rh')
    plt.title(r'Step model - BCE for varying $x_0, Rh$ (m=40, r=10)') # TODO
    plt.savefig('./plots/task_2_3_step_CE_contour_Rh_x0.png')
    plt.show()

task_2_2.py
import numpy as np
import matplotlib.pyplot as plt
import models_hmm
import numpy.random as npr
# make text larger
plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})

T=1000
m = T/2
x0 = 0.2
Rh = 50
bin_edges=np.linspace(0,1000,20)
num_trajectories=5
colors = ['blue', 'orange', 'green', 'red']

# plot trajectories and jump time histograms for simple 2-state model
# jumps histograms for simulate_2state should look like the 
# Week 1 histograms that have r=1 since Geom(p) = NB(1,p).
fig1 = plt.figure()
fig2 = plt.figure()
rs = np.linspace(1, 10, 4, dtype=int)
i=0
for r in rs:
    step = models_hmm.StepModelHMM(m, r, x0, Rh)
    spikes, jumps, rates = step.simulate_2state(Ntrials=100, T=T)
    color = colors[i]
    plt.figure(fig1.number)
    for j in range(num_trajectories):
        if j==0:
            label = 'r='+str(r)
        else:
            label=None
        plt.plot(rates[j], color=color, label=label)
    plt.figure(fig2.number)
    plt.hist(jumps, bins=bin_edges, alpha=0.5, label='r='+str(r))
    i+=1

plt.figure(fig1.number)
plt.xlabel('Time (ms)')
plt.ylabel('Firing Rate (Hz)')
plt.title('m=' + str(np.round(m)))
plt.legend()

plt.figure(fig2.number)
plt.xlabel('Jump Time (ms)')
plt.ylabel('Frequency')
plt.title('m=' + str(np.round(m)))
plt.legend()

plt.show()

# plot trajectories and jump time histograms for exact model with r+1 states
fig1 = plt.figure()
fig2 = plt.figure()
rs = np.linspace(1,100,4, dtype=int)
i = 0
for r in rs:
    step = models_hmm.StepModelHMM(m, r, x0, Rh)
    spikes, jumps, rates = step.simulate_exact(Ntrials=100, T=T)
    color = colors[i]
    plt.figure(fig1.number)
    for j in range(num_trajectories):
        if j==0:
            label = 'r='+str(r)
        else:
            label=None
        plt.plot(rates[j], color=color, label=label)
    plt.figure(fig2.number)
    plt.hist(jumps, bins=bin_edges, alpha=0.5, label='r='+str(r))
    i+=1

plt.figure(fig1.number)
plt.xlabel('Time (ms)')
plt.ylabel('Firing Rate (Hz)')
plt.title('m=' + str(np.round(m)))
plt.legend()

plt.figure(fig2.number)
plt.xlabel('Jump Time (ms)')
plt.ylabel('Frequency')
plt.title('m=' + str(np.round(m)))
plt.legend()

plt.show()

# plot trajectories and jump time histograms for exact 2-state model (inhomogeneous MC)
fig1 = plt.figure()
fig2 = plt.figure()
rs = np.linspace(1, 100, 4, dtype=int)
i = 0
for r in rs:
    step = models_hmm.StepModelHMM(m, r, x0, Rh)
    spikes, jumps, rates = step.simulate_exact_2state(Ntrials=100, T=T)
    color = colors[i]
    plt.figure(fig1.number)
    for j in range(num_trajectories):
        if j==0:
            label = 'r='+str(r)
        else:
            label=None
        plt.plot(rates[j], color=color, label=label)
    plt.figure(fig2.number)
    plt.hist(jumps, bins=bin_edges, alpha=0.5, label='r='+str(r))
    i+=1

plt.figure(fig1.number)
plt.xlabel('Time (ms)')
plt.ylabel('Firing Rate (Hz)')
plt.title('m=' + str(np.round(m)))
plt.legend()

plt.figure(fig2.number)
plt.xlabel('Jump Time (ms)')
plt.ylabel('Frequency')
plt.title('m=' + str(np.round(m)))
plt.legend()

plt.show()

w3_22.py
import numpy as np
import matplotlib.pyplot as plt
from collections import OrderedDict as OD
import scipy.special
import os
from scipy.interpolate import griddata
import w3_2
import w3_utils
from models_hmm import RampModelHMM
import pandas as pd
from matplotlib.lines import Line2D


var = lambda a, b, frac: ((b-a) * frac) ** 2
mean = lambda a, b: (b+a)/2

def run_and_plot_selection(filename, ramp_grid, step_grid, gen_ramp_post, gen_step_post, inf_ramp_post, inf_step_post, n_datasets, n_trials, plot_title_prefix, Rh, x0, show=False, plot=True):
    
    if not os.path.exists(filename):
        print(f"Running model selection, saving to {filename}...")
        w3_2.model_selection(
            ramp_grid, step_grid,
            gen_ramp_post, gen_step_post, # generating
            inf_ramp_post, inf_step_post, # inference
            N_DATASETS=n_datasets, N_TRIALS=n_trials,
            save_to=filename
        )
    # else:
    #     print(f"Found existing results file: {filename}")


    heatmap_savename = f'plots/task_3_2_2_{os.path.basename(filename)[:-4]}_heatmap.png'
    confmat_savename = f'plots/task_3_2_2_{os.path.basename(filename)[:-4]}_confmat.png'
    plot_title = f'{plot_title_prefix}, {n_trials} trials/dataset, Rh={Rh}, x0={x0}'
    
    w3_2.plot_heatmap(filename, plot_title, save_name=heatmap_savename, show=show)
    ramp_accuracy, step_accuracy = w3_2.plot_confusion_matrix(filename, plot_title, save_name=confmat_savename, show=show)
    return ramp_accuracy, step_accuracy


if __name__ == "__main__":
    os.makedirs('plots', exist_ok=True)
    os.makedirs('results', exist_ok=True)
    K = 25
    T_MS = 100
    RH = 20
    M_GRID = 15
    X0 = 0.5
    # N_DATASETS = 50
    # N_TRIALS = 5

    # STD_FRACTION = 0.25

    # TODO changeme
    BETA_RANGE = (0, 4)
    SIGMA_RANGE = (0.04, 4)

    M_RANGE = (T_MS * 0.25, T_MS * 0.75)
    R_RANGE = (1, 6)

    ramp_param_specs = OD([
        ('beta', np.linspace(*BETA_RANGE, M_GRID)),
        ('sigma', np.exp(np.linspace(np.log(SIGMA_RANGE[0]),
                                     np.log(SIGMA_RANGE[1]),
                                     M_GRID))),
        ('x0', X0),
        ('K', K),
        ('T', T_MS),
        ('Rh', RH)
    ])

    step_param_specs = OD([('m', np.linspace(*M_RANGE, M_GRID)),
                           ('r', np.linspace(*R_RANGE, 6).astype(int)),
                           ('x0', X0),
                           ('K', K),
                           ('T', T_MS),
                           ('Rh', RH)])

    ramp_params_grid = w3_utils.make_params_grid(ramp_param_specs)
    step_params_grid = w3_utils.make_params_grid(step_param_specs)

    uniform_ramp_posterior = w3_utils.uniform_prior(ramp_params_grid)
    uniform_step_posterior = w3_utils.uniform_prior(step_params_grid)



    N_DATASETS = 50
    N_TRIALS_LIST = [5, 10, 15, 20, 30, 50]
    sigma_fract_list = [0.0625, 0.125, 0.25, 0.5]
    accuracies = {'Uniform': {'ramp': [], 'step': []}}
    for sf in sigma_fract_list:
        accuracies[f'Gaussian, SF={sf}'] = {'ramp': [], 'step': []}

    for N_TRIALS in N_TRIALS_LIST:
        print("--------------------------------")
        print("N_TRIALS: ", N_TRIALS)
        print("Running Uniform prior")
        # TEST 1

        fn = "./results/UU_D" + str(N_DATASETS) + "_T" + str(N_TRIALS) + ".csv"
        step_accuracy, ramp_accuracy = run_and_plot_selection(
            filename=fn,
            ramp_grid=ramp_params_grid,
            step_grid=step_params_grid,
            gen_ramp_post=uniform_ramp_posterior,
            gen_step_post=uniform_step_posterior,
            inf_ramp_post=uniform_ramp_posterior,
            inf_step_post=uniform_step_posterior,
            n_datasets=N_DATASETS,
            n_trials=N_TRIALS,
            plot_title_prefix='Uniform prior',
            Rh=RH,
            x0=X0
        )
        accuracies['Uniform']['ramp'].append(ramp_accuracy)
        accuracies['Uniform']['step'].append(step_accuracy)

        # TEST 2

        for STD_FRACTION in sigma_fract_list:
            print("Running Gaussian prior, STD_FRACTION: ", STD_FRACTION)
            gauss_ramp_posterior = w3_utils.gaussian_prior(
                ramp_params_grid,
                mu={
                    "beta": mean(*BETA_RANGE),
                    "sigma": mean(*SIGMA_RANGE)
                },
                cov={
                    ("beta", "beta"): var(*BETA_RANGE, STD_FRACTION),
                    ("sigma", "sigma"): var(*SIGMA_RANGE, STD_FRACTION)
                })

            gauss_step_posterior = w3_utils.gaussian_prior(
                step_params_grid,
                mu={
                    "m": mean(*M_RANGE),
                    "r": 1
                },
                cov={
                    ("m", "m"): var(*M_RANGE, STD_FRACTION),
                    ("r", "r"): var(*R_RANGE, STD_FRACTION)
                })

            fn = "./results/GU_D" + str(N_DATASETS) + "_T" + str(N_TRIALS) + "_SF" + str(STD_FRACTION) + ".csv"

            step_accuracy, ramp_accuracy = run_and_plot_selection(
                filename=fn,
                ramp_grid=ramp_params_grid,
                step_grid=step_params_grid,
                gen_ramp_post=uniform_ramp_posterior,
                gen_step_post=uniform_step_posterior,
                inf_ramp_post=gauss_ramp_posterior,
                inf_step_post=gauss_step_posterior,
                n_datasets=N_DATASETS,
                n_trials=N_TRIALS,
                plot_title_prefix=r'Gaussian prior, $\sigma_{frac}$=' + str(STD_FRACTION),
                Rh=RH,
                x0=X0
            )
            accuracies[f'Gaussian, SF={STD_FRACTION}']['ramp'].append(ramp_accuracy)
            accuracies[f'Gaussian, SF={STD_FRACTION}']['step'].append(step_accuracy)

    plt.figure(figsize=(10, 6))
    for label, accs_dict in accuracies.items():
        avg_accs = [(r + s) / 2 for r, s in zip(accs_dict['ramp'], accs_dict['step'])]
        plt.plot(N_TRIALS_LIST, avg_accs, marker='o', linestyle='-', label=label)
    
    plt.xlabel("Number of Trials")
    plt.ylabel("Overall HMM Accuracy")
    plt.title("HMM Accuracy vs. Number of Trials for Different Priors")
    plt.legend()
    plt.grid(True)
    plt.ylim(0.45, 1.05)
    plt.savefig('plots/task_3_2_2_accuracy_vs_n_trials.png')
    # plt.show()
    plt.close()

    fig, ax = plt.subplots(figsize=(10, 6))
    colors = plt.cm.viridis(np.linspace(0, 1, len(accuracies)))
    for i, (label, accs_dict) in enumerate(accuracies.items()):
        ax.plot(N_TRIALS_LIST, accs_dict['ramp'], marker='o', linestyle='-', label=label, color=colors[i])
        ax.plot(N_TRIALS_LIST, accs_dict['step'], marker='x', linestyle='--', color=colors[i])

    ax.set_xlabel("Number of Trials")
    ax.set_ylabel("HMM Accuracy")
    ax.set_title("Ramp vs. Step HMM Accuracy for Different Priors")
    ax.grid(True)
    ax.set_ylim(0.45, 1.05)

    # Create the top legend for model types (linestyles) and add it as an artist
    linestyle_handles = [
        Line2D([], [], color='gray', linestyle='-', marker='o', label='Ramp'),
        Line2D([], [], color='gray', linestyle='--', marker='x', label='Step')
    ]
    linestyle_legend = ax.legend(handles=linestyle_handles, loc='lower right')
    ax.add_artist(linestyle_legend)

    # Create the bottom legend for prior types, positioned below the first one
    ax.legend(title='Prior Type', loc='lower right', bbox_to_anchor=(1, 0.12))
    
    fig.tight_layout()
    plt.savefig('plots/task_3_2_2_accuracy_breakdown_vs_n_trials.png')
    # plt.show()
    plt.close()

    prior_labels = ['Uniform', 'Gaussian, SF=0.5', 'Gaussian, SF=0.25', 'Gaussian, SF=0.125', 'Gaussian, SF=0.0625']
    ramp_acc_matrix = np.array([accuracies[label]['ramp'] for label in prior_labels]).T
    step_acc_matrix = np.array([accuracies[label]['step'] for label in prior_labels]).T

    heatmap_xticklabels = []
    for label in prior_labels:
        if 'Gaussian' in label:
            val = label.split('=')[-1]
            heatmap_xticklabels.append(fr'Gaus $\sigma_{{frac}}$=1/{int(1/float(val))}')
        else:
            heatmap_xticklabels.append(label)
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))

    # Ramp accuracy heatmap
    im1 = ax1.imshow(ramp_acc_matrix, cmap='viridis', aspect='auto', origin='lower', vmin=0.5, vmax=1)
    ax1.set_title('Ramp Model Accuracy')
    ax1.set_xticks(np.arange(len(prior_labels)))
    ax1.set_xticklabels(heatmap_xticklabels, rotation=45, ha="right")
    ax1.set_yticks(np.arange(len(N_TRIALS_LIST)))
    ax1.set_yticklabels(N_TRIALS_LIST)
    ax1.set_ylabel('Number of Trials')
    fig.colorbar(im1, ax=ax1, label='Accuracy')

    # step accuracy heatmap
    im2 = ax2.imshow(step_acc_matrix, cmap='viridis', aspect='auto', origin='lower', vmin=0.5, vmax=1)
    ax2.set_title('Step Model Accuracy')
    ax2.set_xticks(np.arange(len(prior_labels)))
    ax2.set_xticklabels(heatmap_xticklabels, rotation=45, ha="right")
    ax2.set_yticks(np.arange(len(N_TRIALS_LIST)))
    ax2.set_yticklabels(N_TRIALS_LIST)
    fig.colorbar(im2, ax=ax2, label='Accuracy')

    fig.suptitle('HMM Accuracy Heatmaps for Different Priors and Trial Counts', fontsize=16)
    fig.tight_layout(rect=[0, 0, 1, 0.96])
    plt.savefig('plots/task_3_2_2_accuracy_heatmaps.png')
    plt.show()

w3_viz.py
import numpy as np
import matplotlib.pyplot as plt
from collections import OrderedDict as OD
import scipy.special
import os
import pickle
import concurrent.futures
from tqdm import tqdm
import argparse

import w3_utils
from models_hmm import RampModelHMM, StepModelHMM

# make text larger
plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})

def task_3_1_1_visualize_posterior_2d(model_type, true_params, n_trials, param_specs, params_grid, K=50, T=100, Rh=50, show=False):
    """
    Visualizes the 2D posterior probability for a given model with x0 fixed.
    """
    if model_type == 'ramp':
        Model, llh_func = RampModelHMM, w3_utils.ramp_LLH
        param1_name, param2_name = 'beta', 'sigma'
        xlabel, ylabel = r'$\beta$', r'$\sigma$'
    else: # step
        Model, llh_func = StepModelHMM, w3_utils.step_LLH
        param1_name, param2_name = 'm', 'r'
        xlabel, ylabel = 'm', 'r'

    cache_dir = os.path.join("plots", "cache")
    os.makedirs(cache_dir, exist_ok=True)
    true_param_str = "-".join([f"{k}_{v:.2f}" for k, v in sorted(true_params.items()) if k in [param1_name, param2_name, 'x0']])
    grid_size = len(param_specs[param1_name])
    cache_filename = os.path.join(cache_dir, f"posterior_2d_{model_type}_{true_param_str}_N{n_trials}_M{grid_size}_K{K}.pickle")

    if os.path.exists(cache_filename):
        with open(cache_filename, 'rb') as f:
            norm_post_grid = pickle.load(f)
        print(f"Loaded from cache: {cache_filename}")
    else:
        if model_type == 'ramp':
            model = Model(beta=true_params['beta'], sigma=true_params['sigma'], x0=true_params['x0'], K=K, Rh=Rh)
            data, _, _ = model.simulate(Ntrials=n_trials, T=T)
        else: # step
            model = Model(m=true_params['m'], r=true_params['r'], x0=true_params['x0'], Rh=Rh)
            data, _, _ = model.simulate_exact(Ntrials=n_trials, T=T, delay_compensation=True)

        llh_grid = llh_func(data, params_grid)
        prior_grid = w3_utils.uniform_prior(params_grid, log=True)
        norm_post_grid = w3_utils.norm_posterior(llh_grid, prior_grid, log=True)
        with open(cache_filename, 'wb') as f:
            pickle.dump(norm_post_grid, f)
        print(f"Saved to cache: {cache_filename}")

    param1_vals = param_specs[param1_name]
    param2_vals = param_specs[param2_name]

    delta1 = param1_vals[1] - param1_vals[0]
    delta2 = param2_vals[1] - param2_vals[0]
    extent = [
        param1_vals[0] - delta1 / 2, param1_vals[-1] + delta1 / 2,
        param2_vals[0] - delta2 / 2, param2_vals[-1] + delta2 / 2
    ]

    plt.figure(figsize=(8, 6))
    plt.imshow(np.exp(norm_post_grid).T, origin='lower', aspect='auto',
               extent=extent, cmap='viridis')
    plt.colorbar(label='Posterior Probability')
    plt.scatter(true_params[param1_name], true_params[param2_name], color='red', marker='x', s=100, label='True Parameters')
    
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.title(f'{model_type.capitalize()} Model\n2D Posterior (x0={true_params["x0"]:.2f}, N_trials={n_trials})')
    plt.legend()
    
    filename = f"plots/task_3_1_1_{model_type}_posterior_N{n_trials}.png"
    plt.tight_layout()
    plt.savefig(filename)
    if show:
        plt.show()
    plt.close()

def _calculate_map_error_single(args):
    """
    Helper function for parallel execution of MAP error calculation for a single parameter set.
    """
    model_type, true_params, inference_params_grid, cache_dir, K, T, Rh, n_trials = args

    if model_type == 'ramp':
        param_names = ['beta', 'sigma']
    else: # step
        param_names = ['m', 'r']

    param_str = "-".join([f"{k}_{v:.2f}" for k, v in sorted(true_params.items()) if k in param_names + ['x0']])
    cache_filename = os.path.join(cache_dir, f"{param_str}.pickle")

    if os.path.exists(cache_filename):
        try:
            with open(cache_filename, 'rb') as f:
                map_error, expectation_error = pickle.load(f)
            return map_error, expectation_error
        except (ValueError, EOFError):
            pass

    if model_type == 'ramp':
        model = RampModelHMM(beta=true_params['beta'], sigma=true_params['sigma'], x0=true_params['x0'], K=K, Rh=Rh)
        data, _, _ = model.simulate(Ntrials=n_trials, T=T)
        llh_grid = w3_utils.ramp_LLH(data, inference_params_grid)
    else:
        model = StepModelHMM(m=true_params['m'], r=true_params['r'], x0=true_params['x0'], Rh=Rh)
        data, _, _ = model.simulate_exact(Ntrials=n_trials, T=T, delay_compensation=True)
        llh_grid = w3_utils.step_LLH(data, inference_params_grid)

    prior_grid = w3_utils.uniform_prior(inference_params_grid, log=True)
    norm_post_grid = w3_utils.norm_posterior(llh_grid, prior_grid, log=True)

    # MAP error
    map_indices = np.unravel_index(np.argmax(norm_post_grid), norm_post_grid.shape)
    map_params = inference_params_grid[map_indices]
    map_error = np.sqrt(sum((true_params[p] - map_params[p])**2 for p in param_names))

    # expectation error
    posterior_means = w3_utils.expectation(norm_post_grid, inference_params_grid, log=True)
    expectation_error = np.sqrt(sum((true_params[p] - posterior_means[p])**2 for p in param_names))

    with open(cache_filename, 'wb') as f:
        pickle.dump((map_error, expectation_error), f)

    return map_error, expectation_error

def task_3_1_1_visualize_map_error(model_type, true_param_specs, inference_param_specs, n_trials, K=50, T=100, Rh=50, show=False):
    """
    For a grid of true parameters, simulates data, finds the MAP estimate,
    and visualizes the error between the true parameters and the MAP estimate.
    Caches results to avoid re-computation and runs in parallel.
    """
    if model_type == 'ramp':
        param1_name, param2_name = 'beta', 'sigma'
        xlabel, ylabel = r'$\beta$', r'$\sigma$'
    else: # step
        param1_name, param2_name = 'm', 'r'
        xlabel, ylabel = 'm', 'r'

    true_params_grid = w3_utils.make_params_grid(true_param_specs)
    inference_params_grid = w3_utils.make_params_grid(inference_param_specs)

    M_inference = len(inference_param_specs[param1_name])
    cache_dir = os.path.join("plots", "cache", f"map_error_{model_type}_{true_param_specs['x0']}_{M_inference}_{K}_{n_trials}_{T}_{Rh}")
    os.makedirs(cache_dir, exist_ok=True)
    
    tasks = [
        (model_type, param_dict.item(), inference_params_grid, cache_dir, K, T, Rh, n_trials)
        for param_dict in np.nditer(true_params_grid, flags=['refs_ok'])
    ]

    with concurrent.futures.ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:
        results = list(tqdm(executor.map(_calculate_map_error_single, tasks), total=len(tasks)))
    
    map_errors, expectation_errors = zip(*results)

    map_error_grid = np.array(map_errors).reshape(true_params_grid.shape)
    expectation_error_grid = np.array(expectation_errors).reshape(true_params_grid.shape)

    true_param1_vals = true_param_specs[param1_name]
    true_param2_vals = true_param_specs[param2_name]

    delta_param1 = true_param1_vals[1] - true_param1_vals[0]
    delta_param2 = true_param2_vals[1] - true_param2_vals[0]
    extent = [
        true_param1_vals[0] - delta_param1 / 2, true_param1_vals[-1] + delta_param1 / 2,
        true_param2_vals[0] - delta_param2 / 2, true_param2_vals[-1] + delta_param2 / 2
    ]
    
    # MAP error
    plt.figure(figsize=(8, 6))
    im = plt.imshow(map_error_grid.T, origin='lower', aspect='auto', extent=extent, cmap='magma')
    plt.colorbar(im, label='MAP Estimation Error (Euclidean Distance)')
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.title(f'{model_type.capitalize()} Model\nMAP Estimation Error (N_trials={n_trials})')
    
    filename = f"plots/task_3_1_1_{model_type}_map_error_x{true_param_specs['x0']}_N{n_trials}.png"
    plt.tight_layout()
    plt.savefig(filename)
    if show:
        plt.show()
    plt.close()

    # expectation error
    plt.figure(figsize=(8, 6))
    im = plt.imshow(expectation_error_grid.T, origin='lower', aspect='auto', extent=extent, cmap='magma')
    plt.colorbar(im, label='Expectation Error (Euclidean Distance)')
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.title(f'{model_type.capitalize()} Model\nPosterior Mean Estimation Error (N_trials={n_trials})')
    
    filename = f"plots/task_3_1_1_{model_type}_expectation_error_N{n_trials}.png"
    plt.tight_layout()
    plt.savefig(filename)
    if show:
        plt.show()
    plt.close()
    return expectation_error_grid


def _analyze_estimation_worker(args):
    model_type, true_params, n_trials, params_grid, param_names, K, T, Rh = args

    if model_type == 'ramp':
        Model, llh_func = RampModelHMM, w3_utils.ramp_LLH
    else:  # step
        Model, llh_func = StepModelHMM, w3_utils.step_LLH

    if model_type == 'ramp':
        model = Model(beta=true_params['beta'], sigma=true_params['sigma'], x0=true_params['x0'], K=K, Rh=Rh)
        data, _, _ = model.simulate(Ntrials=n_trials, T=T)
    else:
        model = Model(m=true_params['m'], r=true_params['r'], x0=true_params['x0'], Rh=Rh)
        data, _, _ = model.simulate_exact(Ntrials=n_trials, T=T, delay_compensation=True)

    llh_grid = llh_func(data, params_grid)
    prior_grid = w3_utils.uniform_prior(params_grid, log=True)
    norm_post_grid = w3_utils.norm_posterior(llh_grid, prior_grid, log=True)

    posterior_means = w3_utils.expectation(norm_post_grid, params_grid, log=True)
    posterior_std_devs = w3_utils.posterior_std_dev(norm_post_grid, params_grid, posterior_means, log=True)

    errors = {}
    stds = {}
    for p in param_names:
        errors[p] = np.abs(posterior_means[p] - true_params[p])
        stds[p] = posterior_std_devs.get(p, np.nan)

    return errors, stds

def task_3_1_2_analyze_estimation_2d(model_type, true_params, n_trials_list, params_grid, n_datasets=1, K=50, T=100, Rh=50, show=False):
    if model_type == 'ramp':
        param_names = ['beta', 'sigma']
        Model, llh_func = RampModelHMM, w3_utils.ramp_LLH
    else: # step
        param_names = ['m', 'r']
        Model, llh_func = StepModelHMM, w3_utils.step_LLH

    cache_dir = os.path.join("plots", "cache")
    os.makedirs(cache_dir, exist_ok=True)
    true_param_str = "-".join([f"{k}_{v:.2f}" for k, v in sorted(true_params.items()) if k in param_names + ['x0']])
    grid_shape_str = "_".join(map(str, params_grid.shape))
    ntrials_str = "_".join(map(str, n_trials_list))
    cache_filename = os.path.join(cache_dir, f"analyze_2d_{model_type}_{true_param_str}_G{grid_shape_str}_N{ntrials_str}_D{n_datasets}_K{K}.pickle")

    if os.path.exists(cache_filename):
        with open(cache_filename, 'rb') as f:
            estimation_errors, posterior_stds = pickle.load(f)
        print(f"Loaded from cache: {cache_filename}")
    else:
        estimation_errors = {p: [] for p in param_names}
        posterior_stds = {p: [] for p in param_names}
    
        for n_trials in n_trials_list:
            print(f"Processing n_trials = {n_trials}")
            tasks = [(model_type, true_params, n_trials, params_grid, param_names, K, T, Rh) for _ in range(n_datasets)]
            
            with concurrent.futures.ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:
                results = list(tqdm(executor.map(_analyze_estimation_worker, tasks), total=len(tasks), desc=f"Averaging over datasets"))

            errors_for_n_trials = {p: [] for p in param_names}
            stds_for_n_trials = {p: [] for p in param_names}

            for errors, stds in results:
                for p in param_names:
                    errors_for_n_trials[p].append(errors[p])
                    stds_for_n_trials[p].append(stds[p])
            
            for p in param_names:
                estimation_errors[p].append(np.mean(errors_for_n_trials[p]))
                posterior_stds[p].append(np.mean(stds_for_n_trials[p]))
        
        with open(cache_filename, 'wb') as f:
            pickle.dump((estimation_errors, posterior_stds), f)
        print(f"Saved to cache: {cache_filename}")

    plt.figure(figsize=(10, 7))
    colors = ['#1f77b4', '#ff7f0e']
    param_labels = {'beta': r'$\beta$', 'sigma': r'$\sigma$', 'm': 'm', 'r': 'r'}

    for i, p in enumerate(param_names):
        error = np.array(estimation_errors[p])
        std_dev = np.array(posterior_stds[p])
        
        plt.plot(n_trials_list, error, 'o-', color=colors[i], label=f'Parameter {param_labels.get(p, p)}')
        plt.fill_between(n_trials_list, error - std_dev, error + std_dev, color=colors[i], alpha=0.2)

    plt.xlabel('Number of Trials')
    plt.ylabel('Error / Std Dev')
    plt.suptitle(f'{model_type.capitalize()} Model\nEstimation Quality vs. Number of Trials (N Datasets={n_datasets})')
    plt.legend()
    plt.xscale('log')
    # plt.yscale('log')
    plt.grid(True, which="both", ls="--")
    
    filepath = f"plots/task_3_1_2_{model_type}_x{true_params['x0']}_ND{n_datasets}_Nerror_vs_ntrials.png"
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    plt.tight_layout()
    plt.savefig(filepath, dpi=300, bbox_inches='tight')
    if show:
        plt.show()
    plt.close()
    return estimation_errors

def task_3_1_3_visualize_posterior_marginal(model_type, true_params, n_trials, param_specs, params_grid, K=50, T=100, Rh=50, show=False):
    if model_type == 'ramp':
        Model, llh_func = RampModelHMM, w3_utils.ramp_LLH
        param_names = ['beta', 'sigma', 'x0']
        labels = [r'$\beta$', r'$\sigma$', 'x0']
    else: # step
        Model, llh_func = StepModelHMM, w3_utils.step_LLH
        param_names = ['m', 'r', 'x0']
        labels = ['m', 'r', 'x0']

    cache_dir = os.path.join("plots", "cache")
    os.makedirs(cache_dir, exist_ok=True)
    true_param_str = "-".join([f"{k}_{v:.2f}" for k, v in sorted(true_params.items()) if k in param_names])
    grid_size = len(param_specs[param_names[0]])
    cache_filename = os.path.join(cache_dir, f"posterior_3d_{model_type}_{true_param_str}_N{n_trials}_M{grid_size}_K{K}.pickle")

    if os.path.exists(cache_filename):
        with open(cache_filename, 'rb') as f:
            norm_post_grid = pickle.load(f)
        print(f"Loaded from cache: {cache_filename}")
    else:
        if model_type == 'ramp':
            model = Model(beta=true_params['beta'], sigma=true_params['sigma'], x0=true_params['x0'], K=K, Rh=Rh)
            data, _, _ = model.simulate(Ntrials=n_trials, T=T)
        else:
            model = Model(m=true_params['m'], r=true_params['r'], x0=true_params['x0'], Rh=Rh)
            data, _, _ = model.simulate_exact(Ntrials=n_trials, T=T, delay_compensation=True)

        llh_grid = llh_func(data, params_grid)
        prior_grid = w3_utils.uniform_prior(params_grid, log=True)
        norm_post_grid = w3_utils.norm_posterior(llh_grid, prior_grid, log=True)
        with open(cache_filename, 'wb') as f:
            pickle.dump(norm_post_grid, f)
        print(f"Saved to cache: {cache_filename}")

    fig, axs = plt.subplots(1, 3, figsize=(18, 5))
    
    marginal_pairs = [(0, 1), (0, 2), (1, 2)]
    for i, (p1_idx, p2_idx) in enumerate(marginal_pairs):
        other_idx = 3 - p1_idx - p2_idx
        marginal_post = scipy.special.logsumexp(norm_post_grid, axis=other_idx)
        
        p1_vals = param_specs[param_names[p1_idx]]
        p2_vals = param_specs[param_names[p2_idx]]
        
        delta1 = p1_vals[1] - p1_vals[0]
        delta2 = p2_vals[1] - p2_vals[0]
        extent = [p1_vals[0] - delta1/2, p1_vals[-1] + delta1/2, 
                  p2_vals[0] - delta2/2, p2_vals[-1] + delta2/2]

        im = axs[i].imshow(np.exp(marginal_post).T, origin='lower', aspect='auto', extent=extent, cmap='viridis')
        axs[i].scatter(true_params[param_names[p1_idx]], true_params[param_names[p2_idx]], c='r', marker='x')
        axs[i].set_xlabel(labels[p1_idx])
        axs[i].set_ylabel(labels[p2_idx])
        axs[i].set_title(f'P({param_names[p1_idx]}, {param_names[p2_idx]})')
        fig.colorbar(im, ax=axs[i], orientation='vertical')

    fig.suptitle(f'{model_type.capitalize()} Model\n2D Marginal Posteriors (N_trials={n_trials})', fontsize=16)
    filepath = f"plots/task_3_1_3_{model_type}_marginals_N{n_trials}.png"
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    fig.tight_layout()
    plt.savefig(filepath, dpi=300, bbox_inches='tight')
    if show:
        plt.show()
    plt.close()

def task_3_1_3_analyze_estimation_3d(model_type, true_params, n_trials_list, params_grid, n_datasets=1, K=50, T=100, Rh=50, show=False):
    if model_type == 'ramp':
        param_names = ['beta', 'sigma', 'x0']
        Model, llh_func = RampModelHMM, w3_utils.ramp_LLH
    else: # step
        param_names = ['m', 'r', 'x0']
        Model, llh_func = StepModelHMM, w3_utils.step_LLH

    cache_dir = os.path.join("plots", "cache")
    os.makedirs(cache_dir, exist_ok=True)
    true_param_str = "-".join([f"{k}_{v:.2f}" for k, v in sorted(true_params.items()) if k in param_names])
    grid_shape_str = "_".join(map(str, params_grid.shape))
    ntrials_str = "_".join(map(str, n_trials_list))
    cache_filename = os.path.join(cache_dir, f"analyze_3d_{model_type}_{true_param_str}_G{grid_shape_str}_N{ntrials_str}_D{n_datasets}_K{K}.pickle")

    if os.path.exists(cache_filename):
        with open(cache_filename, 'rb') as f:
            estimation_errors, posterior_stds = pickle.load(f)
        print(f"Loaded from cache: {cache_filename}")
    else:
        estimation_errors = {p: [] for p in param_names}
        posterior_stds = {p: [] for p in param_names}

        for n_trials in n_trials_list:
            print(f"Processing 3D n_trials = {n_trials}")
            tasks = [(model_type, true_params, n_trials, params_grid, param_names, K, T, Rh) for _ in range(n_datasets)]

            with concurrent.futures.ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:
                results = list(tqdm(executor.map(_analyze_estimation_worker, tasks), total=len(tasks), desc=f"Averaging over datasets"))
            
            errors_for_n_trials = {p: [] for p in param_names}
            stds_for_n_trials = {p: [] for p in param_names}

            for errors, stds in results:
                for p in param_names:
                    errors_for_n_trials[p].append(errors[p])
                    stds_for_n_trials[p].append(stds[p])

            for p in param_names:
                estimation_errors[p].append(np.mean(errors_for_n_trials[p]))
                posterior_stds[p].append(np.mean(stds_for_n_trials[p]))

        with open(cache_filename, 'wb') as f:
            pickle.dump((estimation_errors, posterior_stds), f)
        print(f"Saved to cache: {cache_filename}")

    plt.figure(figsize=(18, 5))
    for i, p in enumerate(param_names):
        plt.subplot(1, 3, i + 1)
        plt.plot(n_trials_list, estimation_errors[p], 'o-', label='Estimation Error')
        plt.plot(n_trials_list, posterior_stds[p], 's--', label='Posterior Std Dev')
        plt.xlabel('Number of Trials')
        plt.ylabel('Error / Std Dev')
        plt.title(f'Parameter: {p}')
        plt.legend()
        plt.xscale('log')
    plt.suptitle(f'{model_type.capitalize()} Model\nEstimation Quality vs. Number of Trials (3D, N Datasets={n_datasets})')
    filepath = f"plots/task_3_1_3_{model_type}_error_vs_ntrials_ND{n_datasets}.png"
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    plt.tight_layout()
    plt.savefig(filepath, dpi=300, bbox_inches='tight')
    if show:
        plt.show()
    plt.close()

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--show', action='store_true')
    args = parser.parse_args()

    K = 25
    T_MS = 100
    RH = 50

    map_x0 = 0.0

    N_MAP_TRIALS = 400
    N_DATASETS_AVG = 10

    M_2D_GRID = 31
    M_TRUE_GRID = 11
    M_INFERENCE_GRID = 31


    ramp_param_2d = OD([
        ('beta', np.linspace(0, 4, M_2D_GRID)),
        ('sigma', np.linspace(0.04, 4, M_2D_GRID)),
        ('x0', 0.2),
        ('K', K), ('T', T_MS), ('Rh', RH)
    ])

    step_param_2d = OD([
        ('m', np.linspace(0, T_MS*3/4, M_2D_GRID)),
        ('r', np.linspace(1, 6, 6).astype(int)),
        ('x0', 0.2),
        ('K', K), ('T', T_MS), ('Rh', RH)
    ])
    #
    # RAMP
    #

    print("\n--- RAMP MODEL ANALYSIS ---")
    ramp_true_params = {'beta': ramp_param_2d['beta'][M_2D_GRID//3], 'sigma': ramp_param_2d['sigma'][3], 'x0': 0.2}
    print(f"Ramp True params: {ramp_true_params}")
    # 3.1.1
    
    ramp_params_grid_2d = w3_utils.make_params_grid(ramp_param_2d)
    task_3_1_1_visualize_posterior_2d('ramp', ramp_true_params, n_trials=10, param_specs=ramp_param_2d, params_grid=ramp_params_grid_2d, K=K, T=T_MS, Rh=RH, show=args.show)
    task_3_1_1_visualize_posterior_2d('ramp', ramp_true_params, n_trials=50, param_specs=ramp_param_2d, params_grid=ramp_params_grid_2d, K=K, T=T_MS, Rh=RH, show=args.show)
    task_3_1_1_visualize_posterior_2d('ramp', ramp_true_params, n_trials=100, param_specs=ramp_param_2d, params_grid=ramp_params_grid_2d, K=K, T=T_MS, Rh=RH, show=args.show)
    task_3_1_1_visualize_posterior_2d('ramp', ramp_true_params, n_trials=400, param_specs=ramp_param_2d, params_grid=ramp_params_grid_2d, K=K, T=T_MS, Rh=RH, show=args.show)

    # 3.1.1
    ramp_true_param_specs = OD([
        ('beta', np.linspace(0, 4, M_TRUE_GRID)),
        ('sigma', np.linspace(0.04, 4, M_TRUE_GRID)),
        ('x0', map_x0),
        ('K', K), ('T', T_MS), ('Rh', RH)
    ])
    ramp_inference_param_specs = OD([
        ('beta', np.linspace(0, 4, M_INFERENCE_GRID)),
        ('sigma', np.linspace(0.04, 4, M_INFERENCE_GRID)),
        ('x0', map_x0),
        ('K', K), ('T', T_MS), ('Rh', RH)
    ])
    task_3_1_1_visualize_map_error('ramp', ramp_true_param_specs, ramp_inference_param_specs, n_trials=N_MAP_TRIALS, K=K, T=T_MS, Rh=RH, show=args.show)

    # 3.1.2

    n_trials_list = [1, 5, 10, 20, 50, 100, 200, 400]
    ramp_params_grid_2d = w3_utils.make_params_grid(ramp_inference_param_specs)
    task_3_1_2_analyze_estimation_2d('ramp', {'beta': ramp_param_2d['beta'][M_2D_GRID//2], 'sigma': ramp_param_2d['sigma'][2], 'x0': 0.0}, n_trials_list, ramp_params_grid_2d, n_datasets=N_DATASETS_AVG, K=K, T=T_MS, Rh=RH, show=args.show or True)
    
    
    # 3.1.3
    ramp_params_specs_3d = OD([
        ('beta', np.linspace(0, 4, M_INFERENCE_GRID)),
        ('sigma', np.linspace(0.04, 4, M_INFERENCE_GRID)),
        ('x0', np.linspace(0, 0.5, M_INFERENCE_GRID)),
        ('K', K), ('T', T_MS), ('Rh', RH)
    ])
    ramp_params_grid_3d = w3_utils.make_params_grid(ramp_params_specs_3d)
    # task_3_1_3_visualize_posterior_marginal('ramp', ramp_true_params, n_trials=100, param_specs=ramp_params_specs_3d, params_grid=ramp_params_grid_3d, K=K, T=T_MS, Rh=RH, show=args.show)
    
    ramp_params_specs_3d = OD([
        ('beta', np.linspace(0, 4, M_TRUE_GRID)),
        ('sigma', np.linspace(0.04, 4, M_TRUE_GRID)),
        ('x0', np.linspace(0, 0.5, M_TRUE_GRID)),
        ('K', K), ('T', T_MS), ('Rh', RH)
    ])
    ramp_params_grid_3d = w3_utils.make_params_grid(ramp_params_specs_3d)
    # task_3_1_3_analyze_estimation_3d('ramp', ramp_true_params, n_trials_list=[50, 100, 200], params_grid=ramp_params_grid_3d, n_datasets=N_DATASETS_AVG, K=K, T=T_MS, Rh=RH, show=args.show)

    #
    # STEP
    #

    print("\n--- STEP MODEL ANALYSIS ---")
    step_true_params = {'m': step_param_2d['m'][M_2D_GRID//2], 'r': step_param_2d['r'][2], 'x0': 0.2}
    print(f"Step True params: {step_true_params}")
    # 3.1.1
    
    step_params_grid_2d = w3_utils.make_params_grid(step_param_2d)
    task_3_1_1_visualize_posterior_2d('step', step_true_params, n_trials=10, param_specs=step_param_2d, params_grid=step_params_grid_2d, K=K, T=T_MS, Rh=RH, show=args.show)
    task_3_1_1_visualize_posterior_2d('step', step_true_params, n_trials=50, param_specs=step_param_2d, params_grid=step_params_grid_2d, K=K, T=T_MS, Rh=RH, show=args.show)
    task_3_1_1_visualize_posterior_2d('step', step_true_params, n_trials=100, param_specs=step_param_2d, params_grid=step_params_grid_2d, K=K, T=T_MS, Rh=RH, show=args.show)
    task_3_1_1_visualize_posterior_2d('step', step_true_params, n_trials=400, param_specs=step_param_2d, params_grid=step_params_grid_2d, K=K, T=T_MS, Rh=RH, show=args.show)

    # 3.1.1
    step_true_param_specs = OD([
        ('m', np.linspace(0, T_MS*3/4, M_TRUE_GRID)),
        ('r', np.linspace(1, 6, 6).astype(int)),
        ('x0', map_x0),
        ('K', K), ('T', T_MS), ('Rh', RH)
    ])
    step_inference_param_specs = OD([
        ('m', np.linspace(0, T_MS*3/4, M_INFERENCE_GRID)),
        ('r', np.linspace(1, 6, 6).astype(int)),
        ('x0', map_x0),
        ('K', K), ('T', T_MS), ('Rh', RH)
    ])
    task_3_1_1_visualize_map_error('step', step_true_param_specs, step_inference_param_specs, n_trials=N_MAP_TRIALS, K=K, T=T_MS, Rh=RH, show=args.show)


    # 3.1.2
    step_true_params = {'m': step_param_2d['m'][M_2D_GRID//2], 'r': step_param_2d['r'][2], 'x0': 0.0}

    n_trials_list = [1, 5, 10, 20, 50, 100, 200, 400]
    step_params_grid_2d = w3_utils.make_params_grid(step_inference_param_specs)
    task_3_1_2_analyze_estimation_2d('step',  {'m': step_param_2d['m'][M_2D_GRID//2], 'r': step_param_2d['r'][-2], 'x0': 0.0}, n_trials_list, step_params_grid_2d,
                                      n_datasets=N_DATASETS_AVG*3, K=K, T=T_MS, Rh=RH,
                                      show=args.show or True)

    # 3.1.3
    step_params_specs_3d = OD([
        ('m', np.linspace(0, T_MS*3/4, M_INFERENCE_GRID)),
        ('r', np.linspace(1, 6, 6).astype(int)),
        ('x0', np.linspace(0, 0.5, M_INFERENCE_GRID)),
        ('K', K), ('T', T_MS), ('Rh', RH)
    ])
    step_params_grid_3d = w3_utils.make_params_grid(step_params_specs_3d)
    # task_3_1_3_visualize_posterior_marginal('step', step_true_params, n_trials=100, param_specs=step_params_specs_3d, params_grid=step_params_grid_3d, K=K, T=T_MS, Rh=RH, show=args.show)
    
    step_params_specs_3d = OD([
        ('m', np.linspace(0, T_MS*3/4, M_TRUE_GRID)),
        ('r', np.linspace(1, 6, 6).astype(int)),
        ('x0', np.linspace(0, 0.5, M_TRUE_GRID)),
        ('K', K), ('T', T_MS), ('Rh', RH)
    ])
    step_params_grid_3d = w3_utils.make_params_grid(step_params_specs_3d)
    # task_3_1_3_analyze_estimation_3d('step', step_true_params, n_trials_list=[50, 100, 200], params_grid=step_params_grid_3d, n_datasets=N_DATASETS_AVG, K=K, T=T_MS, Rh=RH, show=args.show)

    # --- Combined Error Plot ---
    print("\n--- Generating Combined Expectation Error vs N_trials Plot ---")
    n_trials_list = [50, 100, 200, 400]
    
    ramp_avg_errors, ramp_std_errors = [], []
    print("Analyzing Ramp Model...")
    for n in n_trials_list:
        error_grid = task_3_1_1_visualize_map_error('ramp', ramp_true_param_specs, ramp_inference_param_specs, n_trials=n, K=K, T=T_MS, Rh=RH, show=args.show)
        ramp_avg_errors.append(np.mean(error_grid))
        ramp_std_errors.append(np.std(error_grid))

    step_avg_errors, step_std_errors = [], []
    print("Analyzing Step Model...")
    for n in n_trials_list:
        error_grid = task_3_1_1_visualize_map_error('step', step_true_param_specs, step_inference_param_specs, n_trials=n, K=K, T=T_MS, Rh=RH, show=args.show)
        step_avg_errors.append(np.mean(error_grid))
        step_std_errors.append(np.std(error_grid))

    plt.figure(figsize=(10, 6))
    
    ramp_avg_errors = np.array(ramp_avg_errors)
    ramp_std_errors = np.array(ramp_std_errors)
    step_avg_errors = np.array(step_avg_errors)
    step_std_errors = np.array(step_std_errors)

    ramp_line, = plt.plot(n_trials_list, ramp_avg_errors, 'o-', label='Ramp Model Avg. Expectation Error')
    plt.fill_between(n_trials_list, ramp_avg_errors - ramp_std_errors, ramp_avg_errors + ramp_std_errors, color=ramp_line.get_color(), alpha=0.2)

    step_line, = plt.plot(n_trials_list, step_avg_errors, 's--', label='Step Model Avg. Expectation Error')
    plt.fill_between(n_trials_list, step_avg_errors - step_std_errors, step_avg_errors + step_std_errors, color=step_line.get_color(), alpha=0.2)

    plt.xlabel('Number of Trials')
    plt.ylabel('Avg. Expectation Error (Euclidean Norm)')
    plt.title('Model Expectation Error vs. Number of Trials')
    plt.legend()
    # plt.xscale('log')
    # plt.yscale('log')
    plt.grid(True, which="both", ls="--")
    
    combined_filepath = f"plots/task_3_1_1_combined_avg_expectation_error_vs_ntrials.png"
    plt.savefig(combined_filepath, dpi=300)
    # if args.show:
    plt.show()
    plt.close()


scratch.py
from models_hmm import RampModelHMM
import matplotlib.pyplot as plt
import w3_2
fn = '0.25GGML_D60_T10'

w3_2.plot_confusion_matrix('./results/' + fn + '.csv' , r'Conf. Matrix (Gaussian gen/prior), $\sigma_{frac}=\frac{1}{4}$',
                           save_name='./plots/task_3_2_3_' + fn + '_confmat',
                           fig_size_factor=0.8)

# w3_2.plot_heatmap('./results/UU_D240_T3.csv', title='Bayes Factor (Uniform generation/prior)')
# w3_2.plot_heatmap('./results/0.5GU_D240_T3.csv')
# w3_2.plot_heatmap('./results/0.25GU_D240_T3.csv')
# w3_2.plot_heatmap('./results/0.125GU_D240_T3.csv')

2_3_filter_traces.py
import numpy as np
import models
import scipy
import inference
from models_hmm import RampModelHMM
import os
import matplotlib.pyplot as plt
import pandas as pd
import joypy
import matplotlib.cm as cm

import task_2_3

red = '#ff9999'
blue = '#99ccff'
plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})


if __name__ == "__main__":
    # step implementation

    trials = 500
    trials_to_plot = 1
    T = 100
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8),
                                   gridspec_kw={'height_ratios': [4, 1]})

    CE_sum = np.zeros(T)
    fCE_sum = np.zeros(T)

    colors = plt.cm.coolwarm(np.linspace(1, 0, trials_to_plot))

    for trial in range(trials):
        ex, fex, bpred_s, fbpred_s, states = task_2_3.step_HMM_inference({
            'T': T,
            'Rh': 20,
        }, test_filtering=True)

        bex = task_2_3.compress_states(ex)
        fbex = task_2_3.compress_states(fex)
        bstates = (states == 10).astype(int) # TODO if r, set == r
        
        CE_sum += task_2_3.cross_entropy(bex, bstates)
        fCE_sum += task_2_3.cross_entropy(fbex, bstates)

        # ax1.matshow(ex.T)

        if trial < trials_to_plot:
            alpha = 1 if trial == 0 else 0.15

            color = ['#111111', '#111111', '#111111'] if trial == 0 else [red, blue, '#aaaaaa']
            color = [red, blue, '#111111']

            # calc expected vals for plotting purposes
            expected_s = ex @ np.arange(ex.shape[1])
            fexpected_s = fex @ np.arange(ex.shape[1])

            ax1.plot(np.arange(T), expected_s, color=color[0], linestyle="dashed",
                     label=f'Trial {trial + 1} (Smoothing Pred.)' if trial == 0 else '', alpha=alpha)
            ax1.plot(np.arange(T), fexpected_s, color=color[1], linestyle="dotted",
                     label=f'Trial {trial + 1} (Filtered Pred.)' if trial == 0 else '', alpha=alpha)

            ax1.plot(np.arange(T), states, color=color[2], label=f'Trial {trial + 1} (True)', alpha=alpha)

            first_pred_index = np.argmax(bpred_s == 1) if np.any(bpred_s == 1) else None
            filter_first_pred_index = np.argmax(fbpred_s == 1) if np.any(fbpred_s == 1) else None



            if trial == 0:
                sstd = np.sqrt(np.sum(
                    (np.arange(ex.shape[1]) - np.sum(np.arange(ex.shape[1]) * ex, axis=1, keepdims=True)) ** 2 * ex,
                    axis=1))
                fstd = np.sqrt(np.sum(
                    (np.arange(fex.shape[1]) - np.sum(np.arange(fex.shape[1]) * fex, axis=1, keepdims=True)) ** 2 * fex,
                    axis=1))

                smooth_color = red
                filter_color = blue

                ax1.fill_between(np.arange(T),
                                 expected_s - 2 * sstd,
                                 expected_s + 2 * sstd,
                                 color=smooth_color, alpha=0.3, label='Smoothing 2',
                                 edgecolor=smooth_color, linewidth=1)

                ax1.fill_between(np.arange(T),
                                 fexpected_s - 2 * fstd,
                                 fexpected_s + 2 * fstd,
                                 color=filter_color, alpha=0.3, label='Filtering 2',
                                 edgecolor=filter_color, linewidth=1)
                print(first_pred_index, filter_first_pred_index)
                if first_pred_index is not None:
                    ax1.scatter(first_pred_index, states[first_pred_index],
                                color=color[0], marker='d', s=100, alpha=alpha,
                                label=f'Smoothed Jump Time',
                                zorder=3)

                if filter_first_pred_index is not None:
                    ax1.scatter(filter_first_pred_index, states[filter_first_pred_index],
                                color=color[1], marker='d', s=100, alpha=alpha,
                                label=f'Filtered Jump Time',
                                zorder=3)

        print('completed', trial)

    ax2.plot(np.arange(T), CE_sum / trials, color=red, linewidth=2)
    ax2.plot(np.arange(T), fCE_sum / trials, color=blue, linewidth=2)

    ax2.set_xlabel('Time')
    ax2.set_ylabel('Cross-Entropy')
    ax2.set_title('Average Cross-Entropy Over Time (' + str(trials) + ' trials)')

    handles, labels = ax1.get_legend_handles_labels()
    unique_labels = dict(zip(labels, handles))
    ax1.set_title("Step Model: Markov state (s) over time")
    ax1.set_ylabel("Markov state (proportional to rate)")
    ax1.legend(unique_labels.values(), unique_labels.keys(),
               loc='lower right', ncol=2, framealpha=0.5)

    plt.tight_layout()
    os.makedirs('plots', exist_ok=True)
    plt.show()
    plt.savefig('./plots/task_2_3_step_filter_traces_final.png')


    # Ramp implementation
    
    trials = 50
    trials_to_plot = 1
    T = 100
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8),
                                   gridspec_kw={'height_ratios': [4, 1]})

    CE_sum = np.zeros(T)
    fCE_sum = np.zeros(T)

    colors = plt.cm.coolwarm(np.linspace(1, 0, trials_to_plot))

    for trial in range(trials):
        ex, fex, expected_s, fexpected_s, states = task_2_3.ramp_HMM_inference({
            'T': T,
            'beta': 1.,
            'sigma': 0.35,
            'Rh': 50,
        }, test_filtering=True)


        CE_sum += task_2_3.cross_entropy(ex, states)
        fCE_sum += task_2_3.cross_entropy(fex, states)

        # ax1.matshow(ex.T)

        if trial < trials_to_plot:
            alpha = 1 if trial == 0 else 0.15

            color = ['#666666', '#666666', '#666666'] if trial == 0 else [red, blue, '#aaaaaa']
            color = [red, blue, '#aaaaaa']

            ax1.plot(np.arange(T), expected_s, color=color[0], linestyle="dashed",
                     label=f'Trial {trial + 1} (Smoothing Pred.)', alpha=alpha)
            ax1.plot(np.arange(T), fexpected_s, color=color[1], linestyle="dotted", label=f'Trial {trial + 1} (Filtered Pred.)', alpha=alpha)

            ax1.plot(np.arange(T), states, color=color[2], label=f'Trial {trial + 1} (True)', alpha=alpha)

            if trial == 0:
                sstd = np.sqrt(np.sum(
                    (np.arange(ex.shape[1]) - np.sum(np.arange(ex.shape[1]) * ex, axis=1, keepdims=True)) ** 2 * ex,
                    axis=1))
                fstd = np.sqrt(np.sum(
                    (np.arange(fex.shape[1]) - np.sum(np.arange(fex.shape[1]) * fex, axis=1, keepdims=True)) ** 2 * fex,
                    axis=1))

                smooth_color = red
                filter_color = blue

                ax1.fill_between(np.arange(T),
                                 expected_s - 2 * sstd,
                                 expected_s + 2 * sstd,
                                 color=smooth_color, alpha=0.3, label='Smoothing 2',
                                 edgecolor=smooth_color, linewidth=1)

                ax1.fill_between(np.arange(T),
                                 fexpected_s - 2 * fstd,
                                 fexpected_s + 2 * fstd,
                                 color=filter_color, alpha=0.3, label='Filtering 2',
                                 edgecolor=filter_color, linewidth=1)

                print('fill between')

        print('completed', trial)

    ax2.plot(np.arange(T), CE_sum / trials, color=red, linewidth=2)
    ax2.plot(np.arange(T), fCE_sum / trials, color=blue, linewidth=2)

    ax2.set_xlabel('Time')
    ax2.set_ylabel('Cross-Entropy')
    ax2.set_title('Average Cross-Entropy Over Time (' + str(trials) + ' trials)')

    handles, labels = ax1.get_legend_handles_labels()
    unique_labels = dict(zip(labels, handles))
    ax1.set_title("Ramp Model: Markov state (s) over time")
    ax1.set_ylabel("Markov state (proportional to rate)")
    ax1.legend(unique_labels.values(), unique_labels.keys(),
               loc='upper left', ncol=2, framealpha=0.5)

    plt.tight_layout()
    plt.show()
    plt.savefig('./plots/task_2_3_ramp_filter_traces_final.png')


task_2_1.py
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import os
import pickle

from models import RampModel
from models_hmm import RampModelHMM

# make text larger
plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})

N_TRIALS = 1000
T_MS = 1000

def plot_compared_trajectories(continuous_model, hmm_model, T_MS):
    _, x_continuous_all, _ = continuous_model.simulate(Ntrials=N_TRIALS, T=T_MS)
    actual_spikes_hmm, x_hmm_all, _ = hmm_model.simulate(Ntrials=N_TRIALS, T=T_MS)
    
    # take mean across all trials
    mean_x_continuous = np.mean(x_continuous_all, axis=0)
    mean_x_hmm = np.mean(x_hmm_all, axis=0)
    
    dt_sim = 1.0 / T_MS
    time_axis = np.arange(T_MS) * dt_sim
    
    plt.figure(figsize=(12, 6))
    plt.title(f"$x_t$ Trajectory (K={hmm_model.K}, T={T_MS}, $N_{{\mathrm{{trials}}}}$={N_TRIALS})")

    plt.plot(time_axis, mean_x_continuous, label="Continuous", linestyle='-')
    plt.plot(time_axis, mean_x_hmm, label="HMM", linestyle='--')
    
    plt.ylabel("$x_t$")
    plt.xlabel("Time (s)")
    plt.ylim(-0.1, 1.1)
    plt.legend()
    plt.grid(True)
    plt.savefig(f'plots/task_2_1_trajectories_B{hmm_model.beta}_S{hmm_model.sigma}_K{hmm_model.K}_T{T_MS}_N{N_TRIALS}.png', dpi=300, bbox_inches='tight')
    plt.show()
    
def plot_sigma_comparison_trajectories(K, T, x0, beta, sigma_values, n_trials):
    plt.figure(figsize=(12, 6))
    plt.title(f"HMM $x_t$ Trajectory (beta={beta}, x0={x0}, K={K}, T={T}, $N_{{\mathrm{{trials}}}}$={n_trials})")


    dt_sim = 1.0 / T
    time_axis_sim = np.arange(T) * dt_sim

    for sigma_val_current in sigma_values:
        hmm_model_sigma = RampModelHMM(K=K, beta=beta, sigma=sigma_val_current, x0=x0)
        
        _, x_traj_sigma, _ = hmm_model_sigma.simulate(Ntrials=n_trials, T=T)
        
        mean_trajectory_sigma = np.mean(x_traj_sigma, axis=0)
        plt.plot(time_axis_sim, mean_trajectory_sigma, label=f"sigma = {sigma_val_current:.3f}")

        stuck_count = 0
        for i in range(n_trials):
            if np.allclose(x_traj_sigma[i,:], x_traj_sigma[i,0]):
                stuck_count +=1
        print(f"For sigma={sigma_val_current:.3f}, {stuck_count}/{n_trials} trajectories appeared stuck at initial value.")
    
    plt.xlabel("Time (s)")
    plt.ylabel("$x_t$")
    plt.ylim(-0.1, 1.1)
    plt.legend()
    plt.grid(True)
    plt.savefig(f'plots/task_2_1_sigma_comparison_K{K}_T{T}_N{n_trials}.png', dpi=300, bbox_inches='tight')
    plt.show()

def analyze_and_plot_accuracy_heatmaps(beta_vals, sigma_vals, x0, K, T, n_trials):
    """
    Calculates the error between continuous and HMM models across a grid
    of beta and sigma values, and plots it as a heatmap.
    """
    cache_dir = os.path.join("plots", "cache")
    os.makedirs(cache_dir, exist_ok=True)
    
    beta_len = len(beta_vals)
    sigma_len = len(sigma_vals)
    cache_filename = os.path.join(cache_dir, f"task_2_1_heatmap_errors_signed_x0{x0:.2f}_K{K}_T{T}_N{n_trials}_B{beta_len}_S{sigma_len}.pickle")

    if os.path.exists(cache_filename):
        with open(cache_filename, 'rb') as f:
            errors = pickle.load(f)
        print(f"Loaded errors from cache: {cache_filename}")
    else:
        rmse_errors = np.zeros((len(sigma_vals), len(beta_vals)))
        signed_errors = np.zeros((len(sigma_vals), len(beta_vals)))
        
        for i, sigma in enumerate(tqdm(sigma_vals)):
            for j, beta in enumerate(beta_vals):
                continuous_model = RampModel(beta=beta, sigma=sigma, x0=x0)
                hmm_model = RampModelHMM(K=K, beta=beta, sigma=sigma, x0=x0)
                
                _, x_continuous_all, _ = continuous_model.simulate(Ntrials=n_trials, T=T)
                _, x_hmm_all, _ = hmm_model.simulate(Ntrials=n_trials, T=T)
                
                mean_x_continuous = np.mean(x_continuous_all, axis=0)
                mean_x_hmm = np.mean(x_hmm_all, axis=0)
                
                # calculate RMSE
                rmse = np.sqrt(np.mean((mean_x_continuous - mean_x_hmm)**2))
                rmse_errors[i, j] = rmse

                # calculate signed mean error
                signed_mean_error = np.mean(mean_x_hmm - mean_x_continuous)
                signed_errors[i, j] = signed_mean_error

        errors = {'rmse': rmse_errors, 'signed': signed_errors}
        with open(cache_filename, 'wb') as f:
            pickle.dump(errors, f)
        print(f"Saved errors to cache: {cache_filename}")

    delta_beta = beta_vals[1] - beta_vals[0]
    delta_sigma_first = sigma_vals[1] - sigma_vals[0]
    delta_sigma_last = sigma_vals[-1] - sigma_vals[-2]
    extent = [
        beta_vals[0] - delta_beta / 2, beta_vals[-1] + delta_beta / 2,
        sigma_vals[0] - delta_sigma_first / 2, sigma_vals[-1] + delta_sigma_last / 2
    ]

    plt.figure(figsize=(10, 8))
    im = plt.imshow(errors['rmse'], aspect='auto', origin='lower', extent=extent, cmap='viridis')
    plt.colorbar(im, label="RMSE of mean $x_t$")
    plt.xlabel(r"$\beta$")
    plt.ylabel(r"$\sigma$")
    # plt.yscale('log')
    plt.title(f"HMM vs Continuous Model Accuracy (RMSE)\n(x0={x0}, K={K}, T={T}, N_trials={n_trials})")
    filename = f'plots/task_2_1_heatmap_rmse_x0{x0}_K{K}_T{T}_N{n_trials}.png'
    plt.savefig(filename, dpi=300, bbox_inches='tight')
    plt.show()

    plt.figure(figsize=(10, 8))
    signed_errors_matrix = errors['signed']
    max_abs_error = np.max(np.abs(signed_errors_matrix))
    im = plt.imshow(signed_errors_matrix, aspect='auto', origin='lower', extent=extent, cmap='coolwarm', vmin=-max_abs_error, vmax=max_abs_error)
    plt.colorbar(im, label="Signed Mean Error (HMM - Continuous)")
    plt.xlabel(r"$\beta$")
    plt.ylabel(r"$\sigma$")
    # plt.yscale('log')
    plt.title(f"HMM vs Continuous Model Accuracy (Signed Error)\n(x0={x0}, K={K}, T={T}, N_trials={n_trials})")
    filename = f'plots/task_2_1_heatmap_signed_error_x0{x0}_K{K}_T{T}_N{n_trials}.png'
    plt.savefig(filename, dpi=300, bbox_inches='tight')
    plt.show()

def main():
    K = 50
    # beta = 1.0
    # sigma = 0.5
    # x0 = 0.0
    # print("Plotting comparison of continous and HHM with T={T_MS}, N_trials={N_TRIALS}")
    # continuous_model = RampModel(beta=beta, sigma=sigma, x0=x0)
    # hmm_model = RampModelHMM(K=K, beta=beta, sigma=sigma, x0=x0)
    # plot_compared_trajectories(continuous_model, hmm_model, T_MS)
 
    # print("Varying Sigma at Beta=0")
    # beta = 0.0
    # x0 = 0.0
    # # calculate approximate critical sigma for HMM
    # sigma_crit = np.sqrt(T_MS) / (K - 1)
    # print(f"critical sigma for T={T_MS}, K={K}: {sigma_crit:.3f}")
    # sigma_values = [sigma_crit * 2, sigma_crit, sigma_crit / 5, sigma_crit / 10]
    # plot_sigma_comparison_trajectories(K=K, 
    #                                    T=T_MS, 
    #                                    x0=x0, 
    #                                    beta=beta, 
    #                                    sigma_values=sigma_values, 
    #                                    n_trials=N_TRIALS)

    print("\n--- HMM Accuracy Analysis ---")
    
    n_grid_points = 15
    beta_vals = np.linspace(0, 4, n_grid_points)
    sigma_vals = np.logspace(np.log10(0.04), np.log10(4), n_grid_points)
    sigma_vals = np.linspace(0.04, 4, n_grid_points)

    x0_heatmap = 0.2
    n_trials_heatmap = 100
    
    analyze_and_plot_accuracy_heatmaps(beta_vals=beta_vals,
                                       sigma_vals=sigma_vals,
                                       x0=x0_heatmap,
                                       K=K,
                                       T=T_MS,
                                       n_trials=n_trials_heatmap)

if __name__ == "__main__":
    main()


2_3_filter_contour.py
import numpy as np
import models
import scipy
import inference
from models_hmm import RampModelHMM
import os
import matplotlib.pyplot as plt

import task_2_3

plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})

np.set_printoptions(legacy='1.25')  # don't show np.float; helps with debug

if __name__ == "__main__":
    num_trials = 30
    num_samples = 10  # on the grid
    K = 50
    smooth_save_filename = "./results/ramp_f_sCE_x0s8.npy"
    filter_save_filename = "./results/ramp_f_fCE_x0s8.npy"

    recompute = False

    T = 100
    rs = np.rint(np.linspace(0, 20, num_samples + 1))[1:]
    betas = np.linspace(0, 4, num_samples)
    sigmas = np.linspace(0, 2, num_samples)
    x0s = np.linspace(0, 1, num_samples)
    Rhs = np.linspace(100, 2000, num_samples)

    ivar1 = x0s
    ivar2 = sigmas

    if os.path.exists(smooth_save_filename) and os.path.exists(filter_save_filename) and not recompute:
        print("loading " + smooth_save_filename + ', ' + filter_save_filename)
        CE_mat = np.load(smooth_save_filename)
        fCE_mat = np.load(filter_save_filename)
    else:

        print("computing")
        CE_mat = np.zeros((num_samples, num_samples))
        fCE_mat = np.zeros((num_samples, num_samples))

        for i1, iv1 in enumerate(ivar1):
            for i2, iv2 in enumerate(ivar2):
                sum_CE = 0
                sum_fCE = 0
                for _ in range(num_trials):
                    ex, fex, _, _, states = task_2_3.ramp_HMM_inference({
                        "x0": iv1,
                        "sigma": iv2,
                        # "beta": b,
                        # "sigma": s,
                        "K": K,
                    }, test_filtering=True)
                    # true_s = (xs * (K - 1)).flatten().astype(int)
                    # bex = task_2_3.compress_states(ex)
                    # bstates = (states == iv2).astype(int)  # TODO if r, set == r

                    # fbex = task_2_3.compress_states(fex)
                    # fbstates = (states == iv2).astype(int)  # TODO if r, set == r

                    sum_CE += task_2_3.cross_entropy(ex, states, time_average=True)
                    sum_fCE += task_2_3.cross_entropy(fex, states, time_average=True)

                CE_mat[i1, i2] = sum_CE / num_trials
                fCE_mat[i1, i2] = sum_fCE / num_trials

            print(f'Progress: {i1 + 1}/{num_samples} (beta)')

        np.save(smooth_save_filename, CE_mat)
        np.save(filter_save_filename, fCE_mat)
        print(f"saved to {smooth_save_filename}")

    # matshow

    # tricontour

    CE_diff = fCE_mat - CE_mat

    ivar1_grid, ivar2_grid = np.meshgrid(ivar1, ivar2, indexing='ij')  # betas, sigmas, indexing='ij')
    ivar1_flat = ivar1_grid.flatten()
    ivar2_flat = ivar2_grid.flatten()
    CE_diff_flat = CE_diff.flatten()

    os.makedirs('plots', exist_ok=True)

    plt.matshow(CE_diff)
    plt.savefig('plots/task_2_3_filter_contour_matshow.png')
    plt.show()

    plt.figure(figsize=(8, 6))
    contour = plt.tricontourf(ivar1_flat, ivar2_flat, CE_diff_flat, levels=20, cmap='viridis')
    plt.colorbar(contour, label='Difference in Cross-Entropy')
    plt.xlabel('x0')
    plt.ylabel('sigma')
    plt.title(r'Ramp: $CE_{smoothed} - CE_{filtered}$ for varying $x_0, sigma$')
    plt.savefig('plots/task_2_3_filter_contour_contour.png')
    plt.show()


utils.py
import numpy as np
import scipy.special
from scipy.optimize import curve_fit

def calculate_psth(spike_trains, t_duration_ms, bin_width_ms):
    # bin = np.convolve(bin, np.ones(bin_width_ms)/bin_width_ms, mode='valid')
    # spike_times = np.linspace(0, t_duration_ms, num = bin.shape[0], endpoint = False)

    # return spike_times, bin * t_duration_ms

    n_trials = spike_trains.shape[0]
    num_bins = int(t_duration_ms / bin_width_ms)
    psth_time_bins_ms = np.arange(num_bins) * bin_width_ms
    binned_sums = np.zeros(num_bins)

    # sum the spikes across trials into bins
    for trial_idx in range(n_trials):
        for bin_idx in range(num_bins):
            start_time = bin_idx * bin_width_ms
            end_time = (bin_idx + 1) * bin_width_ms
            binned_sums[bin_idx] += np.sum(spike_trains[trial_idx, start_time:end_time])
    
    # average and convert to Hz
    mean_spikes_per_bin = binned_sums / n_trials
    psth_values_hz = mean_spikes_per_bin / (bin_width_ms / 1000.0)  # convert to Hz
    
    return psth_time_bins_ms, psth_values_hz

def calculate_fano_factor(spike_trains, t_duration_ms, bin_width_ms):
    n_trials = spike_trains.shape[0]
    num_bins_fano = int(t_duration_ms / bin_width_ms)
    fano_time_bins_ms = np.arange(num_bins_fano) * bin_width_ms
    binned_counts_per_trial = np.zeros((n_trials, num_bins_fano))

    for trial_idx in range(n_trials):
        for bin_idx in range(num_bins_fano):
            start_time = bin_idx * bin_width_ms
            end_time = (bin_idx + 1) * bin_width_ms
            binned_counts_per_trial[trial_idx, bin_idx] = np.sum(spike_trains[trial_idx, start_time:end_time])
            
    mean_counts_per_bin = np.mean(binned_counts_per_trial, axis=0)
    variance_counts_per_trial = np.var(binned_counts_per_trial, axis=0, ddof=0)
    
    fano_factors = np.full_like(mean_counts_per_bin, np.nan, dtype=float)
    
    # calculate Fano factor only where mean is non zero
    non_zero_mean_indices = mean_counts_per_bin != 0
    fano_factors[non_zero_mean_indices] = variance_counts_per_trial[non_zero_mean_indices] / mean_counts_per_bin[non_zero_mean_indices]
    
    return fano_time_bins_ms, fano_factors

def generate_model_parameters(model_type_to_generate, t_duration_ms):
    if model_type_to_generate == 'ramp':
        beta = np.random.uniform(0, 4.0)
        sigma = np.exp(np.random.uniform(np.log(0.04), np.log(4)))
        return {'beta': beta, 'sigma': sigma}
    else:
        m = np.random.uniform(t_duration_ms * 0.25, t_duration_ms * 0.75)
        r = np.random.uniform(0.5, 6.0)
        x0 = np.random.uniform(0, 0.5)
        return {'m': m, 'r': r, 'x0': x0}

def generate_random_model_parameters(t_duration_ms):
    model_type = np.random.choice(['ramp', 'step'])
    if model_type == 'ramp':
        beta = np.random.uniform(0.1, 50.0)
        sigma = np.random.uniform(0.1, 5.0)
        params = {'beta': beta, 'sigma': sigma}
    else:
        # Use the passed t_duration_ms for calculating 'm'
        m = np.random.uniform(t_duration_ms * 0.1, t_duration_ms * 0.9)
        r = np.random.uniform(0.1, 50.0)
        params = {'m': m, 'r': r}
    return params

# --- Ad-hoc Classifier Functions ---

def sigmoid_func(t, L, k, t0, y0):
    """ 
    L: Amplitude of the step (max val - min val)
    k: Steepness of the sigmoid
    t0: Midpoint of the sigmoid
    y0: y(t=0)

    y(t) = y0 + L / (1 + exp(-k * (t - t0)))
    """
    return y0 + L * scipy.special.expit(k * (t - t0))


def ramp_func(t, m, t1, A, b):
    """
    m: Slope of the initial linear segment
    t1: Transition time from linear to exponential
    A: Absolute asymptotic value the curve settles at
    b: y(t=0)

    y(t) = b + m*t                                   for t <= t1
    y(t) = A - (A - y(t1)) * exp(-beta * (t - t1))   for t > t1
      beta = m / (A - y(t1)) to ensure slope continuity
    """
    y = np.zeros_like(t, dtype=float)
    
    # linear line (t < t1)
    y_val_at_t1 = b + m * t1

    linear_indices = np.where(t < t1)[0]
    y[linear_indices] = b + m * t[linear_indices]

    # exponential curve (t > t1)
    exp_indices = np.where(t >= t1)[0]
    if exp_indices.size == 0: # transition is at end ?
        return y

    # if the asymptote is very close to the value at t1, return the asymptote
    if abs(A - y_val_at_t1) < 1e-9: 
        y[exp_indices] = A 
        return y
        
    # if the asymptote is below the value at t1, return a large penalty (we should never go down in our psth)
    if A < y_val_at_t1:
        y[exp_indices] = 1e12
        return y

    beta = m / (A - y_val_at_t1)
    y[exp_indices] = A - (A - y_val_at_t1) * np.exp(-beta * (t[exp_indices] - t1))
    
    return y

def fit_sigmoid(x_data, y_data):
    min_y, max_y = (np.min(y_data), np.max(y_data)) if y_data.size > 0 else (0,1)
    guess_sigmoid = [max_y - min_y, 5.0, 0.5, min_y]
    
    bounds_sigmoid = (
        [0, 1e-3, 0, 0],  
        [max_y*2 +1 if max_y >0 else 2, 100.0, 1.0, max_y+1 if max_y >0 else 1]
    )
    
    guess_sigmoid = [np.clip(guess_sigmoid[i], bounds_sigmoid[0][i], bounds_sigmoid[1][i]) for i in range(4)]

    params_sigmoid, _ = curve_fit(sigmoid_func, x_data, y_data, p0=guess_sigmoid, bounds=bounds_sigmoid, maxfev=10000)
    return params_sigmoid

def fit_ramp(x_data, y_data):
    x_data = np.asarray(x_data, dtype=float)
    y_data = np.asarray(y_data, dtype=float)

    b_guess = y_data[0]
    m_guess = (y_data[1] - y_data[0]) / (x_data[1] - x_data[0])
    A_guess = y_data[-1]
    t1_guess = x_data[-1]/2

    y_at_t1_guess = b_guess + m_guess * t1_guess
    if A_guess <= y_at_t1_guess and m_guess * t1_guess > -b_guess : # check if ramp part is positive
        A_guess = y_at_t1_guess * 1.2 if y_at_t1_guess > 0 else y_at_t1_guess + abs(y_at_t1_guess*0.2) + 1.0


    initial_params = [m_guess, t1_guess, A_guess, b_guess]

    # bounds
    max_y_val = np.max(y_data)
    min_y_val = np.min(y_data)

    bounds = [
        [0.1, 1000],  # m
        [x_data[0], x_data[-1]],  # t1
        [min_y_val * 0.5 if min_y_val > 0 else -max_y_val, max_y_val * 4.0 + 1.0 if max_y_val > 0 else 1000.0],  # A
        [0.0, max_y_val * 1.5 + 1.0]  # b
    ]

    initial_params = [np.clip(initial_params[i], bounds[i][0], bounds[i][1]) for i in range(4)]

    # curve fit expects a different format *sigh*
    lower_bounds = [b[0] for b in bounds]
    upper_bounds = [b[1] for b in bounds]
    
    popt, _ = curve_fit(
        ramp_func,
        x_data,
        y_data,
        p0=initial_params,
        bounds=(lower_bounds, upper_bounds),
        maxfev=10000, 
    )
    
    m_opt, t1_opt, A_opt, b_opt = popt
    
    return m_opt, t1_opt, A_opt, b_opt

def classify_model_by_psth(spike_trains, t_duration_ms, psth_bin_width_ms, show_plot=False):
    import matplotlib.pyplot as plt
    import traceback

    time_bins, psth_hz = calculate_psth(spike_trains, t_duration_ms, psth_bin_width_ms)

    t_data_normalized = time_bins / t_duration_ms
    y_data = psth_hz
    y_data = y_data[~np.isnan(y_data)]

    if y_data.size < 4:
        # print("Warning: y_data is empty after NaN removal in classify_model_by_psth. Returning random choice.")
        return np.random.choice(['ramp', 'step'])

    # fit to sigmoid curve
    ssr_sigmoid = float('inf')

    try:
        # initial guess for sigmoid
        L_sig, k_sig, t0_sig, b_sig_val = fit_sigmoid(t_data_normalized, y_data)
        y_fit_sigmoid = sigmoid_func(t_data_normalized, L_sig, k_sig, t0_sig, b_sig_val)
        ssr_sigmoid = np.sum((y_data - y_fit_sigmoid)**2)
        if show_plot:
            print(f"Sigmoid fit: ssr={ssr_sigmoid:6.2f}, L={L_sig:6.2f}, k={k_sig:6.2f}, t0={t0_sig:6.2f}, b={b_sig_val:6.2f}")

    except Exception:
        if show_plot:
            print(traceback.format_exc())
    
    ssr_ramp = float('inf')

    try:
        m_fit, t1_fit, A_fit, b_ramp_fit = fit_ramp(t_data_normalized, y_data) 
        y_fit_ramp = ramp_func(t_data_normalized, m_fit, t1_fit, A_fit, b_ramp_fit)
        ssr_ramp = np.sum((y_data - y_fit_ramp)**2)
        if show_plot:
            print(f"Ramp fit: ssr={ssr_ramp:.3f}, m={m_fit:.3f}, t1={t1_fit:.3f}, A={A_fit:.3f}, b={b_ramp_fit:.3f}")
    except Exception:
        if show_plot:
            print(traceback.format_exc())
        

    if ssr_ramp < ssr_sigmoid + 10:
        final_classification = 'ramp'
    else:
        final_classification = 'step'


    if show_plot:
        plt.figure(figsize=(10, 6))
        plt.plot(t_data_normalized, y_data, 'ko', label='Original PSTH', markersize=4)
        plt.plot(t_data_normalized, y_fit_sigmoid, 'r--', label=f'Sigmoid Fit (SSR: {ssr_sigmoid:.2f})')
        plt.plot(t_data_normalized, y_fit_ramp, 'g--', label=f'Ramp Fit (SSR: {ssr_ramp:.2f})')
        plt.xlabel("Normalized Time")
        plt.ylabel("PSTH (Hz)")
        plt.title(f"PSTH Fit Classification: {final_classification.upper()}")
        plt.legend()
        plt.grid(True)
        plt.show()

    return final_classification

inference.py
# Credit: Functions here are essentially copies of those in the
# SSM package by Scott Linderman et al. https://github.com/lindermanlab/ssm

import numba
import numpy as np
import numpy.random as npr
from scipy.special import logsumexp as logsumexp_scipy
from scipy.special import gammaln

LOG_EPS = 1e-16


@numba.jit(nopython=True, cache=True)
def logsumexp(x):
    N = x.shape[0]

    # find the max
    m = -np.inf
    for i in range(N):
        m = max(m, x[i])

    # sum the exponentials
    out = 0
    for i in range(N):
        out += np.exp(x[i] - m)

    return m + np.log(out)


@numba.jit(nopython=True, cache=True)
def dlse(a, out):
    K = a.shape[0]
    lse = logsumexp(a)
    for k in range(K):
        out[k] = np.exp(a[k] - lse)


@numba.jit(nopython=True, cache=True)
def forward_pass(pi0,
                 Ps,
                 log_likes,
                 alphas):

    T = log_likes.shape[0]  # number of time steps
    K = log_likes.shape[1]  # number of discrete states

    assert Ps.shape[0] == T-1 or Ps.shape[0] == 1
    assert Ps.shape[1] == K
    assert Ps.shape[2] == K
    assert alphas.shape[0] == T
    assert alphas.shape[1] == K

    # Check if we have heterogeneous transition matrices.
    # If not, save memory by passing in log_Ps of shape (1, K, K)
    hetero = (Ps.shape[0] == T-1)
    alphas[0] = np.log(pi0) + log_likes[0]
    for t in range(T-1):
        m = np.max(alphas[t])
        alphas[t+1] = np.log(np.dot(np.exp(alphas[t] - m), Ps[t * hetero])) + m + log_likes[t+1]
    return logsumexp(alphas[T-1])


@numba.jit(nopython=True, cache=True)
def backward_pass(Ps,
                  log_likes,
                  betas):

    T = log_likes.shape[0]  # number of time steps
    K = log_likes.shape[1]  # number of discrete states

    assert Ps.shape[0] == T-1 or Ps.shape[0] == 1
    assert Ps.shape[1] == K
    assert Ps.shape[2] == K
    assert betas.shape[0] == T
    assert betas.shape[1] == K

    # Check if we have heterogeneous transition matrices.
    # If not, save memory by passing in log_Ps of shape (1, K, K)
    hetero = (Ps.shape[0] == T-1)
    tmp = np.zeros(K)

    # Initialize the last output
    betas[T-1] = 0
    for t in range(T-2,-1,-1):
        tmp = log_likes[t+1] + betas[t+1]
        m = np.max(tmp)
        betas[t] = np.log(np.dot(Ps[t * hetero], np.exp(tmp - m))) + m


def hmm_normalizer(pi0, Ps, ll):
    T, K = ll.shape
    alphas = np.zeros((T, K))

    if Ps.ndim == 2:
        Ps = Ps[None, :, :]
    assert Ps.ndim == 3

#     # Make sure everything is C contiguous
#     pi0 = to_c(pi0)
#     Ps = to_c(Ps)
#     ll = to_c(ll)

    forward_pass(pi0, Ps, ll, alphas)
    return logsumexp(alphas[-1])


def hmm_expected_states(pi0, Ps, ll, filter=False):
    """
    Calculates the posterior probabilities of HMM states given the observations, implicitly input via
    the matrix of observation log-likelihoods.
    :param pi0: shape (K,), vector of initial state probabilities.
    :param Ps: shape (K, K): state transition matrix (time-homogeneous case), or:
               shape (T-1, K, K): temporal sequence

    :param ll: shape (T, K): matrix of log-likelihoods (i.e. log observation probabilities
                             evaluated for the actual observations).
    :param filter: False by default. If True the function calculates the so-called "filtered"
                   posterior probabilities which only take into account observations until time t
                   (as opposed to all observations until time T (with Python index T-1), which is what
                   is calculated by default).
    :return:
    expected_states: this is an array of shape (T, K) with the t-th row giving the
                     posterior probabilities of the different Markov states,
                     conditioned on the sequence of observations.
    normalizer: this is the model log-likelihood, i.e. it is the log-probability of the entire sequence
                of observations (given the model parameters, which are implicit here).
    """
    T, K = ll.shape

    if Ps.ndim == 2:
        Ps = Ps[None, :, :]
    assert Ps.ndim == 3

    alphas = np.zeros((T, K))
    forward_pass(pi0, Ps, ll, alphas)
    normalizer = logsumexp(alphas[-1])

    betas = np.zeros((T, K))
    if not filter:
        backward_pass(Ps, ll, betas)

    # Compute P[x_t | n_{1:T}] for t = 1, ..., T (if filter = True, calculate P[x_t | n_{1:t}] instead).
    expected_states = alphas + betas
    expected_states -= logsumexp_scipy(expected_states, axis=1, keepdims=True)
    expected_states = np.exp(expected_states)

    # expected_joints calculation removed

    return expected_states, normalizer


@numba.jit(nopython=True, cache=True)
def backward_sample(Ps, log_likes, alphas, us, zs):
    T = log_likes.shape[0]
    K = log_likes.shape[1]
    assert Ps.shape[0] == T-1 or Ps.shape[0] == 1
    assert Ps.shape[1] == K
    assert Ps.shape[2] == K
    assert alphas.shape[0] == T
    assert alphas.shape[1] == K
    assert us.shape[0] == T
    assert zs.shape[0] == T

    lpzp1 = np.zeros(K)
    lpz = np.zeros(K)

    # Trick for handling time-varying transition matrices
    hetero = (Ps.shape[0] == T-1)

    for t in range(T-1,-1,-1):
        # compute normalized log p(z[t] = k | z[t+1])
        lpz = lpzp1 + alphas[t]
        Z = logsumexp(lpz)

        # sample
        acc = 0
        zs[t] = K-1
        for k in range(K):
            acc += np.exp(lpz[k] - Z)
            if us[t] < acc:
                zs[t] = k
                break

        # set the transition potential
        if t > 0:
            lpzp1 = np.log(Ps[(t-1) * hetero, :, int(zs[t])] + LOG_EPS)


@numba.jit(nopython=True, cache=True)
def _hmm_sample(pi0, Ps, ll):
    T, K = ll.shape

    # Forward pass gets the predicted state at time t given
    # observations up to and including those from time t
    alphas = np.zeros((T, K))
    forward_pass(pi0, Ps, ll, alphas)

    # Sample backward
    us = npr.rand(T)
    zs = -1 * np.ones(T)
    backward_sample(Ps, ll, alphas, us, zs)
    return zs


def hmm_sample(pi0, Ps, ll):
    return _hmm_sample(pi0, Ps, ll).astype(int)


@numba.jit(nopython=True, cache=True)
def _viterbi(pi0, Ps, ll):
    """
    This is modified from pyhsmm.internals.hmm_states
    by Matthew Johnson.
    """
    T, K = ll.shape

    # Check if the transition matrices are stationary or
    # time-varying (hetero)
    hetero = (Ps.shape[0] == T-1)
    if not hetero:
        assert Ps.shape[0] == 1

    # Pass max-sum messages backward
    scores = np.zeros((T, K))
    args = np.zeros((T, K))
    for t in range(T-2,-1,-1):
        vals = np.log(Ps[t * hetero] + LOG_EPS) + scores[t+1] + ll[t+1]
        for k in range(K):
            args[t+1, k] = np.argmax(vals[k])
            scores[t, k] = np.max(vals[k])

    # Now maximize forwards
    z = np.zeros(T)
    z[0] = (scores[0] + np.log(pi0 + LOG_EPS) + ll[0]).argmax()
    for t in range(1, T):
        z[t] = args[t, int(z[t-1])]

    return z


def viterbi(pi0, Ps, ll):
    """
    Find the most likely state sequence
    """
    return _viterbi(pi0, Ps, ll).astype(int)


def poisson_logpdf(counts, lambdas, mask=None):
    """
    Compute the log probability of a Poisson distribution.
    This will broadcast as long as data and lambdas have the same
    (or at least compatible) leading dimensions.
    Parameters
    ----------
    counts : array_like of shape (T,) or (Ntrials, T),
             array of integer counts for which to evaluate the log probability
    lambdas : array_like of shape (K,)
        The rates (mean counts) of the Poisson distribution(s)
    Returns
    -------
    lls : array_like with shape (T, K), or (Ntrials, T, K) depending on
          the shape of 'counts'.
        Log probabilities under the Poisson distribution(s).
    """
    assert counts.dtype in (int, np.int8, np.int16, np.int32, np.int64)
    assert counts.ndim == 1 or counts.ndim == 2
    if counts.ndim == 1:
        counts = counts[:, None]
    elif counts.ndim == 2:
        counts = counts[:,:,None]

    # Compute log pdf
    lambdas[lambdas == 0] = 1e-8
    lls = -gammaln(counts + 1) - lambdas + counts * np.log(lambdas)
    return lls

2_3_plot_maker.py
import numpy as np
import models
import scipy
import inference
from models_hmm import RampModelHMM
import os
import matplotlib.pyplot as plt

import task_2_3


num_trials = 600
num_samples = 15 # on the grid
K = 50
save_filename = "./results/CE_15x0x15rh.npy" # TODO

    # TODO
T = 100
ms = np.linspace(T * 0.1, T * 0.75, num_samples)
rs = np.rint(np.linspace(0, 20, num_samples+1))[1:]
betas = np.linspace(0, 4, num_samples)
sigmas = np.linspace(0, 4, num_samples)
x0s = np.linspace(0.2, 1, num_samples)
Rhs = np.linspace(0, 500, num_samples)

# TODO changeme
ivar1 = x0s # x-axis
ivar2 = Rhs

print("loading " + save_filename)
CE_mat = np.load(save_filename)



iv1_grid, iv2_grid = np.meshgrid(ivar1, ivar2, indexing='ij')
iv1_flat = iv1_grid.flatten()
iv2_flat = iv2_grid.flatten()
CE_flat = CE_mat.flatten()

os.makedirs('plots', exist_ok=True)


plt.figure(figsize=(8 * 0.6, 6 * 0.6))
contour = plt.tricontourf(iv1_flat, iv2_flat, CE_flat, levels=20, cmap='viridis')
plt.colorbar(contour, label='Cross-Entropy (CE)')
plt.xlabel('x0') # TODO
plt.ylabel('Rh') # TODO
plt.title(r'Ramp: CE, varying $x_0, Rh$') # TODO
plt.savefig('plots/ramp_x0Rh_smol.png')
plt.show()


w3_23_B.py
import numpy as np
import os
import argparse
import concurrent.futures
from tqdm import tqdm
from collections import OrderedDict as OD
import scipy.special
from scipy.stats import norm, truncnorm
from scipy.optimize import curve_fit
import pickle
from pathlib import Path

from models_hmm import RampModelHMM, StepModelHMM
import w3_utils
from utils import calculate_psth, classify_model_by_psth

# --- Core Logic for Task 3.2.3 ---

def calculate_log_prior_grid(param_grid, param_ranges, sigma_frac):
    log_prior_grid = np.zeros_like(param_grid, dtype=float)
    for idx, params in np.ndenumerate(param_grid):
        log_prob = 0
        for name, (min_p, max_p) in param_ranges.items():
            if name in params:
                mean_p, std_p = (min_p + max_p) / 2, (max_p - min_p) * sigma_frac
                if std_p > 0:
                    log_prob += norm.logpdf(params[name], loc=mean_p, scale=std_p)
        log_prior_grid[idx] = log_prob
    return log_prior_grid - scipy.special.logsumexp(log_prior_grid)

def _comparison_worker(args_tuple):
    (true_model_type, prior_type, ramp_ranges, step_ranges, sigma_frac, 
     ramp_grid, step_grid, ramp_log_prior, step_log_prior,
     K, T, Rh, x0, n_trials, bin_w) = args_tuple

    if prior_type == 'gaussian':
        if true_model_type == 'ramp':
            params = {n: truncnorm.rvs((min_p - (min_p+max_p)/2)/((max_p-min_p)*sigma_frac), (max_p - (min_p+max_p)/2)/((max_p-min_p)*sigma_frac), loc=(min_p+max_p)/2, scale=(max_p-min_p)*sigma_frac) for n, (min_p, max_p) in ramp_ranges.items()}
            model = RampModelHMM(**params, x0=x0, K=K, Rh=Rh)
            data, _, _ = model.simulate(Ntrials=n_trials, T=T)
        else: # step
            params = {n: truncnorm.rvs((min_p - (min_p+max_p)/2)/((max_p-min_p)*sigma_frac), (max_p - (min_p+max_p)/2)/((max_p-min_p)*sigma_frac), loc=(min_p+max_p)/2, scale=(max_p-min_p)*sigma_frac) for n, (min_p, max_p) in step_ranges.items() if n != 'r'}
            params['r'] = np.random.choice(np.arange(step_ranges['r'][0], step_ranges['r'][1]+1))
            model = StepModelHMM(**params, x0=x0, Rh=Rh)
            data, _, _ = model.simulate_exact(Ntrials=n_trials, T=T, delay_compensation=True)
    elif prior_type == 'uniform':
        if true_model_type == 'ramp':
            params = {n: np.random.uniform(min_p, max_p) for n, (min_p, max_p) in ramp_ranges.items()}
            model = RampModelHMM(**params, x0=x0, K=K, Rh=Rh)
            data, _, _ = model.simulate(Ntrials=n_trials, T=T)
        else: # step
            params = {n: np.random.uniform(min_p, max_p) for n, (min_p, max_p) in step_ranges.items() if n != 'r'}
            params['r'] = np.random.randint(step_ranges['r'][0], step_ranges['r'][1]+1)
            model = StepModelHMM(**params, x0=x0, Rh=Rh)
            data, _, _ = model.simulate_exact(Ntrials=n_trials, T=T, delay_compensation=True)

    ramp_llh = w3_utils.ramp_LLH(data, ramp_grid)
    step_llh = w3_utils.step_LLH(data, step_grid)
    ramp_marginal = scipy.special.logsumexp(ramp_llh + ramp_log_prior)
    step_marginal = scipy.special.logsumexp(step_llh + step_log_prior)
    bayes_correct = (1 if ramp_marginal > step_marginal else 0) if true_model_type == 'ramp' else (1 if step_marginal > ramp_marginal else 0)

    adhoc_pred = classify_model_by_psth(data, T, bin_w)
    adhoc_correct = 1 if adhoc_pred == true_model_type else 0
    return bayes_correct, adhoc_correct

def main():
    parser = argparse.ArgumentParser(description="Task 3.2.3: Compare Bayesian and Ad-hoc Classifiers")
    parser.add_argument('--n_datasets', type=int, default=100)
    parser.add_argument('--n_trials', type=int, default=300)
    parser.add_argument('--m_grid', type=int, default=10)
    parser.add_argument('--prior', type=str, default='gaussian', choices=['gaussian', 'uniform'], help="Prior to use for data generation and inference.")
    parser.add_argument('--no_cache', action='store_true', help="Disable caching and force re-computation.")
    args = parser.parse_args()

    K, T_MS, RH, X0, SIGMA_FRAC, PSTH_BIN_W = 50, 100, 50, 0.2, 0.25, 25
    
    ramp_ranges = OD([('beta', (0, 4)), ('sigma', (0.04, 4))])
    step_ranges = OD([('m', (0, T_MS * 3/4)), ('r', (1, 6))])

    ramp_specs = OD(list(ramp_ranges.items()) + [('x0', X0), ('K', K), ('T', T_MS), ('Rh', RH)])
    step_specs = OD(list(step_ranges.items()) + [('x0', X0), ('T', T_MS), ('Rh', RH)])
    for k in ['m', 'r']:
        step_specs[k] = np.arange(step_ranges[k][0], step_ranges[k][1]+1) if k == 'r' else np.linspace(*step_ranges[k], args.m_grid)
    ramp_specs['sigma'] = np.linspace(*ramp_ranges['sigma'], args.m_grid)
    ramp_specs['beta'] = np.linspace(*ramp_ranges['beta'], args.m_grid)

    ramp_grid = w3_utils.make_params_grid(ramp_specs)
    step_grid = w3_utils.make_params_grid(step_specs)
    
    if args.prior == 'gaussian':
        ramp_log_prior = calculate_log_prior_grid(ramp_grid, ramp_ranges, SIGMA_FRAC)
        step_log_prior = calculate_log_prior_grid(step_grid, step_ranges, SIGMA_FRAC)
    else: # uniform
        ramp_log_prior = w3_utils.uniform_prior(ramp_grid)
        step_log_prior = w3_utils.uniform_prior(step_grid)

    cache_dir = Path("cache")
    cache_dir.mkdir(exist_ok=True)

    print(f"--- Comparing Classifiers | Prior: {args.prior.upper()} | N_datasets={args.n_datasets}, N_trials={args.n_trials}, Sigma_frac={SIGMA_FRAC} ---")
    totals = {'bayes': {'ramp': 0, 'step': 0}, 'adhoc': {'ramp': 0, 'step': 0}}
    
    for model_type in ['ramp', 'step']:
        print(f"\nGenerating data from {model_type.capitalize()} model...")
        
        cache_filename = f"task3.2.3_{model_type}_p-{args.prior}_N{args.n_datasets}_T{args.n_trials}_M{args.m_grid}_S{SIGMA_FRAC}.pkl"
        cache_path = cache_dir / cache_filename
        
        results = []
        if cache_path.exists() and not args.no_cache:
            try:
                with open(cache_path, 'rb') as f:
                    results = pickle.load(f)
                print(f"Loaded {len(results)} cached results from {cache_path}")
            except (pickle.UnpicklingError, EOFError):
                 print(f"Cache file {cache_path} is corrupted. Starting fresh.")
                 results = []

        n_remaining = args.n_datasets - len(results)

        if n_remaining <= 0:
            print(f"Found {len(results)} cached results, which is sufficient. Skipping computation.")
        else:
            print(f"Found {len(results)} cached results. Running {n_remaining} more simulations.")
            tasks = [(model_type, args.prior, ramp_ranges, step_ranges, SIGMA_FRAC, 
                      ramp_grid, step_grid, ramp_log_prior, step_log_prior,
                      K, T_MS, RH, X0, args.n_trials, PSTH_BIN_W) for _ in range(n_remaining)]
            
            with concurrent.futures.ProcessPoolExecutor() as executor:
                new_results_iterator = executor.map(_comparison_worker, tasks)
                
                for res in tqdm(new_results_iterator, total=n_remaining, desc=f"Running {model_type}"):
                    results.append(res)
                    with open(cache_path, 'wb') as f:
                        pickle.dump(results, f)

        if results:
            bayes_correct, adhoc_correct = zip(*results)
            totals['bayes'][model_type] = np.sum(bayes_correct)
            totals['adhoc'][model_type] = np.sum(adhoc_correct)

    print("\n" + "="*20 + " RESULTS " + "="*20)
    for name, t in totals.items():
        ramp_acc = (t['ramp'] / args.n_datasets * 100) if args.n_datasets > 0 else 0
        step_acc = (t['step'] / args.n_datasets * 100) if args.n_datasets > 0 else 0
        total_acc = (ramp_acc + step_acc) / 2
        print(f"\n{name.capitalize()} Classifier:")
        print(f"  Accuracy on Ramp data: {ramp_acc:.1f}%")
        print(f"  Accuracy on Step data: {step_acc:.1f}%")
        print(f"  {'':-^30}\n  Overall Accuracy:      {total_acc:.1f}%")
    print("="*49)

if __name__ == '__main__':
    main() 

w4_11.py
import numpy as np
import matplotlib.pyplot as plt
from collections import OrderedDict as OD
import scipy.special
import os
from scipy.interpolate import griddata
import w3_2


import w3_utils
from models_hmm import RampModelHMM

var = lambda a, b, frac: ((b-a) * frac) ** 2
mean = lambda a, b: (b+a)/2

if __name__ == "__main__":
    K = 25
    T_MS = 100
    RH = 20
    M_GRID = 15
    X0 = 0.5
    # N_DATASETS = 50
    # N_TRIALS = 5

    # STD_FRACTION = 0.25

    # TODO changeme
    BETA_RANGE = (0, 4)
    SIGMA_RANGE = (0.04, 4)

    M_RANGE = (T_MS * 0.25, T_MS * 0.75)
    R_RANGE = (1, 6)

    ramp_param_specs = OD([
        ('beta', np.linspace(*BETA_RANGE, M_GRID)),
        ('sigma', np.exp(np.linspace(np.log(SIGMA_RANGE[0]),
                                     np.log(SIGMA_RANGE[1]),
                                     M_GRID))),
        ('x0', X0),
        ('K', K),
        ('T', T_MS),
        ('Rh', RH)
    ])

    step_param_specs = OD([('m', list(M_RANGE) + [M_GRID]),
                ('r', list(R_RANGE) + [6]),
                ('x0', X0),
                ('K', K),
                ('T', T_MS),
                ('Rh', RH)])

    ramp_params_grid = w3_utils.make_params_grid(ramp_param_specs)
    step_params_grid = w3_utils.make_params_grid(step_param_specs)

    uniform_ramp_posterior = w3_utils.uniform_prior(ramp_params_grid)
    uniform_step_posterior = w3_utils.uniform_prior(step_params_grid)



    N_DATASETS = 96
    # N_TRIALS = 30

    # 4_11

    # we prob want to do this for n_trials = 5 10 15 20 30 50

    N_TRIALS_LIST = [50]

    # BASELINE

    for N_TRIALS in N_TRIALS_LIST:
        fn = "./results/UU_D" + str(N_DATASETS) + "_shape1_T" + str(N_TRIALS) + ".csv"

        w3_2.model_selection(
            ramp_params_grid, step_params_grid,
            uniform_ramp_posterior, uniform_step_posterior,  # generating
            uniform_ramp_posterior, uniform_step_posterior,  # inference
            N_DATASETS=N_DATASETS, N_TRIALS=N_TRIALS,
            ramp_gamma_shape=1, step_gamma_shape=1,
            # format: generating: G/U; inference: G/U; n. datasets, n. trials
            # if G, append std_fraction on front
            save_to=os.path.join(os.getcwd(), fn)
        )

        w3_2.plot_heatmap(fn, 'Uniform prior, shape=1, ' + str(N_TRIALS) + ' trials/dataset')
        w3_2.plot_confusion_matrix(fn, 'Uniform prior, shape=1, ' + str(N_TRIALS) + ' trials/dataset',
                                   save_name=fn[:-4] + '.png')

        # TEST 1

        fn = "./results/UU_D" + str(N_DATASETS) + "_shape3_T" + str(N_TRIALS) + ".csv"

        w3_2.model_selection(
            ramp_params_grid, step_params_grid,
            uniform_ramp_posterior, uniform_step_posterior,  # generating
            uniform_ramp_posterior, uniform_step_posterior,  # inference
            N_DATASETS=N_DATASETS, N_TRIALS=N_TRIALS,
            ramp_gamma_shape=5, step_gamma_shape=5,
            # format: generating: G/U; inference: G/U; n. datasets, n. trials
            # if G, append std_fraction on front
            save_to=os.path.join(os.getcwd(), fn)
        )

        w3_2.plot_heatmap(fn, 'Uniform prior, shape=3, ' + str(N_TRIALS) + ' trials/dataset')
        w3_2.plot_confusion_matrix(fn, 'Uniform prior, shape=3, ' + str(N_TRIALS) + ' trials/dataset',
                                   save_name=fn[:-4] + '.png')

        # TEST 2

        fn = "./results/UU_D" + str(N_DATASETS) + "_shape5_T" + str(N_TRIALS) + ".csv"

        w3_2.model_selection(
            ramp_params_grid, step_params_grid,
            uniform_ramp_posterior, uniform_step_posterior,  # generating
            uniform_ramp_posterior, uniform_step_posterior,  # inference
            N_DATASETS=N_DATASETS, N_TRIALS=N_TRIALS,
            ramp_gamma_shape=9, step_gamma_shape=9,
            # format: generating: G/U; inference: G/U; n. datasets, n. trials
            # if G, append std_fraction on front
            save_to=os.path.join(os.getcwd(), fn)
        )

        w3_2.plot_heatmap(fn, 'Uniform prior, shape=5, ' + str(N_TRIALS) + ' trials/dataset')
        w3_2.plot_confusion_matrix(fn, 'Uniform prior, shape=5, ' + str(N_TRIALS) + ' trials/dataset',
                                   save_name=fn[:-4] + '.png')

wk4_2.py
import numpy as np
import matplotlib.pyplot as plt
import os
from matplotlib.lines import Line2D

plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})

import models
from utils import calculate_psth
from utils import calculate_fano_factor

T = 1000
N_TRIALS = 5000
PSTH_BIN_WIDTH_MS = 25

os.makedirs('cache', exist_ok=True)

step_fano_data = []

# step model plots

fig1 = plt.figure()
fig2 = plt.figure()
fig3 = plt.figure()

for g in np.array([1,3,5]):
    model = models.StepModel(m=T/2, r=2, isi_gamma_shape=g)

    cache_fn_main = f'cache/step_m{model.m}_r{model.r}_g{g}_nt{N_TRIALS}_T{T}.npz'
    if os.path.exists(cache_fn_main):
        print(f"Loading cached simulation from {cache_fn_main}")
        data = np.load(cache_fn_main)
        spikes, jumps = data['spikes'], data['jumps']
    else:
        print(f"Running simulation and caching to {cache_fn_main}")
        spikes, jumps, _ = model.simulate(Ntrials=N_TRIALS, T=T)
        np.savez(cache_fn_main, spikes=spikes, jumps=jumps)
    
    plt.figure(fig1.number)
    plt.hist(jumps, alpha=0.5, label=f'm={model.m}, r={model.r}, Shape={g}')

    # spike raster
    plt.figure(figsize=(10, 6))
    for trial_idx in range(10):
        spike_times_trial = np.where(spikes[trial_idx, :] > 0)[0]
        plt.plot(spike_times_trial, np.ones_like(spike_times_trial) * trial_idx, '|', color='black', markersize=5)
        
        plt.plot(jumps[trial_idx], trial_idx, 'ro', markersize=5, label='Jump Time' if trial_idx == 0 else "")

    plt.xlabel("Time (ms)")
    plt.ylabel("Trial Number")
    plt.title(f"Step Model - Spike Raster (m={model.m}, r={model.r}, Shape={g})")
    plt.ylim(-1, 10)
    if N_TRIALS > 0: plt.legend()
    plt.savefig(f'plots/task_4_2_step_raster_shape={g}.png', dpi=300, bbox_inches='tight')
    
    # psth
    psth_time_bins_ms, psth_values_hz = calculate_psth(spikes, T, PSTH_BIN_WIDTH_MS)
    plt.figure(fig2.number)
    plt.plot(psth_time_bins_ms, psth_values_hz, label=f'm={model.m}, r={model.r}, Shape={g}')
    
    # fano
    cache_fn_fano = f'cache/step_m{model.m}_r{model.r}_g{g}_nt50000_T{T}_fano.npz'
    if os.path.exists(cache_fn_fano):
        print(f"Loading cached Fano data from {cache_fn_fano}")
        data = np.load(cache_fn_fano)
        spikes_fano = data['spikes']
    else:
        print(f"Running Fano simulation and caching to {cache_fn_fano}")
        spikes_fano, _, _ = model.simulate(Ntrials=50000, T=T)
        np.savez(cache_fn_fano, spikes=spikes_fano)
        
    fano_time_bins_ms, fano_factors = calculate_fano_factor(spikes_fano, T, PSTH_BIN_WIDTH_MS)
    step_fano_data.append((fano_time_bins_ms, fano_factors, g))
    plt.figure(fig3.number)
    plt.plot(fano_time_bins_ms, fano_factors, label=f'm={model.m}, r={model.r}, Shape={g}')

plt.figure(fig1.number)
plt.xlabel('Time (ms)')
plt.ylabel('Frequency')
plt.title('Jump Times Histogram')
plt.legend()
plt.grid()
filename = f"plots/task_4_2_step_hist.png"
plt.savefig(filename)

plt.figure(fig2.number)
plt.xlabel('Time (ms)')
plt.ylabel('Firing Rate (Hz)')
plt.title('Step Model PSTH For Different Gamma Shapes')
plt.legend()
plt.grid()
filename = f"plots/task_4.2_step_psth.png"
plt.savefig(filename)

plt.figure(fig3.number)
plt.plot(fano_time_bins_ms, np.ones(len(fano_time_bins_ms)), 'k--', label='Poisson (Fano=1)')
plt.xlabel('Time (ms)')
plt.ylabel('Fano Factor')
plt.title('Step Model Fano Factor For Different Gamma Shapes')
plt.legend()
plt.grid()
filename = f"plots/task_4_2_step_fano.png"
plt.savefig(filename)
print('ramp models')
# ramp model plots

ramp_fano_data = []

fig4 = plt.figure()
fig5 = plt.figure()
fig6 = plt.figure()

for g in np.array([1,3,5]):
    model = models.RampModel(beta=2, isi_gamma_shape=g)

    cache_fn_main = f'cache/ramp_b{model.beta}_s{model.sigma}_g{g}_nt{N_TRIALS}_T{T}.npz'
    if os.path.exists(cache_fn_main):
        print(f"Loading cached simulation from {cache_fn_main}")
        data = np.load(cache_fn_main)
        spikes, xs = data['spikes'], data['xs']
    else:
        print(f"Running simulation and caching to {cache_fn_main}")
        spikes, xs, _ = model.simulate(Ntrials=N_TRIALS, T=T)
        np.savez(cache_fn_main, spikes=spikes, xs=xs)

    # calculate bound hitting times
    bound_hitting_times = []
    for trial_idx in range(N_TRIALS):
        trial_xs = xs[trial_idx, :]
        hit_times = np.where(trial_xs >= 1.0)[0]
        if len(hit_times) > 0:
            bound_hitting_times.append(hit_times[0])
        else:
            bound_hitting_times.append(T)

    # histogram bound hitting times
    plt.figure(fig4.number)
    plt.hist(bound_hitting_times, alpha=0.5, label=f'={model.beta}, ={model.sigma}, Shape={g}')


    # spike raster
    plt.figure(figsize=(10, 6))
    for trial_idx in range(10):
        spike_times_trial = np.where(spikes[trial_idx, :] > 0)[0]
        plt.plot(spike_times_trial, np.ones_like(spike_times_trial) * trial_idx, '|', color='black', markersize=5)
        plt.plot(bound_hitting_times[trial_idx], trial_idx, 'ro', markersize=5, 
                     label='Bound Hit Time' if trial_idx == 0 else "")
        
    plt.xlabel("Time (ms)")
    plt.ylabel("Trial Number")
    plt.title(f"Ramp Model - Spike Raster (={model.beta}, ={model.sigma}, Shape={g})")
    plt.ylim(-1, 10)
    if N_TRIALS > 0: plt.legend()
    plt.savefig(f'plots/task_4_2_ramp_raster_shape={g}.png', dpi=300, bbox_inches='tight')

    # psth
    psth_time_bins_ms, psth_values_hz = calculate_psth(spikes, T, PSTH_BIN_WIDTH_MS)
    plt.figure(fig5.number)
    plt.plot(psth_time_bins_ms, psth_values_hz, label=f'={model.beta}, ={model.sigma}, Shape={g}')
    
    # fano
    cache_fn_fano = f'cache/ramp_b{model.beta}_s{model.sigma}_g{g}_nt50000_T{T}_fano.npz'
    if os.path.exists(cache_fn_fano):
        print(f"Loading cached Fano data from {cache_fn_fano}")
        data = np.load(cache_fn_fano)
        spikes_fano = data['spikes']
    else:
        print(f"Running Fano simulationand caching to {cache_fn_fano}")
        spikes_fano, _, _ = model.simulate(Ntrials=50000, T=T)
        np.savez(cache_fn_fano, spikes=spikes_fano)
        
    fano_time_bins_ms, fano_factors = calculate_fano_factor(spikes_fano, T, PSTH_BIN_WIDTH_MS)
    ramp_fano_data.append((fano_time_bins_ms, fano_factors, g))
    plt.figure(fig6.number)
    plt.plot(fano_time_bins_ms, fano_factors, label=f'={model.beta}, ={model.sigma}, Shape={g}')

plt.figure(fig4.number)
plt.xlabel('Time (ms)')
plt.ylabel('Frequency')
plt.title('Hit Times Histogram')
plt.legend()
plt.grid()
filename = f"plots/task_4_2_ramp_hist.png"
plt.savefig(filename)

plt.figure(fig5.number)
plt.xlabel('Time (ms)')
plt.ylabel('Firing Rate (Hz)')
plt.title('Ramp Model PSTH For Different Gamma Shapes')
plt.legend()
plt.grid()
filename = f"plots/task_4_2_ramp_psth.png"
plt.savefig(filename)

plt.figure(fig6.number)
plt.plot(fano_time_bins_ms, np.ones(len(fano_time_bins_ms)), 'k--', label='Poisson (Fano=1)')
plt.xlabel('Time (ms)')
plt.ylabel('Fano Factor')
plt.title('Ramp Model Fano Factor For Different Gamma Shapes')
plt.legend()
plt.grid()
filename = f"plots/task_4_2_ramp_fano.png"
plt.savefig(filename)

# --- Combined Fano Factor Plot (Styled like w4_12_plots.py) ---
plt.figure(figsize=(12, 8))
colors = {1: 'blue', 3: 'green', 5: 'red'}

# Plot Step Fano Factors (solid lines)
for bins, factors, g in step_fano_data:
    plt.plot(bins, factors, color=colors[g], linestyle='-')

# Plot Ramp Fano Factors (dashed lines)
for bins, factors, g in ramp_fano_data:
    plt.plot(bins, factors, color=colors[g], linestyle='--')

plt.xlabel('Time (ms)')
plt.ylabel('Fano Factor')
plt.title('Ramp and Step Model Fano Factor vs. Gamma Shapes')
plt.grid(True)
plt.ylim(0, 1.5)

# Create the two-part legend
legend_elements_conditions = [
    Line2D([0], [0], color=colors[1], lw=2, label='Shape=1'),
    Line2D([0], [0], color=colors[3], lw=2, label='Shape=3'),
    Line2D([0], [0], color=colors[5], lw=2, label='Shape=5'),
    Line2D([0], [0], color='k', linestyle=':', lw=2, label='Poisson (Fano=1)')
]

legend_elements_models = [
    Line2D([0], [0], color='gray', linestyle='-', label='Step Model'),
    Line2D([0], [0], color='gray', linestyle='--', label='Ramp Model')
]

# Add the Poisson reference line (plotted last to appear in legend correctly if needed)
if ramp_fano_data:
    last_bins = ramp_fano_data[-1][0]
    plt.plot(last_bins, np.ones(len(last_bins)), 'k:', lw=2)


ax = plt.gca()
leg1 = ax.legend(handles=legend_elements_conditions, title='Gamma Shape', loc='upper right')
ax.add_artist(leg1)
leg2 = ax.legend(handles=legend_elements_models, title='Model Type', loc='center right')


plt.savefig("plots/task_4_2_fano_combined.png")
plt.show()

2_3_ridgeline_CE.py
# generate ridgeline CE plots

import numpy as np
import models
import scipy
import inference
from models_hmm import RampModelHMM
import os
import matplotlib.pyplot as plt
import pandas as pd
import joypy
import matplotlib.cm as cm

import task_2_3

np.set_printoptions(legacy='1.25')  # don't show np.float; helps with debug

if __name__ == "__main__":
    # Step version

    num_trials = 500 # trials per parameter combo
    num_samples = 15 # on parameter space
    T = 250 # 300 for r-plot, 100 otw
    save_filename = "./results/ridgeline_15r_T250.npy" # TODO changeme
    recompute = False

    ms = np.linspace(T * 0.25, T * 0.75, num_samples) # TODO define
    rs = np.rint(np.linspace(0, 100, num_samples + 1)[1:])

    ivar = rs # the independent var in this model; change this line
    # r = 10
    m = 100 # special params to visualize r

    if os.path.exists(save_filename) and not recompute:
        print("loading " + save_filename)
        CE_mat = np.load(save_filename)
    else:
        print("computing")
        CE_mat = np.zeros((num_samples, T))

        for i1, iv in enumerate(ivar):  # iv for independent variable
            sum_CE = 0
            for _ in range(num_trials):
                ex, expected_s, states = task_2_3.step_HMM_inference({
                    # "x0": 0.02,
                    "r": iv,
                    "m": m,
                    # "sigma": s, # for now
                    "T": T
                })

                bex = task_2_3.compress_states(ex)
                bstates = (states == iv).astype(int)
                # TODO change r to iv if ivar = rs sorry for the spaghetti code lmao
                sum_CE += task_2_3.cross_entropy(bex, bstates)

            CE_mat[i1] = sum_CE / num_trials

            print(f'Progress: {i1 + 1}/{num_samples} (iv)')

        np.save(save_filename, CE_mat)
        print(f"saved to {save_filename}")

    # smooth and take the negative differential
    dCE = np.diff(CE_mat, axis=1)
    dCE = scipy.ndimage.gaussian_filter1d(dCE, 2, axis=1)

    dCE *= -1

    # what if we just plot the CE?
    dCE = CE_mat

    ymax = np.max(dCE)
    dCE /= ymax

    df = pd.DataFrame(dCE.T)
    df.columns = [f"{iv:.2f}" for iv in ivar]

    # Create ridgeline plot
    plt.figure(figsize=(10, 8))

    xrange = list(range(T))

    fig, axes = joypy.joyplot(df,
                              kind="values",
                              overlap=5 / 15,
                              fade=True,
                              linecolor='black',
                              linewidth=0.5,
                              colormap=cm.coolwarm,
                              ylim=(-1, 1),
                              title='Cross-Entropy over time for varying r',
                              x_range=xrange) # TODO changeme

    plt.xlabel(r"t", fontsize=12)

    ax = axes[-1]
    ax.yaxis.set_label_position("right")
    ax.set_ylabel("r") # TODO changeme
    ax.yaxis.set_visible(True)
    ax.yaxis.set_ticks([])

    os.makedirs('plots', exist_ok=True)
    plt.savefig('./plots/task_2_3_ridgeline_15r.png') # TODO changeme

    
    # Ramp version
    
    num_trials = 15
    num_samples = 20
    K = 50
    T = 100
    save_filename = "./results/ridgeline_15b.npy"
    recompute = False

    betas = np.linspace(0, 4, num_samples)
    # sigmas = np.linspace(0, 4, num_samples)

    if os.path.exists(save_filename) and not recompute:
        print("loading " + save_filename)
        CE_mat = np.load(save_filename)
    else:
        print("computing")
        CE_mat = np.zeros((num_samples, T))

        for i1, s in enumerate(betas):
            sum_CE = 0
            for _ in range(num_trials):
                ex, expected_s, states = task_2_3.ramp_HMM_inference({
                    # "x0": 0.02,
                    "beta": s,
                    # "sigma": s, # for now
                    "K": K
                })
                sum_CE += task_2_3.cross_entropy(ex, states)
            CE_mat[i1] = sum_CE / num_trials

            print(f'Progress: {i1 + 1}/{num_samples} (beta)')

        np.save(save_filename, CE_mat)
        print(f"saved to {save_filename}")

    # smooth and take the negative differential
    dCE = np.diff(CE_mat, axis=1)
    dCE = scipy.ndimage.gaussian_filter1d(dCE, 2, axis=1)

    dCE *= -1
    ymax = np.max(dCE)
    dCE /= ymax

    df = pd.DataFrame(dCE.T)
    df.columns = [f"{s:.2f}" for s in betas]

    # Create ridgeline plot
    plt.figure(figsize=(10, 8))


    xrange = list(range(T))


    fig, axes = joypy.joyplot(df,
                            kind="values",
                            overlap=5/15,
                            fade=True,
                            linecolor='black',
                            linewidth=0.5,
                            colormap=cm.coolwarm,
                            ylim=(0, 1),
                            title='Decrease in Cross-Entropy over time for varying ',
                            x_range=xrange)

    plt.xlabel(r"t", fontsize=12)

    ax = axes[-1]
    ax.yaxis.set_label_position("right")
    ax.set_ylabel("")
    ax.yaxis.set_visible(True)
    ax.yaxis.set_ticks([])



    plt.savefig('./plots/task_2_3_ridgeline_15b.png')

    
    # Ramp version (sigma)
    
    num_trials = 15
    num_samples = 20
    K = 50
    T = 100
    save_filename = "./results/ridgeline_21s.npy"
    recompute = False

    sigmas = np.linspace(0, 4, num_samples)
    beta = 1.5

    if os.path.exists(save_filename) and not recompute:
        print("loading " + save_filename)
        CE_mat = np.load(save_filename)
    else:
        print("computing")
        CE_mat = np.zeros((num_samples, T))

        for i1, s in enumerate(sigmas):
            sum_CE = 0
            for _ in range(num_trials):
                ex, expected_s, states = task_2_3.ramp_HMM_inference({
                    # "x0": 0.02,
                    "beta": beta,
                    "sigma": s,
                    "K": K
                })
                sum_CE += task_2_3.cross_entropy(ex, states)
            CE_mat[i1] = sum_CE / num_trials

            print(f'Progress: {i1 + 1}/{num_samples} (sigma)')

        np.save(save_filename, CE_mat)
        print(f"saved to {save_filename}")

    # smooth and take the negative differential
    dCE = np.diff(CE_mat, axis=1)
    dCE = scipy.ndimage.gaussian_filter1d(dCE, 2, axis=1)

    dCE *= -1
    ymax = np.max(dCE)
    dCE /= ymax

    df = pd.DataFrame(dCE.T)
    df.columns = [f"{s:.2f}" for s in sigmas]

    # Create ridgeline plot
    plt.figure(figsize=(10, 8))


    xrange = list(range(T))


    fig, axes = joypy.joyplot(df,
                            kind="values",
                            overlap=5/15,
                            fade=True,
                            linecolor='black',
                            linewidth=0.5,
                            colormap=cm.coolwarm,
                            ylim=(0, 1),
                            title='Decrease in Cross-Entropy over time for varying ',
                            x_range=xrange)

    plt.xlabel(r"t", fontsize=12)

    ax = axes[-1]
    ax.yaxis.set_label_position("right")
    ax.set_ylabel("")
    ax.yaxis.set_visible(True)
    ax.yaxis.set_ticks([])

    plt.savefig('./plots/task_2_3_ridgeline_20s.png')


    # Step version (m)

    num_trials = 500 # trials per parameter combo
    num_samples = 15 # on parameter space
    T = 250
    save_filename = "./results/ridgeline_15m_T250.npy"
    recompute = False

    ms = np.linspace(T * 0.25, T * 0.75, num_samples)

    ivar = ms
    r = 10

    if os.path.exists(save_filename) and not recompute:
        print("loading " + save_filename)
        CE_mat = np.load(save_filename)
    else:
        print("computing")
        CE_mat = np.zeros((num_samples, T))

        for i1, iv in enumerate(ivar):  # iv for independent variable
            sum_CE = 0
            for _ in range(num_trials):
                ex, expected_s, states = task_2_3.step_HMM_inference({
                    "r": r,
                    "m": iv,
                    "T": T
                })

                bex = task_2_3.compress_states(ex)
                bstates = (states == r).astype(int)
                sum_CE += task_2_3.cross_entropy(bex, bstates)

            CE_mat[i1] = sum_CE / num_trials

            print(f'Progress: {i1 + 1}/{num_samples} (m)')

        np.save(save_filename, CE_mat)
        print(f"saved to {save_filename}")

    # what if we just plot the CE?
    dCE = CE_mat

    ymax = np.max(dCE)
    dCE /= ymax

    df = pd.DataFrame(dCE.T)
    df.columns = [f"{iv:.2f}" for iv in ivar]

    # Create ridgeline plot
    plt.figure(figsize=(10, 8))

    xrange = list(range(T))

    fig, axes = joypy.joyplot(df,
                              kind="values",
                              overlap=5 / 15,
                              fade=True,
                              linecolor='black',
                              linewidth=0.5,
                              colormap=cm.coolwarm,
                              ylim=(-1, 1),
                              title='Cross-Entropy over time for varying m',
                              x_range=xrange)

    plt.xlabel(r"t", fontsize=12)

    ax = axes[-1]
    ax.yaxis.set_label_position("right")
    ax.set_ylabel("m")
    ax.yaxis.set_visible(True)
    ax.yaxis.set_ticks([])

    os.makedirs('plots', exist_ok=True)
    plt.savefig('./plots/task_2_3_ridgeline_15m.png')


task_2_2_.py
import numpy as np
import matplotlib.pyplot as plt
import models
import models_hmm
import os
from tqdm import tqdm
import pickle
import concurrent.futures

# make text larger
plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})

def _run_single_simulation(args):
    """Helper for running one simulation instance for parallel execution."""
    model_class, sim_func, m, r, n_trials, T, bin_edges = args
    model_instance = model_class(m=m, r=r)
    sim_function = getattr(model_instance, sim_func)
    _, jumps, _ = sim_function(Ntrials=n_trials, T=T)
    counts, _ = np.histogram(jumps, bins=bin_edges, density=True)
    return counts

def compare_jump_time_histograms(m, r, n_trials, n_datasets, T):
    """
    Compares the jump time histograms of the week 1 model and the three
    HMM approximations, using parallel processing and caching.
    """
    
    models_to_compare = {
        "Week 1 Model": {
            "model_class": models.StepModel,
            "sim_func": "simulate",
            "plot_type": "line"
        },
        "HMM (2-state)": {
            "model_class": models_hmm.StepModelHMM,
            "sim_func": "simulate_2state",
        },
        "HMM (r+1-state)": {
            "model_class": models_hmm.StepModelHMM,
            "sim_func": "simulate_exact",
        },
        "HMM (Inhomogeneous 2-state)": {
            "model_class": models_hmm.StepModelHMM,
            "sim_func": "simulate_exact_2state",
        }
    }
    
    cache_dir = os.path.join("plots", "cache")
    os.makedirs(cache_dir, exist_ok=True)
    
    bin_edges = np.linspace(0, T, 51)
    bin_width = bin_edges[1] - bin_edges[0]
    
    all_avg_hists = {}

    for name, details in models_to_compare.items():
        print(f"Processing {name}...")
        
        safe_name = name.replace(" ", "_").replace("(", "").replace(")", "").replace("+", "")
        cache_filename = os.path.join(cache_dir, f"task_2_2_hists_{safe_name}_m{m}_r{r}_T{T}_N{n_trials}_D{n_datasets}.pickle")

        if os.path.exists(cache_filename):
            with open(cache_filename, 'rb') as f:
                all_avg_hists[name] = pickle.load(f)
            print(f"  Loaded from cache: {cache_filename}")
        else:
            tasks = [(details["model_class"], details["sim_func"], m, r, n_trials, T, bin_edges) for _ in range(n_datasets)]
            
            dataset_hist_counts = []
            with concurrent.futures.ProcessPoolExecutor() as executor:
                results = list(tqdm(executor.map(_run_single_simulation, tasks), total=len(tasks), desc=f"  Datasets for {name}"))
                dataset_hist_counts.extend(results)

            avg_hist = np.mean(dataset_hist_counts, axis=0)
            all_avg_hists[name] = avg_hist
            
            with open(cache_filename, 'wb') as f:
                pickle.dump(avg_hist, f)
            print(f"  Saved to cache: {cache_filename}")

    plt.figure(figsize=(12 * 0.7, 8 * 0.7))
    
    for name, avg_hist in all_avg_hists.items():
        if models_to_compare[name].get('plot_type') == "line":
            bin_centers = bin_edges[:-1] + bin_width / 2

            plt.plot(bin_centers, avg_hist, alpha=1, label=name, color='black')
        else:
            plt.bar(bin_edges[:-1], avg_hist, width=bin_width, alpha=0.5, label=name, align='edge')

    plt.xlabel('Jump Time (ms)')
    plt.ylabel('Probability Density')
    plt.title(f'Comparison of Jump Time Distributions\n(m={m}, r={r}, N_trials={n_trials}, N_datasets={n_datasets})')
    plt.legend()
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    
    savename = f'plots/task_2_2_histogram_comparison_m{m}_r{r}_line.png'
    os.makedirs('plots', exist_ok=True)
    plt.savefig(savename, dpi=300, bbox_inches='tight')
    plt.show()


if __name__ == "__main__":
    T_DURATION = 1000
    N_TRIALS = 1000
    N_DATASETS = 20
    
    M = 500
    R = 100
    
    compare_jump_time_histograms(
        m=M,
        r=R,
        n_trials=N_TRIALS,
        n_datasets=N_DATASETS,
        T=T_DURATION
    )

import models
import os
import pickle
from tqdm import tqdm
import concurrent.futures

def _run_single_step_grid_point(args):
    """Helper function to run simulation for a single parameter grid point."""
    m, r, n_trials, T, n_datasets = args
    
    rmses = []
    signed_errors = []

    for _ in range(n_datasets):
        week1_model = models.StepModel(m=m, r=r)
        hmm_model = models_hmm.StepModelHMM(m=m, r=r)

        _, _, rates_week1 = week1_model.simulate(Ntrials=n_trials, T=T, get_rate=True)
        _, _, rates_hmm = hmm_model.simulate_exact_2state(Ntrials=n_trials, T=T)

        avg_rates_week1 = np.mean(rates_week1, axis=0)
        avg_rates_hmm = np.mean(rates_hmm, axis=0)

        rmse = np.sqrt(np.mean((avg_rates_hmm - avg_rates_week1)**2))
        signed_error = np.mean(avg_rates_hmm - avg_rates_week1)
        
        rmses.append(rmse)
        signed_errors.append(signed_error)

    return np.mean(rmses), np.mean(signed_errors)

def analyze_step_model_accuracy_heatmap(m_vals, r_vals, n_trials, T, n_datasets):
    """
    Analyzes the accuracy of the Inhomogeneous 2-state HMM against the Week 1 model
    across a parameter grid and plots the results as heatmaps.
    """
    print("\n--- Running Step Model HMM Accuracy Analysis ---")
    cache_dir = os.path.join("plots", "cache")
    os.makedirs(cache_dir, exist_ok=True)
    
    m_len = len(m_vals)
    r_len = len(r_vals)
    cache_filename = os.path.join(cache_dir, f"task_2_2_heatmap_errors_m{m_len}_r{r_len}_T{T}_N{n_trials}_D{n_datasets}.pickle")

    if os.path.exists(cache_filename):
        with open(cache_filename, 'rb') as f:
            errors = pickle.load(f)
        print(f"Loaded errors from cache: {cache_filename}")
    else:
        tasks = []
        for r in r_vals:
            for m in m_vals:
                tasks.append((m, r, n_trials, T, n_datasets))
        
        results = []
        with concurrent.futures.ProcessPoolExecutor() as executor:
            results = list(tqdm(executor.map(_run_single_step_grid_point, tasks), total=len(tasks), desc="Processing grid points"))
        
        rmse_errors = np.array([res[0] for res in results]).reshape(len(r_vals), len(m_vals))
        signed_errors = np.array([res[1] for res in results]).reshape(len(r_vals), len(m_vals))
        errors = {'rmse': rmse_errors, 'signed': signed_errors}
        
        with open(cache_filename, 'wb') as f:
            pickle.dump(errors, f)
        print(f"Saved errors to cache: {cache_filename}")

    # --- Plotting ---
    delta_m = m_vals[1] - m_vals[0] if len(m_vals) > 1 else 0
    extent = [m_vals[0] - delta_m / 2, m_vals[-1] + delta_m / 2, r_vals[0] - 0.5, r_vals[-1] + 0.5]

    # Plot RMSE
    plt.figure(figsize=(10, 8))
    im = plt.imshow(errors['rmse'], aspect='auto', origin='lower', extent=extent, cmap='viridis')
    plt.colorbar(im, label="RMSE of mean firing rate")
    plt.xlabel("m (mean jump time)")
    plt.ylabel("r (jump time variability)")
    plt.yticks(r_vals)
    plt.title(f"Step Model HMM vs. Week 1 Model Accuracy (RMSE)\n(N_trials={n_trials}, N_datasets={n_datasets})")
    plt.savefig('plots/task_2_2_heatmap_rmse.png', dpi=300, bbox_inches='tight')
    plt.show()

    # Plot Signed Error
    plt.figure(figsize=(10, 8))
    signed_errors_matrix = errors['signed']
    max_abs_error = np.max(np.abs(signed_errors_matrix))
    im = plt.imshow(signed_errors_matrix, aspect='auto', origin='lower', extent=extent, cmap='coolwarm', vmin=-max_abs_error, vmax=max_abs_error)
    plt.colorbar(im, label="Signed Mean Error (HMM - Week 1)")
    plt.xlabel("m (mean jump time)")
    plt.ylabel("r (jump time variability)")
    plt.yticks(r_vals)
    plt.title(f"Step Model HMM vs. Week 1 Model Accuracy (Signed Error)\n(N_trials={n_trials}, N_datasets={n_datasets})")
    plt.savefig('plots/task_2_2_heatmap_signed_error.png', dpi=300, bbox_inches='tight')
    plt.show()

if __name__ == "__main__":
    T_DURATION = 1000
    N_TRIALS_HEATMAP = 1000
    N_GRID_POINTS_M = 15
    N_DATASETS_HEATMAP = 5 # Average over 5 datasets for stability

    m_values = np.linspace(1, T_DURATION * 3 / 4, N_GRID_POINTS_M)
    r_values = np.arange(1, 7)
    
    analyze_step_model_accuracy_heatmap(
        m_vals=m_values,
        r_vals=r_values,
        n_trials=N_TRIALS_HEATMAP,
        T=T_DURATION,
        n_datasets=N_DATASETS_HEATMAP
    )

george/task_1_1_ramp.py
import numpy as np
import matplotlib.pyplot as plt
import models
import argparse
# make text larger
plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})

parser = argparse.ArgumentParser()
parser.add_argument('--show', action='store_true', help='Show plots interactively')
args = parser.parse_args()

N_TRIALS = 100  # number of trials to simulate
T_DURATION = 1000  # duration of each trial in time-steps or ms

beta_values = [4, 4, 1]  # drift rate
sigma_values = [0.1, 0.4, 0.1]  # noise/diffusion

all_bound_hitting_times = {}
all_avg_trajectories = {}

for beta, sigma in zip(beta_values, sigma_values):
    print(f"\nTesting ={beta}, ={sigma}")
    ramp_model = models.RampModel(beta=beta, sigma=sigma)
    spikes_ramp, xs_ramp, rates_ramp = ramp_model.simulate(Ntrials=N_TRIALS, T=T_DURATION, get_rate=True)

    # calculate bound hitting times
    bound_hitting_times = []
    for trial_idx in range(N_TRIALS):
        trial_xs = xs_ramp[trial_idx, :]
        hit_times = np.where(trial_xs >= 1.0)[0]
        if len(hit_times) > 0:
            bound_hitting_times.append(hit_times[0])
        else:
            bound_hitting_times.append(T_DURATION)
    
    all_bound_hitting_times[(beta, sigma)] = bound_hitting_times
    avg_trajectory = np.mean(xs_ramp, axis=0)
    all_avg_trajectories[(beta, sigma)] = avg_trajectory

    if beta == 4 and sigma == 0.1:
        beta = 2
        sigma = 0.3
        ramp_model = models.RampModel(beta=2, sigma=0.3)
        spikes_ramp, xs_ramp, rates_ramp = ramp_model.simulate(Ntrials=N_TRIALS, T=T_DURATION, get_rate=True)

        # calculate bound hitting times
        bound_hitting_times = []
        for trial_idx in range(N_TRIALS):
            trial_xs = xs_ramp[trial_idx, :]
            hit_times = np.where(trial_xs >= 1.0)[0]
            if len(hit_times) > 0:
                bound_hitting_times.append(hit_times[0])
            else:
                bound_hitting_times.append(T_DURATION)
        # # spike raster
        plt.figure(figsize=(10, 6))
        for trial_idx in range(N_TRIALS):
            spike_times_trial = np.where(spikes_ramp[trial_idx, :] > 0)[0]
            plt.plot(spike_times_trial, np.ones_like(spike_times_trial) * trial_idx, '|', color='black', markersize=5)
            plt.plot(bound_hitting_times[trial_idx], trial_idx, 'ro', markersize=5, 
                    label='Bound Hit Time' if trial_idx == 0 else "")

        plt.xlabel("Time (ms)")
        plt.ylabel("Trial Number")
        plt.title(f"Ramp Model - Spike Raster (={beta}, ={sigma})")
        plt.ylim(-1, N_TRIALS)
        if N_TRIALS > 0: plt.legend()
        plt.savefig(f'plots/task_1_1_ramp_raster_B{beta}_S{sigma}.png', dpi=300, bbox_inches='tight')
        if args.show:
            plt.show()
        else:
            plt.close()

    print(f"Mean bound-hitting time: {np.mean(bound_hitting_times):.2f} ms")

# Combined histogram of bound-hitting times
plt.figure(figsize=(10, 6))
for (beta, sigma), bound_hitting_times in all_bound_hitting_times.items():
    if bound_hitting_times:
        plt.hist(bound_hitting_times, bins=50, alpha=0.5, label=f'={beta}, ={sigma}', range=(0, T_DURATION))

plt.xlabel("Time (ms)")
plt.ylabel("Frequency (Hz)")
plt.title("Ramp Model - Histogram of Bound-Hitting Times")
plt.legend()
plt.savefig('plots/task_1_1_ramp_bound_hitting_combined.png', dpi=300, bbox_inches='tight')
if args.show:
    plt.show()
else:
    plt.close()

# Combined average trajectories plot
plt.figure(figsize=(10, 6))
time_axis = np.arange(T_DURATION)
for (beta, sigma), avg_trajectory in all_avg_trajectories.items():
    plt.plot(time_axis, avg_trajectory, label=f'={beta}, ={sigma}')

plt.xlabel("Time (ms)")
plt.ylabel("Average Latent Variable $x_t$")
plt.title("Ramp Model - Average Latent Variable Trajectories")
plt.axhline(1.0, color='r', linestyle='--', label='Boundary $x_t=1$')
plt.legend(loc='lower right')
plt.savefig('plots/task_1_1_ramp_avg_trajectories_combined.png', dpi=300, bbox_inches='tight')
if args.show:
    plt.show()
else:
    plt.close()

george/models.py
import numpy as np
import numpy.random as npr


def lo_histogram(x, bins):
    """
    Left-open version of np.histogram with left-open bins covering the interval (left_edge, right_edge]
    (np.histogram does the opposite and treats bins as right-open.)
    Input & output behaviour is exactly the same as np.histogram
    """
    out = np.histogram(-x, -bins[::-1])
    return out[0][::-1], out[1:]


def gamma_isi_point_process(rate, shape):
    """
    Simulates (1 trial of) a sub-poisson point process (with underdispersed inter-spike intervals relative to Poisson)
    :param rate: time-series giving the mean spike count (firing rate * dt) in different time bins (= time steps)
    :param shape: shape parameter of the gamma distribution of ISI's
    :return: vector of spike counts with same shape as "rate".
    """
    sum_r_t = np.hstack((0, np.cumsum(rate)))
    gs = np.zeros(2)
    while gs[-1] < sum_r_t[-1]:
        gs = np.cumsum( npr.gamma(shape, 1 / shape, size=(2 + int(2 * sum_r_t[-1]),)) )
    y, _ = lo_histogram(gs, sum_r_t)

    return y



class StepModel():
    """
    Simulator of the Stepping Model of Latimer et al. Science 2015.
    """
    def __init__(self, m=50, r=10, x0=0.2, Rh=50, isi_gamma_shape=None, Rl=None, dt=None):
        """
        Simulator of the Stepping Model of Latimer et al. Science 2015.
        :param m: mean jump time (in # of time-steps). This is the mean parameter of the Negative Binomial distribution
                  of jump (stepping) time
        :param r: parameter r ("# of successes") of the Negative Binomial (NB) distribution of jump (stepping) time
                  (Note that it is more customary to parametrise the NB distribution by its parameter p and r,
                  instead of m and r, where p is so-called "probability of success" (see Wikipedia). The two
                  parametrisations are equivalent and one can go back-and-forth via: m = r (1-p)/p and p = r / (m + r).)
        :param x0: determines the pre-jump firing rate, via  R_pre = x0 * Rh (see below for Rh)
        :param Rh: firing rate of the "up" state (the same as the post-jump state in most of the project tasks)
        :param isi_gamma_shape: shape parameter of the Gamma distribution of inter-spike intervals.
                            see https://en.wikipedia.org/wiki/Gamma_distribution
        :param Rl: firing rate of the post-jump "down" state (rarely used)
        :param dt: real time duration of time steps in seconds (only used for converting rates to units of inverse time-step)
        """
        self.m = m
        self.r = r
        self.x0 = x0

        self.p = r / (m + r)

        self.Rh = Rh
        if Rl is not None:
            self.Rl = Rl

        self.isi_gamma_shape = isi_gamma_shape
        self.dt = dt


    @property
    def params(self):
        return self.m, self.r, self.x0

    @property
    def fixed_params(self):
        return self.Rh, self.Rl


    def emit(self, rate):
        """
        emit spikes based on rates
        :param rate: firing rate sequence, r_t, possibly in many trials. Shape: (Ntrials, T)
        :return: spike train, n_t, as an array of shape (Ntrials, T) containing integer spike counts in different
                 trials and time bins.
        """
        if self.isi_gamma_shape is None:
            # poisson spike emissions
            y = npr.poisson(rate * self.dt)
        else:
            # sub-poisson/underdispersed spike emissions
            y = gamma_isi_point_process(rate * self.dt, self.isi_gamma_shape)

        return y


    def simulate(self, Ntrials=1, T=100, get_rate=True):
        """
        :param Ntrials: (int) number of trials
        :param T: (int) duration of each trial in number of time-steps.
        :param get_rate: whether or not to return the rate time-series
        :return:
        spikes: shape = (Ntrial, T); spikes[j] gives the spike train, n_t, in trial j, as
                an array of spike counts in each time-bin (= time step)
        jumps:  shape = (Ntrials,) ; jumps[j] is the jump time (aka step time), tau, in trial j.
        rates:  shape = (Ntrial, T); rates[j] is the rate time-series, r_t, in trial j (returned only if get_rate=True)
        """
        # set dt (time-step duration in seconds) such that trial duration is always 1 second, regardless of T.
        dt = 1 / T
        self.dt = dt

        ts = np.arange(T)

        spikes, jumps, rates = [], [], []
        for tr in range(Ntrials):
            # sample jump time
            jump = npr.negative_binomial(self.r, self.p)
            jumps.append(jump)

            # first set rate at all times to pre-step rate
            rate = np.ones(T) * self.x0 * self.Rh
            # then set rates after jump to self.Rh
            rate[ts >= jump] = self.Rh
            rates.append(rate)

            spikes.append(self.emit(rate))

        if get_rate:
            return np.array(spikes), np.array(jumps), np.array(rates)
        else:
            return np.array(spikes), np.array(jumps)


class RampModel():
    """
    Simulator of the Ramping Model (aka Drift-Diffusion Model) of Latimer et al., Science (2015).
    """
    def __init__(self, beta=0.5, sigma=0.2, x0=.2, Rh=50, isi_gamma_shape=None, Rl=None, dt=None):
        """
        Simulator of the Ramping Model of Latimer et al. Science 2015.
        :param beta: drift rate of the drift-diffusion process
        :param sigma: diffusion strength of the drift-diffusion process.
        :param x0: average initial value of latent variable x[0]
        :param Rh: the maximal firing rate obtained when x_t reaches 1 (corresponding to the same as the post-step
                   state in most of the project tasks)
        :param isi_gamma_shape: shape parameter of the Gamma distribution of inter-spike intervals.
                            see https://en.wikipedia.org/wiki/Gamma_distribution
        :param Rl: Not implemented. Ignore.
        :param dt: real time duration of time steps in seconds (only used for converting rates to units of inverse time-step)
        """
        self.beta = beta
        self.sigma = sigma
        self.x0 = x0

        self.Rh = Rh
        if Rl is not None:
            self.Rl = Rl

        self.isi_gamma_shape = isi_gamma_shape
        self.dt = dt


    @property
    def params(self):
        return self.mu, self.sigma, self.x0

    @property
    def fixed_params(self):
        return self.Rh, self.Rl


    def f_io(self, xs, b=None):
        if b is None:
            return self.Rh * np.maximum(0, xs)
        else:
            return self.Rh * b * np.log(1 + np.exp(xs / b))


    def emit(self, rate):
        """
        emit spikes based on rates
        :param rate: firing rate sequence, r_t, possibly in many trials. Shape: (Ntrials, T)
        :return: spike train, n_t, as an array of shape (Ntrials, T) containing integer spike counts in different
                 trials and time bins.
        """
        if self.isi_gamma_shape is None:
            # poisson spike emissions
            y = npr.poisson(rate * self.dt)
        else:
            # sub-poisson/underdispersed spike emissions
            y = gamma_isi_point_process(rate * self.dt, self.isi_gamma_shape)

        return y


    def simulate(self, Ntrials=1, T=100, get_rate=True):
        """
        :param Ntrials: (int) number of trials
        :param T: (int) duration of each trial in number of time-steps.
        :param get_rate: whether or not to return the rate time-series
        :return:
        spikes: shape = (Ntrial, T); spikes[j] gives the spike train, n_t, in trial j, as
                an array of spike counts in each time-bin (= time step)
        xs:     shape = (Ntrial, T); xs[j] is the latent variable time-series x_t in trial j
        rates:  shape = (Ntrial, T); rates[j] is the rate time-series, r_t, in trial j (returned only if get_rate=True)
        """
        # set dt (time-step duration in seconds) such that trial duration is always 1 second, regardless of T.
        dt = 1 / T
        self.dt = dt

       # simulate all trials in parallel (using numpy arrays and broadcasting)

        # first, directly integrate/sum the drift-diffusion updates
        # x[t+1] = x[t] +  dt +  dt * randn (with initial condition x[0] = x0 +  dt * randn)
        # to get xs in shape (Ntrials, T):
        ts = np.arange(T)
        xs = self.x0 + self.beta * dt * ts + self.sigma * np.sqrt(dt) * np.cumsum(npr.randn(Ntrials, T), axis=1)
        # in each trial set x to 1 after 1st passage through 1; padding xs w 1 assures passage does happen, possibly at T+1
        taus = np.argmax(np.hstack((xs, np.ones((xs.shape[0],1)))) >= 1., axis=-1)
        xs = np.where(ts[None,:] >= taus[:,None], 1., xs)
        # # the above 2 lines are equivalent to:
        # for x in xs:
        #     if np.sum(x >= 1) > 0:
        #         tau = np.nonzero(x >= 1)[0][0]
        #         x[tau:] = 1

        rates = self.f_io(xs) # shape = (Ntrials, T)

        spikes = np.array([self.emit(rate) for rate in rates]) # shape = (Ntrial, T)

        if get_rate:
            return spikes, xs, rates
        else:
            return spikes, xs



george/task_1_4.py
import numpy as np
import matplotlib.pyplot as plt
import models
import argparse
import scipy.special
from scipy.optimize import curve_fit
import traceback
from utils import calculate_psth, calculate_fano_factor, generate_model_parameters, classify_model_by_psth
# make text larger
plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})

parser = argparse.ArgumentParser()
parser.add_argument('--show', action='store_true')
args = parser.parse_args()

if args.show:
    N_DATASETS_PER_CASE = 10
else:
    N_DATASETS_PER_CASE = 1000

T_DURATION_MS = 1000
FANO_BIN_WIDTH_MS = 50
PSTH_BIN_WIDTH_MS = 25
N_TRIALS_CLASSIFY = 400

def classify_model_by_fano(spike_trains, t_duration_ms, fano_bin_width_ms):
    """our strategy here is to detect a peak in the fano factor and then check if it is a step or ramp"""
    _, f_values = calculate_fano_factor(spike_trains, t_duration_ms, fano_bin_width_ms)

    n_smooth = 3
    smoothing_window = np.ones(n_smooth)/n_smooth
    smoothed_f_values = np.convolve(f_values, smoothing_window, mode='valid')

    max_f = np.max(smoothed_f_values)
    idx_max = np.argmax(smoothed_f_values)
    num_fano_bins = len(smoothed_f_values)
    mean_f = np.mean(smoothed_f_values)
    is_peak_central = (idx_max > num_fano_bins * 0.20) and (idx_max < num_fano_bins * 0.80)
    is_peak_prominent = max_f > mean_f * 1.1
    is_peak_at_end = idx_max > num_fano_bins * 0.80
    has_significant_drop = False
    if idx_max < num_fano_bins - 1: 
        drop_window_start = idx_max + 1
        drop_window_end = min(drop_window_start + int(num_fano_bins * 0.3), num_fano_bins) 
        if drop_window_end > drop_window_start:
            mean_f_after_peak = np.mean(smoothed_f_values[drop_window_start:drop_window_end])
            if not np.isnan(mean_f_after_peak):
                 has_significant_drop = mean_f_after_peak < (max_f * 0.90) 

    has_significant_rise = False
    if idx_max > 0: 
        rise_window_end = idx_max
        rise_window_start = max(0, idx_max - int(num_fano_bins * 0.3)) 
        if rise_window_end > rise_window_start:
            mean_f_before_peak = np.mean(smoothed_f_values[rise_window_start:rise_window_end])
            if not np.isnan(mean_f_before_peak):
                 has_significant_rise = mean_f_before_peak < (max_f * 0.90) 
                 
    if has_significant_drop and has_significant_rise and not is_peak_at_end and is_peak_central:
        return 'step'
    else:
        return 'ramp'


def evaluate_classifiers():
    scenarios = [
        {'name': 'Ramp Detection', 'model_type': 'ramp'},
        {'name': 'Step Detection', 'model_type': 'step'},
    ]

    for scenario in scenarios:
        correct_fano = 0
        correct_psth = 0

        for i in range(N_DATASETS_PER_CASE):
            current_params = generate_model_parameters(scenario['model_type'], T_DURATION_MS)
            
            if scenario['model_type'] == 'ramp':
                model = models.RampModel(beta=current_params['beta'], sigma=current_params['sigma'])
            else: 
                model = models.StepModel(m=current_params['m'], r=current_params['r'], x0=current_params['x0'])
            
            spikes, _, _ = model.simulate(Ntrials=N_TRIALS_CLASSIFY, T=T_DURATION_MS)
            
            predicted_type_fano = classify_model_by_fano(spikes, T_DURATION_MS, FANO_BIN_WIDTH_MS)
            if predicted_type_fano == scenario['model_type']:
                correct_fano += 1
            
            predicted_type_psth = classify_model_by_psth(spikes, T_DURATION_MS, PSTH_BIN_WIDTH_MS, args.show)
            if predicted_type_psth == scenario['model_type']:
                correct_psth += 1
            
        accuracy_fano = (correct_fano / N_DATASETS_PER_CASE) * 100
        accuracy_psth = (correct_psth / N_DATASETS_PER_CASE) * 100
        
        print()
        print(f"Result for {scenario['name']}:")
        print(f"  Fano Classifier: Correctly classified {correct_fano}/{N_DATASETS_PER_CASE} ({accuracy_fano:.2f}%)")
        print(f"  PSTH Classifier: Correctly classified {correct_psth}/{N_DATASETS_PER_CASE} ({accuracy_psth:.2f}%)")
        

if __name__ == "__main__":
    evaluate_classifiers() 

george/task_1_1_step.py
import numpy as np
import matplotlib.pyplot as plt
import models
import argparse
# make text larger
plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})

parser = argparse.ArgumentParser()
parser.add_argument('--show', action='store_true')
args = parser.parse_args()

N_TRIALS = 500  # number of trials to simulate
T_DURATION = 1000  # duration of each trial in time-steps or ms

M_values = [T_DURATION / 3, T_DURATION / 3, T_DURATION * 2 / 3] # mean jump time
R_values = [10, 100, 100] # jump time variability 

all_jumps = {}
all_avg_rates = {}

for M, R in zip(M_values, R_values):
    N_TRIALS = 50
    M = 500
    R = 100
    print(f"\nTesting M={M}, R={R}")
    step_model = models.StepModel(m=M, r=R)

    spikes_step, jumps_step, rates_step = step_model.simulate(Ntrials=N_TRIALS, T=T_DURATION, get_rate=True)

    all_jumps[(M, R)] = jumps_step
    avg_rates = np.mean(rates_step, axis=0)
    all_avg_rates[(M, R)] = avg_rates

    # spike raster
    plt.figure(figsize=(10, 6))
    for trial_idx in range(N_TRIALS):
        spike_times_trial = np.where(spikes_step[trial_idx, :] > 0)[0]
        plt.plot(spike_times_trial, np.ones_like(spike_times_trial) * trial_idx, '|', color='black', markersize=5)
        
        plt.plot(jumps_step[trial_idx], trial_idx, 'ro', markersize=5, label='Jump Time' if trial_idx == 0 else "")

    plt.xlabel("Time (ms)")
    plt.ylabel("Trial Number")
    plt.title(f"Step Model - Spike Raster (m={M}, r={R})")
    plt.ylim(-1, N_TRIALS)
    if N_TRIALS > 0: plt.legend()
    plt.savefig(f'plots/task_1_1_step_raster_M{M}_R{R}.png', dpi=300, bbox_inches='tight')
    if args.show:
        plt.show()
    else:
        plt.close()
    break
N_TRIALS = 500  # number of trials to simulate

# Combined histogram of jump times
plt.figure(figsize=(8, 5))
for (M, R), jumps in all_jumps.items():
    plt.hist(jumps, bins=50, range=(0, T_DURATION), density=True, alpha=0.5, label=f'm={int(M)}, r={R}')
plt.xlabel("Time (ms)")
plt.ylabel("Frequency (Hz)")
plt.title("Step Model - Histogram of Jump Times")
plt.legend()
plt.savefig('plots/task_1_1_step_histogram_combined.png', dpi=300, bbox_inches='tight')
if args.show:
    plt.show()
else:
    plt.close()

# Combined average firing rate plot
plt.figure(figsize=(10, 6))
time_axis = np.arange(T_DURATION)
for (M, R), avg_rates in all_avg_rates.items():
    plt.plot(time_axis, avg_rates, label=f'm={int(M)}, r={R}')

plt.xlabel("Time (ms)")
plt.ylabel("Average Firing Rate (Hz)")
plt.title("Step Model - Average Firing Rate")
plt.legend(loc='upper left')
plt.savefig('plots/task_1_1_step_avg_rates_combined.png', dpi=300, bbox_inches='tight')
if args.show:
    plt.show()
else:
    plt.close()


george/task_1_2.py
import numpy as np
import matplotlib.pyplot as plt
import models
import argparse
from utils import calculate_psth
# make text larger
plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})

parser = argparse.ArgumentParser()
parser.add_argument('--show', action='store_true')
args = parser.parse_args()

T_DURATION_MS = 1000
PSTH_BIN_WIDTH_MS = 25

def calculate_psth_fluctuations(spike_trains, t_duration_ms, bin_width_ms):
    n_trials = spike_trains.shape[0]

    num_bins = int(t_duration_ms / bin_width_ms)

    all_trials_binned_counts = np.zeros((n_trials, num_bins))

    for trial_i in range(n_trials):
        for bin_idx in range(num_bins):
            start_time = bin_idx * bin_width_ms
            end_time = (bin_idx + 1) * bin_width_ms
            all_trials_binned_counts[trial_i, bin_idx] = np.sum(spike_trains[trial_i, start_time:end_time])
            
    std_counts_per_bin = np.std(all_trials_binned_counts)
    se_counts_per_bin = std_counts_per_bin / np.sqrt(n_trials)
    se_rate_per_bin_hz = se_counts_per_bin / (bin_width_ms / 1000.0)
    
    average_se_of_psth = np.mean(se_rate_per_bin_hz)
    return average_se_of_psth

def analyze_psth_fluctuations(show_plot):
    n_trials_list = np.array([20, 50, 100, 200, 500, 1000, 2000])
    avg_se_list = []

    model = models.RampModel(beta=1, sigma=0.3)

    for n_trials in n_trials_list:
        spikes, _, _ = model.simulate(Ntrials=n_trials, T=T_DURATION_MS)
        avg_se = calculate_psth_fluctuations(spikes, T_DURATION_MS, PSTH_BIN_WIDTH_MS)
        avg_se_list.append(avg_se)

    avg_se_list = np.array(avg_se_list)

    plt.figure(figsize=(10, 6))
    plt.plot(n_trials_list, avg_se_list, 'o-', label='Average SE of PSTH')
    
    # filter for NaN
    valid_indices = ~np.isnan(avg_se_list)
    if np.any(valid_indices) and sum(valid_indices) > 1:
        # use the first point to scale a 1/sqrt(N) curve
        scale_factor = avg_se_list[valid_indices][0] * np.sqrt(n_trials_list[valid_indices][0])
        plt.plot(n_trials_list, scale_factor / np.sqrt(n_trials_list), '--', label='1/N (scaled)')

    plt.xlabel("Number of Trials (N)")
    plt.ylabel("Average Standard Error of PSTH (Hz)")
    plt.title("PSTH Fluctuation vs. Number of Trials")
    plt.grid(True, alpha=0.5)
    plt.legend()
    plt.savefig('plots/task_1_2_psth_fluctuations.png', dpi=300, bbox_inches='tight')
    if show_plot:
        plt.show()
    else:
        plt.close()


def evaluate_psth_with_n_trials(show_plot, model_type):
    n_trials_to_plot = [100, 2000]
    N_TRIALS_REFERENCE = 50000

    if model_type.lower() == 'ramp':
        model = models.RampModel(beta=1.5, sigma=0.4)
        model_desc = f"Ramp Model (={1.5}, ={0.4})"
    else:
        model = models.StepModel(m=T_DURATION_MS/2, r=20)
        model_desc = f"Step Model (m={T_DURATION_MS/2}, r={20})"

    plt.figure(figsize=(12, 7))
    
    spikes_ref, _, _ = model.simulate(Ntrials=N_TRIALS_REFERENCE, T=T_DURATION_MS)
    time_bins, psth_ref_raw = calculate_psth(spikes_ref, T_DURATION_MS, PSTH_BIN_WIDTH_MS)
    plt.plot(time_bins, psth_ref_raw, label=f'Reference PSTH (N={N_TRIALS_REFERENCE})', color='black', linestyle='--', linewidth=2)

    for i, n_trials in enumerate(n_trials_to_plot):
        spikes, _, _ = model.simulate(Ntrials=n_trials, T=T_DURATION_MS)
        current_time_bins, psth_raw = calculate_psth(spikes, T_DURATION_MS, PSTH_BIN_WIDTH_MS)
        plt.plot(current_time_bins, psth_raw, label=f'PSTH (N={n_trials})', alpha=0.8)

    plt.xlabel("Time (ms)")
    plt.ylabel("Firing Rate (Hz)")
    plt.title(f"PSTH with Varying Number of Trials\n{model_desc}")
    plt.legend()
    plt.grid(True, alpha=0.5)
    
    plot_filename = f"plots/task_1_2_psth_n_trials_{model_type.lower()}.png"
    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')
    if show_plot:
        plt.show()
    else:
        plt.close()


def plot_psths(params):
    plt.figure(figsize=(12 * 0.7, 7 * 0.7))
    

    for param in params:
        model_type = "Unknown"
        model = None
        
        if 'beta' in param and 'sigma' in param:
            model_type = "Ramp"
            model = models.RampModel(beta=param['beta'], sigma=param['sigma'])
        else:
            model_type = "Step"
            model = models.StepModel(m=param['m'], r=param['r'])

        spikes, _, _ = model.simulate(Ntrials=1000, T=100)
        
        time_bins, psth_hz = calculate_psth(spikes, 100, PSTH_BIN_WIDTH_MS//5)
        
        label_params = ", ".join([f"{key}={value}" for key, value in param.items()])
        plt.plot(time_bins, psth_hz, marker='.', linestyle='-', markersize=5, label=f'{model_type}: {label_params}')

    plt.title(f'PSTH Comparison for indistuingishable case')
    plt.xlabel(f'Time (ms)')
    plt.ylabel('PSTH (Hz)')
    plt.legend()
    plt.grid(True, alpha=0.5)
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    analyze_psth_fluctuations(args.show)
    
    evaluate_psth_with_n_trials(args.show, 'ramp')
    evaluate_psth_with_n_trials(args.show, 'step')

    param_sets = [
        {"beta": 1.5, "sigma": 0.27},
        {"m": 30, "r": 2.45},
    ]

    plot_psths(param_sets)


george/utils.py
import numpy as np
def calculate_psth(spike_trains, t_duration_ms, bin_width_ms):
    # bin = np.convolve(bin, np.ones(bin_width_ms)/bin_width_ms, mode='valid')
    # spike_times = np.linspace(0, t_duration_ms, num = bin.shape[0], endpoint = False)

    # return spike_times, bin * t_duration_ms

    n_trials = spike_trains.shape[0]
    num_bins = int(t_duration_ms / bin_width_ms)
    psth_time_bins_ms = np.arange(num_bins) * bin_width_ms
    binned_sums = np.zeros(num_bins)

    # sum the spikes across trials into bins
    for trial_idx in range(n_trials):
        for bin_j in range(num_bins):
            start_time = bin_j * bin_width_ms
            end_time = (bin_j + 1) * bin_width_ms
            binned_sums[bin_j] += np.sum(spike_trains[trial_idx, start_time:end_time])
    
    # average and convert to Hz
    mean_spikes_per_bin = binned_sums / n_trials
    psth_values_hz = mean_spikes_per_bin / (bin_width_ms / 1000.0)  # convert to Hz
    
    return psth_time_bins_ms, psth_values_hz

def calculate_fano_factor(spike_trains, t_duration_ms, bin_width_ms):
    n_trials = spike_trains.shape[0]
    num_bins_fano = int(t_duration_ms / bin_width_ms)
    fano_time_bins_ms = np.arange(num_bins_fano) * bin_width_ms
    binned_counts_per_trial = np.zeros((n_trials, num_bins_fano))

    for trial_idx in range(n_trials):
        for bin_idx in range(num_bins_fano):
            start_time = bin_idx * bin_width_ms
            end_time = (bin_idx + 1) * bin_width_ms
            binned_counts_per_trial[trial_idx, bin_idx] = np.sum(spike_trains[trial_idx, start_time:end_time])
            
    mean_counts_per_bin = np.mean(binned_counts_per_trial, axis=0)
    variance_counts_per_trial = np.var(binned_counts_per_trial, axis=0, ddof=0)
    
    fano_factors = np.full_like(mean_counts_per_bin, np.nan, dtype=float)
    
    # calculate Fano factor only where mean is non zero
    non_zero_mean_indices = mean_counts_per_bin != 0
    fano_factors[non_zero_mean_indices] = variance_counts_per_trial[non_zero_mean_indices] / mean_counts_per_bin[non_zero_mean_indices]
    
    return fano_time_bins_ms, fano_factors

def generate_model_parameters(model_type_to_generate, t_duration_ms):
    if model_type_to_generate == 'ramp':
        beta = np.random.uniform(0, 4.0)
        sigma = np.exp(np.random.uniform(np.log(0.04), np.log(4)))
        return {'beta': beta, 'sigma': sigma}
    else:
        m = np.random.uniform(t_duration_ms * 0.25, t_duration_ms * 0.75)
        r = np.random.uniform(0.5, 6.0)
        x0 = np.random.uniform(0, 0.5)
        return {'m': m, 'r': r, 'x0': x0}

def generate_random_model_parameters(t_duration_ms):
    model_type = np.random.choice(['ramp', 'step'])
    if model_type == 'ramp':
        beta = np.random.uniform(0.1, 50.0)
        sigma = np.random.uniform(0.1, 5.0)
        params = {'beta': beta, 'sigma': sigma}
    else:
        # Use the passed t_duration_ms for calculating 'm'
        m = np.random.uniform(t_duration_ms * 0.1, t_duration_ms * 0.9)
        r = np.random.uniform(0.1, 50.0)
        params = {'m': m, 'r': r}
    return params

george/task_1_3.py
import numpy as np
import matplotlib.pyplot as plt
import models
import argparse
from utils import calculate_fano_factor, generate_model_parameters, generate_random_model_parameters
# make text larger
plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 14,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})

RUNNING_IN_JUPYTER = True
if not RUNNING_IN_JUPYTER:
    parser = argparse.ArgumentParser()
    parser.add_argument('--show', action='store_true')
    args = parser.parse_args()
else:
    # dont have command line args in jupyter, mock it
    class ArgsMock:
        show = True
    args = ArgsMock()

T_DURATION_MS = 1000
FANO_BIN_WIDTH_MS = 50
N_TRIALS_FANO = 50000

def analyze_fano_factors(params, label, show_plot):

    model_type = 'ramp' if all('beta' in p for p in params) else ('step' if all('m' in p for p in params) else 'mixed')

    plt.figure(figsize=(12 * 0.8, 7 * 0.8))
    for params in params:
        if 'beta' in params:
            model = models.RampModel(beta=params['beta'], sigma=params['sigma'])
        elif 'm' in params:
            model = models.StepModel(m=params['m'], r=params['r'])
        spikes, _, _ = model.simulate(Ntrials=N_TRIALS_FANO, T=T_DURATION_MS)
        time_bins, fano_vals = calculate_fano_factor(spikes, T_DURATION_MS, FANO_BIN_WIDTH_MS)
        # Fano stats
        valid_fano = fano_vals[~np.isnan(fano_vals)]
        mean_fano = np.mean(valid_fano)
        var_fano = np.var(valid_fano)
        start_fano = valid_fano[0] if len(valid_fano) > 0 else np.nan
        description = f"={params['beta']}, ={params['sigma']}" if 'beta' in params else f"m={params['m']}, r={params['r']}"
        if show_plot:
            print(f"Fano factor stats for {description}: mean: {mean_fano:.3f} starting val: {start_fano:.3f} variance: {var_fano:.3f}")
        
        plt.plot(time_bins, fano_vals, label=f"{'ramp' if 'beta' in params else 'step'}: {description}", alpha=0.8)
   
    plt.axhline(1, color='k', linestyle='--', label='Poisson (Fano=1)')
    plt.xlabel(f"Time (ms)")
    plt.ylabel("Fano Factor")
    model_label = "for Ramp Model" if model_type == "ramp" else "for Step Model" if model_type == "step" else ""
    plt.title(f"Fano Factor vs. Time {model_label} (N_trials={N_TRIALS_FANO})")
    plt.legend()
    plt.grid(True, alpha=0.5)
    plt.ylim(0, 2.5)
    plt.savefig('plots/task_1_3_fano_factor_{label}.png', dpi=300, bbox_inches='tight')
    if show_plot:
        plt.show()
    else:
        plt.close()


def generate_random_model_parameters():
    model_type = np.random.choice(['ramp', 'step'])
    if model_type == 'ramp':
        beta = np.random.uniform(0.1, 50.0)
        sigma = np.random.uniform(0.1, 5.0)
        params = {'beta': beta, 'sigma': sigma}
    else:
        m = np.random.uniform(T_DURATION_MS * 0.1, T_DURATION_MS * 0.9)
        r = np.random.uniform(0.1, 50.0)
        params = {'m': m, 'r': r}

    return params

def plot_step_model_trials(m_param, r_param, trial_counts, T_duration, show_plot):
    """
    Plots the activity of a StepModel for different numbers of trials.
    - For N=1, plots the spike train of a single trial.
    - For N in (1, 300], plots a raster of spike trains.
    - For N > 300 (large N), plots the Peri-Stimulus Time Histogram (PSTH).
    """
    model = models.StepModel(m=m_param, r=r_param)
    
    num_plots = len(trial_counts)
    # Ensure axes is a flat array for easy indexing, even if num_plots is 1
    fig, axes = plt.subplots(num_plots, 1, figsize=(12, 3.5 * num_plots), sharex=True, squeeze=False)
    axes = axes.flatten() 

    fig.suptitle(f"Step Model Activity (m={m_param}ms, effect of r={r_param})", fontsize=16)

    for i, N in enumerate(trial_counts):
        # Assuming model.simulate returns:
        # spikes: list of arrays (spike times per trial for each of N trials)
        # rates_psth: array (average firing rate over time, i.e., PSTH)
        # binned_spikes: 2D array (trial x time_bin) of spike counts (currently unused here)
        spikes, rates_psth, _ = model.simulate(Ntrials=N, T=T_duration)
        
        ax = axes[i]
        
        # Plot vertical line for step time 'm'
        ax.axvline(m_param, color='tomato', linestyle='--', linewidth=1.5, label=f'Step at t={m_param}ms', zorder=1)

        if N == 1:
            current_title = f"Single Trial (N=1)"
            # Based on ValueError, assume 'spikes' is a direct np.ndarray for N=1
            if isinstance(spikes, np.ndarray) and spikes.size > 0:
                ax.eventplot(spikes, lineoffsets=1, linelengths=0.8, colors='k', zorder=2) # Plot 'spikes' directly
                ax.set_yticks([1])
                ax.set_yticklabels(['Trial 1'])
            else: # No spikes, or not an ndarray (e.g. None), or an empty ndarray
                ax.text(0.5, 0.5, 'No spikes', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)
                ax.set_yticks([])
            ax.set_ylim(0.5, 1.5)
        elif N > 1 and N <= 300: # Raster plot for N (e.g., 300)
            current_title = f"Raster Plot (N={N})"
            # Check if spikes is a NumPy array and contains any finite values (actual spikes)
            if spikes is not None and np.any(np.isfinite(spikes)):
                 # eventplot can take a 2D array, treating rows as trials.
                 # Ensure lineoffsets match the number of trials, which should be N.
                 ax.eventplot(spikes, colors='k', linelengths=0.8, lineoffsets=np.arange(1, N + 1), zorder=2)
                 ax.set_ylim(0.5, N + 0.5)
                 ax.set_ylabel("Trial Number")
            else:
                 ax.text(0.5, 0.5, 'No spikes', horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)
                 ax.set_yticks([]) 
                 ax.set_ylabel("") 
        elif N > 300: # PSTH for large N (e.g., 10000)
            current_title = f"PSTH (N={N})"
            time_points_psth = np.linspace(0, T_duration, len(rates_psth), endpoint=True)
            ax.plot(time_points_psth, rates_psth, color='dodgerblue', linewidth=1.5, label='Avg. Firing Rate', zorder=2)
            ax.set_ylabel("Firing Rate (spikes/s)")
            ax.grid(True, linestyle=':', alpha=0.7)
            ax.legend(loc='best') # Legend for PSTH (includes axvline label)

        ax.set_title(current_title)
        ax.set_xlim(0, T_duration)

        # Add legend for the axvline if not the PSTH plot (which already has a combined legend)
        if not (N > 300):
            # Only show legend if there are actual elements labeled (the axvline here)
            handles, labels = ax.get_legend_handles_labels()
            if handles:
                 ax.legend(loc='best')

        if i == num_plots - 1: # Only set xlabel for the bottom subplot
            ax.set_xlabel("Time (ms)")
    
    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust rect for suptitle and ensure layout is tight
    
    plot_filename = f'plots/task_1_3_step_model_trials_m{m_param}_r{r_param}.png'
    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')
    print(f"Saved plot to {plot_filename}")

    if show_plot:
        plt.show()
    else:
        plt.close(fig)

def plot_fano_factor_for_step_model_trials(m_param, r_param, trial_counts, T_duration, fano_bin_width_ms, show_plot):
    """
    Calculates and plots Fano factors for a StepModel with varying numbers of trials.
    Each trial count will be represented as a different line on the same plot.
    """
    plt.figure(figsize=(12, 7))
    model_instance = models.StepModel(m=m_param, r=r_param) # Create model once

    for N in trial_counts:
        spikes, _, _ = model_instance.simulate(Ntrials=N, T=T_duration)
        time_bins, fano_vals = calculate_fano_factor(spikes, T_duration, fano_bin_width_ms)
        
        plt.plot(time_bins, fano_vals, label=f"N={N}", alpha=0.8)

        # Optional: Print some stats for each N if desired
        valid_fano = fano_vals[~np.isnan(fano_vals)]
        mean_fano = np.mean(valid_fano) if len(valid_fano) > 0 else np.nan
        print(f"For N={N}, m={m_param}, r={r_param}: Mean Fano Factor: {mean_fano:.3f} (using {len(valid_fano)} valid points)")

    plt.axhline(1, color='k', linestyle='--', label='Poisson (Fano=1)')
    # plt.axvline(m_param, color='tomato', linestyle=':', linewidth=1.5, label=f'Step at t={m_param}ms')
    plt.xlabel(f"Time (ms)")
    plt.ylabel("Fano Factor")
    plt.title(f"Fano Factor vs. Time for Step Model (m={m_param}, r={r_param}) across Trial Counts")
    plt.legend()
    plt.grid(True, alpha=0.5)
    plt.ylim(0, plt.ylim()[1] * 1.1 if plt.ylim()[1] > 2 else 2.5) # Adjust y-lim, ensure min 2.5

    plot_filename = f'plots/task_1_3_fano_step_trials_m{m_param}_r{r_param}.png'
    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')
    print(f"Saved Fano factor plot to {plot_filename}")

    plt.tight_layout()

    if show_plot:
        plt.show()
    else:
        plt.close()

if __name__ == "__main__":
    
    # Call the new function to plot step model trials
    step_m_param = 500
    step_r_param = 5
    trial_counts_for_step_plot = [1, 300, 10000]
    # plot_step_model_trials(m_param=step_m_param, 
    #                        r_param=step_r_param, 
    #                        trial_counts=trial_counts_for_step_plot, 
    #                        T_duration=T_DURATION_MS, 
    #                        show_plot=args.show)

    # Call the new function to plot Fano factors for step model with different trial counts
    # fano_trial_counts = [300, 10000] # Using a range of N values
    # plot_fano_factor_for_step_model_trials(m_param=step_m_param, # Use same m, r as above
    #                                        r_param=step_r_param,
    #                                        trial_counts=fano_trial_counts,
    #                                        T_duration=T_DURATION_MS,
    #                                        fano_bin_width_ms=FANO_BIN_WIDTH_MS,
    #                                        show_plot=args.show)

    params = {
        # "random_1": [generate_random_model_parameters(), generate_random_model_parameters()],
        # "random_2": [generate_random_model_parameters(), generate_random_model_parameters()],
        # "random_3": [generate_random_model_parameters(), generate_random_model_parameters()],
        # "random_4": [generate_random_model_parameters(), generate_random_model_parameters()],
        # "random_5": [generate_random_model_parameters(), generate_random_model_parameters()],
        # "random_6": [generate_random_model_parameters(), generate_random_model_parameters()],
        # "random_7": [generate_random_model_parameters(), generate_random_model_parameters()],
        # "random_8": [generate_random_model_parameters(), generate_random_model_parameters()],
        # "ramp_sigma": [
        #     {'beta': 0.5, 'sigma': 0.1},
        #     {'beta': 0.5, 'sigma': 0.8},
        #     {'beta': 10, 'sigma': 0.4},
        # ],
        # "ramp_beta": [
        #     {'beta': 0, 'sigma': 0.2},
        #     {'beta': 0.5, 'sigma': 0.2},
        #     {'beta': 2, 'sigma': 0.2}
        # ],
        # "step_r": [
        #     {'m': T_DURATION_MS / 2, 'r': 0.1},
        #     {'m': T_DURATION_MS / 2, 'r': 1},
        #     {'m': T_DURATION_MS / 2, 'r': 20},
        #     {'m': T_DURATION_MS / 2, 'r': 100}
        # ],
        "step_m": [
            {'m': T_DURATION_MS / 4, 'r': 1},
            {'m': T_DURATION_MS / 4, 'r': 6},
            {'m': T_DURATION_MS * .75, 'r': 12}
        ],
    # }
    # params = {
        # "indistinguishable_1": [
        #     {'beta': 1.0, 'sigma': 0.3},
        #     {'m': 50, 'r': 2.0}
        # ],
        # "indistinguishable_2": [
        #     {'beta': 1.5, 'sigma': 0.27},
        #     {'m': 30, 'r': 2.45}
        # ],
        # "indistinguishable_3": [
        #     {'beta': 1.8, 'sigma': 0.43}, 
        #     {'m': 26, 'r': 2.15}
        # ]
    }
    print(params)
    for param_type, param_list in params.items():
        print(param_type)
        analyze_fano_factors(param_list, param_type, args.show) 


